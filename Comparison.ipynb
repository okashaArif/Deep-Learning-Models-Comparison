{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf8cjNTZU25Q",
        "outputId": "70f9e759-c0c3-4ad8-a96a-9448bf22921c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                               text\n",
            "0      1  ounce feather bowl hummingbird opec moment ala...\n",
            "1      1  wulvob get your medircations online qnb ikud v...\n",
            "2      0   computer connection from cnn com wednesday es...\n",
            "3      1  university degree obtain a prosperous future m...\n",
            "4      0  thanks for all your answers guys i know i shou...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Set option to display all rows\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "df = pd.read_csv('/content/combined_data.csv')\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy1z4Rt5WTu6",
        "outputId": "3a775847-9642-4cca-880b-be3f81c014a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(83448, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "BXTF15FtWCVh",
        "outputId": "2fea5358-5aaa-40a0-c525-f2a75c4f0ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label    0\n",
              "text     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOTEo3LtWWR0"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('/content/final_features.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "xlfm39AGWpYL",
        "outputId": "6f711e56-be02-4bd8-93df-1421e9846ef7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  id  Length-of-Email  URLs-in-a-Email  \\\n",
              "0           0   1           0.0239           0.0003   \n",
              "1           1   2           0.0019           0.0003   \n",
              "2           2   3           0.0154           0.0006   \n",
              "3           3   4           0.0007           0.0003   \n",
              "4           4   5           0.0023           0.0006   \n",
              "\n",
              "   Repititive-Words-in-a-Email  Uinque-Words-in-a-Email  \\\n",
              "0                       0.0777                   0.0115   \n",
              "1                       0.0000                   0.0022   \n",
              "2                       0.0564                   0.0079   \n",
              "3                       0.0000                   0.0008   \n",
              "4                       0.0015                   0.0020   \n",
              "\n",
              "   Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "0                     0.0                       0.06   \n",
              "1                     0.0                       0.02   \n",
              "2                     0.0                       0.06   \n",
              "3                     0.0                       0.00   \n",
              "4                     0.0                       0.06   \n",
              "\n",
              "   Number of co-occuring words  Number of capitalized words  ...  semantic  \\\n",
              "0                       0.0001                       0.0000  ...    0.2847   \n",
              "1                       0.0000                       0.0000  ...    0.2338   \n",
              "2                       0.0001                       0.0000  ...    0.2577   \n",
              "3                       0.0000                       0.0000  ...    0.2860   \n",
              "4                       0.0000                       0.0024  ...    0.2766   \n",
              "\n",
              "   Neg-Sentiment  Neu-Sentiment  Pos-Sentiment  Comp-Sentiment  Spam lexicon  \\\n",
              "0         0.0968          0.719         0.2810          0.9959        0.4000   \n",
              "1         0.0000          0.876         0.1692          0.4767        0.0000   \n",
              "2         0.0232          0.928         0.0750          0.7967        0.0000   \n",
              "3         0.0000          0.538         0.6303          0.8568        0.0667   \n",
              "4         0.0000          0.884         0.1583          0.6947        0.0667   \n",
              "\n",
              "   User features  Polarity  Subjective  class  \n",
              "0              0    0.1722    0.183625      0  \n",
              "1              0    0.1572    0.508423      0  \n",
              "2              0    0.0398    0.462447      0  \n",
              "3              0    0.6183    0.007581      0  \n",
              "4              1    0.1463    0.143069      0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aad93382-b1a0-4929-8219-a14417e76064\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>URLs-in-a-Email</th>\n",
              "      <th>Repititive-Words-in-a-Email</th>\n",
              "      <th>Uinque-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occuring words</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>...</th>\n",
              "      <th>semantic</th>\n",
              "      <th>Neg-Sentiment</th>\n",
              "      <th>Neu-Sentiment</th>\n",
              "      <th>Pos-Sentiment</th>\n",
              "      <th>Comp-Sentiment</th>\n",
              "      <th>Spam lexicon</th>\n",
              "      <th>User features</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjective</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0239</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.0777</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2847</td>\n",
              "      <td>0.0968</td>\n",
              "      <td>0.719</td>\n",
              "      <td>0.2810</td>\n",
              "      <td>0.9959</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1722</td>\n",
              "      <td>0.183625</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2338</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.876</td>\n",
              "      <td>0.1692</td>\n",
              "      <td>0.4767</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1572</td>\n",
              "      <td>0.508423</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0564</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2577</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.928</td>\n",
              "      <td>0.0750</td>\n",
              "      <td>0.7967</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0398</td>\n",
              "      <td>0.462447</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2860</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.538</td>\n",
              "      <td>0.6303</td>\n",
              "      <td>0.8568</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6183</td>\n",
              "      <td>0.007581</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2766</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.884</td>\n",
              "      <td>0.1583</td>\n",
              "      <td>0.6947</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1463</td>\n",
              "      <td>0.143069</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aad93382-b1a0-4929-8219-a14417e76064')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aad93382-b1a0-4929-8219-a14417e76064 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aad93382-b1a0-4929-8219-a14417e76064');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f7251c6d-4c1a-45c0-a0ac-bcc2e02c0cc7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7251c6d-4c1a-45c0-a0ac-bcc2e02c0cc7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f7251c6d-4c1a-45c0-a0ac-bcc2e02c0cc7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lepR-MB5WrEB",
        "outputId": "07949af0-ba64-4d08-deae-a1439d64fb68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'id', 'Length-of-Email', 'URLs-in-a-Email',\n",
              "       'Repititive-Words-in-a-Email', 'Uinque-Words-in-a-Email',\n",
              "       'Quoted-text-in-a-Email', 'Question-Marks-in-a-Email',\n",
              "       'Number of co-occuring words', 'Number of capitalized words',\n",
              "       'Number-of-noun', 'semantic', 'Neg-Sentiment', 'Neu-Sentiment',\n",
              "       'Pos-Sentiment', 'Comp-Sentiment', 'Spam lexicon', 'User features',\n",
              "       'Polarity', 'Subjective', 'class'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df=df.copy()"
      ],
      "metadata": {
        "id": "vDPgWvW0WpPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Example spam lexicon (you can add more words based on your specific use case)\n",
        "spam_lexicons = set([\n",
        "    # Financial-related terms\n",
        "    'free', 'winner', 'win', 'prize', 'cash', 'urgent', 'congratulations',\n",
        "    'claim', 'credit', 'debt', 'discount', 'clearance', 'bargain', 'save',\n",
        "    'cheap', 'guarantee', 'money', 'investment', 'earn', 'income', 'profit',\n",
        "    'rich', 'fortune', 'million', 'billion', 'dollars', 'revenue', 'payment',\n",
        "\n",
        "    # Persuasive phrases\n",
        "    'act now', 'apply now', 'buy now', 'call now', 'click here', 'limited time',\n",
        "    'offer expires', 'order now', 'please read', 'risk-free', 'special promotion',\n",
        "    'this won’t last', 'urgent', 'exclusive offer', 'once in a lifetime',\n",
        "    'instant access', 'do it today', 'don’t delete', 'offer ends', 'final notice',\n",
        "\n",
        "    # Personal-related terms\n",
        "    'friend', 'dear', 'partner', 'family', 'important', 'invitation',\n",
        "    'attention', 'selected', 'member', 'winner', 'amazing', 'surprise',\n",
        "    'gift', 'loyal', 'lucky', 'vacation', 'holiday', 'win', 'visit',\n",
        "\n",
        "    # Legal-related terms\n",
        "    'law', 'legal', 'banned', 'illegal', 'violation', 'urgent', 'immediate action',\n",
        "    'penalty', 'court', 'attorney', 'lawyer', 'lawsuit', 'tax', 'IRS', 'federal',\n",
        "    'regulation', 'compliance', 'subpoena', 'judgment', 'settlement',\n",
        "\n",
        "    # Technical-related terms\n",
        "    'password', 'account', 'security', 'login', 'verify', 'verification', 'confirm',\n",
        "    'account update', 'limited access', 'account alert', 'unauthorized', 'compromise',\n",
        "    'system', 'database', 'phishing', 'hack', 'breach', 'malware', 'spyware',\n",
        "    'virus', 'install', 'download', 'software', 'update', 'scan', 'safe', 'trusted',\n",
        "\n",
        "    # Medical and health-related terms\n",
        "    'medicine', 'prescription', 'pharmacy', 'doctor', 'health', 'cure', 'treatment',\n",
        "    'drug', 'pill', 'weight loss', 'fat burning', 'anti-aging', 'miracle', 'remedy',\n",
        "    'supplement', 'herbal', 'detox', 'disease', 'cancer', 'diabetes', 'allergy',\n",
        "\n",
        "    # Miscellaneous\n",
        "    'adult', 'nude', 'sex', 'XXX', 'porn', 'casino', 'gambling', 'betting', 'lottery',\n",
        "    'jackpot', 'luxury', 'brand new', 'limited edition', 'celebrity', 'fame', 'fortune',\n",
        "    'confidential', 'private', 'secret', 'hidden', 'mystery', 'solution', 'bonus',\n",
        "    'gift card', 'voucher', 'rewards', 'prizes', 'cashback', 'sweepstakes'\n",
        "])\n",
        "\n",
        "# Function to count spam lexicons\n",
        "def count_spam_lexicons(text, spam_lexicons):\n",
        "    words = text.lower().split()\n",
        "    return sum(1 for word in words if word in spam_lexicons)\n",
        "\n",
        "# Function to count words with specific POS tags (e.g., nouns)\n",
        "def count_pos_tags(text, pos_tag):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    tagged_words = nltk.pos_tag(words)\n",
        "    return sum(1 for word, tag in tagged_words if tag.startswith(pos_tag))\n",
        "\n",
        "# Function to extract features from text\n",
        "def extract_features(text):\n",
        "    features = {}\n",
        "\n",
        "    # Length of email\n",
        "    features['Length-of-Email'] = len(text)\n",
        "\n",
        "    # Count URLs in email\n",
        "    features['URLs-in-a-Email'] = len(re.findall(r'http[s]?://\\S+', text))\n",
        "\n",
        "    # Count capitalized words in email (before converting to lowercase)\n",
        "    words = text.split()\n",
        "    features['Number of capitalized words'] = sum(1 for word in words if word.isupper())\n",
        "\n",
        "    # Convert text to lowercase for further processing\n",
        "    words = text.lower().split()\n",
        "\n",
        "    # Count repetitive words in email\n",
        "    word_counts = Counter(words)\n",
        "    features['Repititive-Words-in-a-Email'] = sum(1 for word, count in word_counts.items() if count > 1)\n",
        "\n",
        "    # Count unique words in email\n",
        "    features['Uinque-Words-in-a-Email'] = len(set(words))\n",
        "\n",
        "    # Count quoted text in email (assuming quoted text starts with \">\")\n",
        "    features['Quoted-text-in-a-Email'] = len(re.findall(r'^>.*$', text, re.MULTILINE))\n",
        "\n",
        "    # Count question marks in email\n",
        "    features['Question-Marks-in-a-Email'] = text.count('?')\n",
        "\n",
        "    # Count co-occurring words (words appearing next to each other, like bigrams)\n",
        "    bigrams = list(nltk.bigrams(words))\n",
        "    features['Number of co-occuring words'] = len(bigrams)\n",
        "\n",
        "    # Count the number of nouns in email\n",
        "    features['Number-of-noun'] = count_pos_tags(text, 'NN')\n",
        "\n",
        "    # Count spam lexicons in email\n",
        "    features['Spam lexicon'] = count_spam_lexicons(text, spam_lexicons)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction to the DataFrame\n",
        "df_features = df['text'].apply(extract_features).apply(pd.Series)\n",
        "\n",
        "# Concatenate the features with the original DataFrame\n",
        "final_csv = pd.concat([df, df_features], axis=1)\n",
        "final_csv.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "sO6ChBM4bPUt",
        "outputId": "20e4ea08-111d-4ed9-fb6e-54f8fc8b0eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text  Length-of-Email  \\\n",
              "0      1  ounce feather bowl hummingbird opec moment ala...              148   \n",
              "1      1  wulvob get your medircations online qnb ikud v...              808   \n",
              "2      0   computer connection from cnn com wednesday es...             2235   \n",
              "3      1  university degree obtain a prosperous future m...              592   \n",
              "4      0  thanks for all your answers guys i know i shou...             1362   \n",
              "\n",
              "   URLs-in-a-Email  Number of capitalized words  Repititive-Words-in-a-Email  \\\n",
              "0                0                            0                            0   \n",
              "1                0                            0                            5   \n",
              "2                0                            0                           61   \n",
              "3                0                            0                            5   \n",
              "4                0                            0                           38   \n",
              "\n",
              "   Uinque-Words-in-a-Email  Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "0                       20                       0                          0   \n",
              "1                       73                       0                          0   \n",
              "2                      180                       0                          0   \n",
              "3                       60                       0                          0   \n",
              "4                      123                       0                          0   \n",
              "\n",
              "   Number of co-occuring words  Number-of-noun  Spam lexicon  \n",
              "0                           19              17             0  \n",
              "1                          102              41             1  \n",
              "2                          336             156             3  \n",
              "3                           75              33             1  \n",
              "4                          221             106             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ffad729-b32d-4239-bb03-b7c662c9b5df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>URLs-in-a-Email</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Repititive-Words-in-a-Email</th>\n",
              "      <th>Uinque-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occuring words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>Spam lexicon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>wulvob get your medircations online qnb ikud v...</td>\n",
              "      <td>808</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>computer connection from cnn com wednesday es...</td>\n",
              "      <td>2235</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>336</td>\n",
              "      <td>156</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>university degree obtain a prosperous future m...</td>\n",
              "      <td>592</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>thanks for all your answers guys i know i shou...</td>\n",
              "      <td>1362</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>221</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ffad729-b32d-4239-bb03-b7c662c9b5df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ffad729-b32d-4239-bb03-b7c662c9b5df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ffad729-b32d-4239-bb03-b7c662c9b5df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-521249a2-be57-4113-afb1-7e779c3de277\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-521249a2-be57-4113-afb1-7e779c3de277')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-521249a2-be57-4113-afb1-7e779c3de277 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_csv",
              "summary": "{\n  \"name\": \"final_csv\",\n  \"rows\": 83448,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 83446,\n        \"samples\": [\n          \"so hard that he can't find time to write to his friends escapenumberf take good care of him aescapenumber aescapenumber they also threatened to destroy fire away then since you are up commanded frank tell him without words so hard that he can't find time to write to his friends escapenumberf take good care of him so hard that he can't find time to write to his friends escapenumberf take good care of him bat's word was law in some things so molly had to submit and took boo away bow aescapenumber aescapenumberas if he had outgrown them and wanted something manlier he took to the hated as if he had outgrown them and wanted something manlier he took to the hated aescapenumber aescapenumberdown workwomen but wishes us to pay them well and economize in some other the house if you feel sociable and your evenings are always free come to me him near her and flapped her fan vigorously whenever he was in sight which with a bucket of water are not pleased for charlie is too presuming and you do need someone to help instantly laid away for repairs and its disappointed maker devoted his energies to helping aescapenumber aescapenumberhead wisely listening to my moral remarks mrs laurence and laurie paused for amy's aescapenumber escapelong how does she behave escapenumberf asked phebe longing for news but too grateful ants when their hill is disturbed of course half a dozen amiable souls posted to have you get thin and pale you know peggy was a jolly lass how beautiful it is cried fanny the drawer took up the little gray book which was her pride thinking christie when her hostess returned and found her warmed refreshed aescapenumber aescapenumber don't then emil who had got his breath by this time gave aescapenumber aescapenumberthen giving a great spring he shot through the air and landed safely anguish as she cried was himself again but it was evident that his sufferings were not smile and agile motion of every limb old ben carried the bag in one soon to tell her all about it you are your active life has done much in some ways to make a man warming and fill the kettle i'll see to the boy commanded mrs aescapenumber aescapenumberat work the sewing room was quite irresistible and he made himself aescapenumber aescapenumbereye showed that his love trials did not quite blind him to the comic aunt looked sober at first but he was so cool about it she couldn't from heart disease and the slightest excitement might kill us if pat while he curried lita till her coat shone like satin then drove is absent template better for it though the memory of it is still bitter and the cross aescapenumber aescapenumber i find don't be a with an unsparing hand institution had not yet made its rules as fixed as the laws of the medes aescapenumber aescapenumberuncle henry smiled and cuddled his little niece\",\n          \"bull market report lescapenumberkup adovcurrent escapenumber escapenumber day target price escapenumber escapelong steadily climb for the top this sym is gaining momentum adov have released very hot news check this out theorize and call to your brocker right now \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length-of-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4178,\n        \"min\": 1,\n        \"max\": 598705,\n        \"num_unique_values\": 7956,\n        \"samples\": [\n          10353,\n          4789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URLs-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of capitalized words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repititive-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 0,\n        \"max\": 2675,\n        \"num_unique_values\": 614,\n        \"samples\": [\n          234\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Uinque-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 145,\n        \"min\": 1,\n        \"max\": 5182,\n        \"num_unique_values\": 1184,\n        \"samples\": [\n          338\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quoted-text-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 338,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question-Marks-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 3188,\n        \"num_unique_values\": 103,\n        \"samples\": [\n          33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of co-occuring words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 724,\n        \"min\": 0,\n        \"max\": 101983,\n        \"num_unique_values\": 2509,\n        \"samples\": [\n          3413\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number-of-noun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334,\n        \"min\": 0,\n        \"max\": 72546,\n        \"num_unique_values\": 1358,\n        \"samples\": [\n          73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 816,\n        \"num_unique_values\": 169,\n        \"samples\": [\n          134\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_csv.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "HpTguhoAjt5q",
        "outputId": "bb4bc9ec-c1ec-4a63-8de1-ba15900d00f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                               text  \\\n",
              "74236      1  for women ages 13 to 60 plus . . . .\\nas seen ...   \n",
              "49007      0  daniel hulme writes on fri jun escapenumber es...   \n",
              "10628      0  rick and sally\\ni told the scholarship winners...   \n",
              "45114      1  hallo\\nich danke dir fir deine liebe mail ich ...   \n",
              "78015      0  hi everyone when i was using cv lm daag i foun...   \n",
              "\n",
              "       Length-of-Email  URLs-in-a-Email  Number of capitalized words  \\\n",
              "74236              363                0                            0   \n",
              "49007              335                0                            0   \n",
              "10628             3145                0                            0   \n",
              "45114             1075                0                            0   \n",
              "78015             1486                0                            0   \n",
              "\n",
              "       Repititive-Words-in-a-Email  Uinque-Words-in-a-Email  \\\n",
              "74236                            9                       53   \n",
              "49007                            4                       34   \n",
              "10628                          101                      256   \n",
              "45114                           30                      133   \n",
              "78015                           47                      139   \n",
              "\n",
              "       Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "74236                       0                          0   \n",
              "49007                       0                          0   \n",
              "10628                       0                          2   \n",
              "45114                       0                          1   \n",
              "78015                       0                          0   \n",
              "\n",
              "       Number of co-occuring words  Number-of-noun  Spam lexicon  \n",
              "74236                           75              20             0  \n",
              "49007                           46              16             0  \n",
              "10628                          653             238             1  \n",
              "45114                          234             118             0  \n",
              "78015                          253             127             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f574d49a-786b-4e2d-8506-460e7231f82a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>URLs-in-a-Email</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Repititive-Words-in-a-Email</th>\n",
              "      <th>Uinque-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occuring words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>Spam lexicon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>74236</th>\n",
              "      <td>1</td>\n",
              "      <td>for women ages 13 to 60 plus . . . .\\nas seen ...</td>\n",
              "      <td>363</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49007</th>\n",
              "      <td>0</td>\n",
              "      <td>daniel hulme writes on fri jun escapenumber es...</td>\n",
              "      <td>335</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10628</th>\n",
              "      <td>0</td>\n",
              "      <td>rick and sally\\ni told the scholarship winners...</td>\n",
              "      <td>3145</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>256</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>653</td>\n",
              "      <td>238</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45114</th>\n",
              "      <td>1</td>\n",
              "      <td>hallo\\nich danke dir fir deine liebe mail ich ...</td>\n",
              "      <td>1075</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>133</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>234</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78015</th>\n",
              "      <td>0</td>\n",
              "      <td>hi everyone when i was using cv lm daag i foun...</td>\n",
              "      <td>1486</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>253</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f574d49a-786b-4e2d-8506-460e7231f82a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f574d49a-786b-4e2d-8506-460e7231f82a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f574d49a-786b-4e2d-8506-460e7231f82a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aba7b24e-1245-4ba1-a534-bd66a9dda359\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aba7b24e-1245-4ba1-a534-bd66a9dda359')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aba7b24e-1245-4ba1-a534-bd66a9dda359 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"final_csv\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"daniel hulme writes on fri jun escapenumber escapenumber at escapenumber escapenumber escapenumberpm escapenumber aaron crane wrote my b escapenumber escapenumber escapenumber now b is escapenumber s escapenumber escapenumber or vice versa i think uh yes serves me right for trying to change metasyntactic numbers midstream aaron crane\",\n          \"hi everyone when i was using cv lm daag i found there might be something wrong with it the problem is that we can't use it to deal with a linear model with more than one predictor variable but the usage documentation hasn't informed us about this you can find it by excuting the following code xx matrix rnorm escapenumber escapenumber ncol escapenumber bb c escapenumber escapenumber escapenumber yy xx bb rnorm escapenumber escapenumber escapenumber data data frame y yy x xx myformula formula y x escapenumber x escapenumber x escapenumber cv lm data myformula m escapenumber plotit f printit true myformula formula y x escapenumber x escapenumber cv lm data myformula m escapenumber plotit f printit true myformula formula y x escapenumber cv lm data myformula m escapenumber plotit f printit true what happened they give three equal mss mean squared error or you can just check the code of function cv lm daag then you will find the residues are all derived from a model with only one predictor but the coefficient of that only one predictor can be calculated from a model with more than one predictors which you've set in the formula term in cv lm daag junjie li klijunjie gmail com undergranduate in dep of tsinghua university alternative html version deleted r help stat math ethz ch mailing list https stat ethz ch mailman listinfo r help please do read the posting guide http www r project org posting guide html and provide commented minimal self contained reproducible code \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length-of-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1150,\n        \"min\": 335,\n        \"max\": 3145,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          335,\n          1486\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URLs-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of capitalized words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repititive-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39,\n        \"min\": 4,\n        \"max\": 101,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Uinque-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87,\n        \"min\": 34,\n        \"max\": 256,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quoted-text-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question-Marks-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of co-occuring words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 242,\n        \"min\": 46,\n        \"max\": 653,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number-of-noun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 91,\n        \"min\": 16,\n        \"max\": 238,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_csv.to_csv('1stpart.csv')"
      ],
      "metadata": {
        "id": "YcLJOB2pj6pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_csv['URLs-in-a-Email'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "McZfOjUpkKvY",
        "outputId": "06b46253-72d3-4f41-92b0-dd91278caadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "URLs-in-a-Email\n",
              "0    83448\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>URLs-in-a-Email</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>83448</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_csv['Number of capitalized words'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "nF5nrOwwka38",
        "outputId": "e6e16a62-7427-438f-a0c4-c0b496aa02d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Number of capitalized words\n",
              "0    83444\n",
              "1        2\n",
              "3        1\n",
              "2        1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>83444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to drop\n",
        "columns_to_drop = ['text', 'URLs-in-a-Email']\n",
        "\n",
        "# Drop the columns from the DataFrame\n",
        "final_csv = final_csv.drop(columns=columns_to_drop)\n"
      ],
      "metadata": {
        "id": "-cWjIZ4yl1GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_csv.to_csv('1stprt1.csv')"
      ],
      "metadata": {
        "id": "suMxQbCvmJoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "NUyjcnzKmc-l",
        "outputId": "071bca11-fa10-4a19-86b6-90a77124bbc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  Length-of-Email  Number of capitalized words  \\\n",
              "0      1              148                            0   \n",
              "1      1              808                            0   \n",
              "2      0             2235                            0   \n",
              "3      1              592                            0   \n",
              "4      0             1362                            0   \n",
              "\n",
              "   Repititive-Words-in-a-Email  Uinque-Words-in-a-Email  \\\n",
              "0                            0                       20   \n",
              "1                            5                       73   \n",
              "2                           61                      180   \n",
              "3                            5                       60   \n",
              "4                           38                      123   \n",
              "\n",
              "   Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "0                       0                          0   \n",
              "1                       0                          0   \n",
              "2                       0                          0   \n",
              "3                       0                          0   \n",
              "4                       0                          0   \n",
              "\n",
              "   Number of co-occuring words  Number-of-noun  Spam lexicon  \n",
              "0                           19              17             0  \n",
              "1                          102              41             1  \n",
              "2                          336             156             3  \n",
              "3                           75              33             1  \n",
              "4                          221             106             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27bf21bf-82ab-4d07-bc94-c4cae0651a17\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Repititive-Words-in-a-Email</th>\n",
              "      <th>Uinque-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occuring words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>Spam lexicon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>808</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2235</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>336</td>\n",
              "      <td>156</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>592</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1362</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>221</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27bf21bf-82ab-4d07-bc94-c4cae0651a17')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27bf21bf-82ab-4d07-bc94-c4cae0651a17 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27bf21bf-82ab-4d07-bc94-c4cae0651a17');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31aeeb26-2b24-42cf-ba28-1ec850f2f7aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31aeeb26-2b24-42cf-ba28-1ec850f2f7aa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31aeeb26-2b24-42cf-ba28-1ec850f2f7aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_csv",
              "summary": "{\n  \"name\": \"final_csv\",\n  \"rows\": 83448,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length-of-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4178,\n        \"min\": 1,\n        \"max\": 598705,\n        \"num_unique_values\": 7956,\n        \"samples\": [\n          10353,\n          4789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of capitalized words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repititive-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 0,\n        \"max\": 2675,\n        \"num_unique_values\": 614,\n        \"samples\": [\n          234,\n          946\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Uinque-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 145,\n        \"min\": 1,\n        \"max\": 5182,\n        \"num_unique_values\": 1184,\n        \"samples\": [\n          338,\n          1372\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quoted-text-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 338,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          28,\n          109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question-Marks-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 3188,\n        \"num_unique_values\": 103,\n        \"samples\": [\n          33,\n          1152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of co-occuring words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 724,\n        \"min\": 0,\n        \"max\": 101983,\n        \"num_unique_values\": 2509,\n        \"samples\": [\n          3413,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number-of-noun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334,\n        \"min\": 0,\n        \"max\": 72546,\n        \"num_unique_values\": 1358,\n        \"samples\": [\n          73,\n          1924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 816,\n        \"num_unique_values\": 169,\n        \"samples\": [\n          134,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTPecRz9XDfy",
        "outputId": "57b28c80-0c15-44f9-ff7d-0b23008454c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Function to clean and preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove email addresses\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove special characters and punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "\n",
        "    # Initialize the lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Lemmatize the tokens\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    # Join the tokens back into a single string\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "\n",
        "    return cleaned_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8pXrzCKZLA7"
      },
      "outputs": [],
      "source": [
        "# Apply the preprocess_text function to the 'email_text' column\n",
        "df['Cleaned_Text'] = df['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yChZA1hrhb48"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"new3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "tf2Hz4VTZRdv",
        "outputId": "1ce1ee12-413b-4ea5-f085-505218c02a09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ounce feather bowl hummingbird opec moment ala...\n",
              "1    wulvob get medircations online qnb ikud viagra...\n",
              "2    computer connection cnn com wednesday escapenu...\n",
              "3    university degree obtain prosperous future mon...\n",
              "4    thanks answer guy know checked rsync manual wo...\n",
              "Name: Cleaned_Text, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cleaned_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wulvob get medircations online qnb ikud viagra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>computer connection cnn com wednesday escapenu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>university degree obtain prosperous future mon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thanks answer guy know checked rsync manual wo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df['Cleaned_Text'].head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "\n",
        "# Download the VADER lexicon for sentiment analysis\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize VADER sentiment intensity analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to calculate semantic and sentiment features\n",
        "def compute_semantic_features(text):\n",
        "    features = {}\n",
        "\n",
        "    # VADER sentiment analysis\n",
        "    sentiment_scores = sia.polarity_scores(text)\n",
        "    features['Neg-Sentiment'] = sentiment_scores['neg']\n",
        "    features['Neu-Sentiment'] = sentiment_scores['neu']\n",
        "    features['Pos-Sentiment'] = sentiment_scores['pos']\n",
        "    features['Comp-Sentiment'] = sentiment_scores['compound']\n",
        "\n",
        "    # TextBlob sentiment analysis\n",
        "    blob = TextBlob(text)\n",
        "    features['Polarity'] = blob.sentiment.polarity\n",
        "    features['Subjective'] = blob.sentiment.subjectivity\n",
        "\n",
        "    return features\n",
        "\n",
        "# Example usage with a DataFrame\n",
        "# Assume `df` is your DataFrame containing the email text in a column named `Cleaned_Text`\n",
        "df_semantic_features = df['Cleaned_Text'].apply(compute_semantic_features).apply(pd.Series)\n",
        "\n",
        "# Concatenate the features with the original DataFrame\n",
        "df = pd.concat([df, df_semantic_features], axis=1)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('email_with_semantic_features.csv', index=False)\n",
        "\n",
        "print(\"Semantic and sentiment features extracted and saved to email_with_semantic_features.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw22aViD7Ehf",
        "outputId": "7d766075-3e37-4d3c-f89f-d23ef990b0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic and sentiment features extracted and saved to email_with_semantic_features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFf_mLp2lt1H",
        "outputId": "8f42fcd1-ddec-4cc6-907a-e48bf22e121e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features extracted and saved to 'extracted_features_emails_with_spam_user.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Load the cleaned dataset\n",
        "df = pd.read_csv('/content/clean.csv')\n",
        "\n",
        "# Initialize Sentiment Analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define a simple spam lexicon\n",
        "spam_lexicon = set([\n",
        "    'free', 'win', 'winner', 'prize', 'cash', 'guarantee', 'credit', 'urgent',\n",
        "    'limited', 'offer', 'click', 'buy', 'cheap', 'order', 'promo', 'congratulations'\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Function to extract features from text\n",
        "def extract_features(email):\n",
        "    text = email['Cleaned_Text']\n",
        "    features = {}\n",
        "\n",
        "    # 1. Length-of-Email\n",
        "    features['Length-of-Email'] = len(text)\n",
        "\n",
        "    # 2. URLs-in-a-Email\n",
        "    features['URLs-in-a-Email'] = len(re.findall(r'http\\S+|www\\S+', text))\n",
        "\n",
        "    # 3. Repetitive-Words-in-a-Email\n",
        "    words = word_tokenize(text)\n",
        "    word_counts = Counter(words)\n",
        "    repetitive_words = [word for word, count in word_counts.items() if count > 1]\n",
        "    features['Repetitive-Words-in-a-Email'] = len(repetitive_words)\n",
        "\n",
        "    # 4. Unique-Words-in-a-Email\n",
        "    unique_words = set(words)\n",
        "    features['Unique-Words-in-a-Email'] = len(unique_words)\n",
        "\n",
        "    # 5. Quoted-text-in-a-Email\n",
        "    features['Quoted-text-in-a-Email'] = len(re.findall(r'\\\"[^\\\"]*\\\"', text))\n",
        "\n",
        "    # 6. Question-Marks-in-a-Email\n",
        "    features['Question-Marks-in-a-Email'] = text.count('?')\n",
        "\n",
        "    # 7. Number of co-occurring words\n",
        "    features['Number of co-occurring words'] = len([word for word in words if words.count(word) > 1])\n",
        "\n",
        "    # 8. Number of capitalized words\n",
        "    features['Number of capitalized words'] = len([word for word in words if word.isupper()])\n",
        "\n",
        "    # 9. Number-of-noun\n",
        "    pos_tags = pos_tag(words)\n",
        "    nouns = [word for word, pos in pos_tags if pos.startswith('NN')]\n",
        "    features['Number-of-noun'] = len(nouns)\n",
        "\n",
        "    # 10. Semantic analysis - Placeholder\n",
        "    features['semantic'] = 'N/A'  # Replace with actual semantic analysis if needed\n",
        "\n",
        "    # 11-14. Sentiment Analysis\n",
        "    sentiment = sia.polarity_scores(text)\n",
        "    features['Neg-Sentiment'] = sentiment['neg']\n",
        "    features['Neu-Sentiment'] = sentiment['neu']\n",
        "    features['Pos-Sentiment'] = sentiment['pos']\n",
        "    features['Comp-Sentiment'] = sentiment['compound']\n",
        "\n",
        "    # 15. Spam lexicon analysis\n",
        "    spam_words = [word for word in words if word in spam_lexicon]\n",
        "    features['Spam lexicon'] = len(spam_words)\n",
        "\n",
        "\n",
        "\n",
        "    # 17. Polarity\n",
        "    polarity = TextBlob(text).sentiment.polarity\n",
        "    features['Polarity'] = polarity\n",
        "\n",
        "    # 18. Subjectivity\n",
        "    subjectivity = TextBlob(text).sentiment.subjectivity\n",
        "    features['Subjective'] = subjectivity\n",
        "\n",
        "    return features\n",
        "\n",
        "# Apply the feature extraction function to each email\n",
        "features_df = df.apply(extract_features, axis=1).apply(pd.Series)\n",
        "\n",
        "# Combine the features with the original DataFrame\n",
        "result_df = pd.concat([df, features_df], axis=1)\n",
        "\n",
        "# Save the result to a new CSV file\n",
        "result_df.to_csv('extracted_features_emails_with_spam_user.csv', index=False)\n",
        "\n",
        "print(\"Features extracted and saved to 'extracted_features_emails_with_spam_user.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idd94Hr6tJ7z"
      },
      "outputs": [],
      "source": [
        "df=result_df.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7qSGRQz030u",
        "outputId": "d3e8eb6d-b4cd-4cdb-e6fd-bd0b04a43a03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'label', 'text', 'Cleaned_Text', 'Length-of-Email',\n",
              "       'URLs-in-a-Email', 'Repetitive-Words-in-a-Email',\n",
              "       'Unique-Words-in-a-Email', 'Quoted-text-in-a-Email',\n",
              "       'Question-Marks-in-a-Email', 'Number of co-occurring words',\n",
              "       'Number of capitalized words', 'Number-of-noun', 'semantic',\n",
              "       'Neg-Sentiment', 'Neu-Sentiment', 'Pos-Sentiment', 'Comp-Sentiment',\n",
              "       'Spam lexicon', 'Polarity', 'Subjective'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "wOGqRrSh07Bc",
        "outputId": "b673b637-6939-45d8-d07a-162ab5a359aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39530</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "1    43891\n",
              "0    39530\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0vM6OVu1PME"
      },
      "outputs": [],
      "source": [
        "df.drop('Unnamed: 0',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALZcr4K91nHO",
        "outputId": "8a8cc5c4-681d-4a40-88e0-49419371feea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f9X3PYl1pl1",
        "outputId": "36fa9d8b-13e4-4947-d237-ad0e33b9420f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(83421, 20)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "3EBW4hTh1xTo",
        "outputId": "3afbc442-8c75-41b4-a6b3-cdfc9cefee95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 83421,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 83419,\n        \"samples\": [\n          \"rise and shine oem soft store escapenumber discounts www it soft download hk we are glad to present you this online software store with maximum lowest prices on the internet you won't find software anywhere else on the internet with prices lower th an here all the programs we have here for sale and available for download only ms windows vista business edition at only escapenumber escapenumber ms office escapenumber professional only escapenumber escapenumber adobe creative suite escapenumber design premium only escapenumber escapenumber systemworks premier escapenumber edt only escapenumber escapenumber and many more come and check out by yourself www it soft download hk yours sincerely burton cormier www it soft download hk\",\n          \"commit day turning grave books welcome glass corner gym promised or mentioned safe effective penisenlargement over escapenumber escapenumber escapenumber bottles sold worldwide weoffer a full money back guarantee if you are not completely satisfied with the results of man xl you have nothing to lose just a lot to gain a breakthrough in herbal science has created a pill that has been designed specifically for penisenlargement the tests that took place over a escapenumber month period showed that out of the escapenumber escapenumber males from around the world who participated the average gain after escapenumber months of taking man xl pills was escapenumber escapenumber inches amazing permanent results that will last did you know man xl was featured in leading mens magazines such as fhm maxim plus many others and rated no escapenumber choice forpenisenlargement also seen on tv gain up to escapenumber inches in length increase yourpenis width girth by upto escapenumber help stop escapelong produce stronger rock harderections escapenumber safe to take with no side effects fast shipping worldwide doctor approved and recommended no pumps no surgery no exercises very discrete shipping and billing escapenumber money back guarantee up to escapenumber free bottles of man xl highly secure escapenumberbit order processing see by yourself before after result by a customer buy this herbal enlargementpills here thinking quietly different god may surprise become added really science miserable miss board \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 81601,\n        \"samples\": [\n          \"received allocation deal purchase spinnaker sale dow volume actualized nothing volume management one look get back thanks joyce\",\n          \"dear customer usa web pharmacy expensive mexican web pharmacy sell fake medication order save money without risking health choose canadian quality matter expensive drug buy web still fake top canadian web pharmacy canadianpharmacy offer wide choice generic medication really low price youre looking cheap high quality medication visit canadianpharmacy right canadianpharmacy escapenumber source cheap generic drug canada sincerely candace tolbert\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length-of-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3441,\n        \"min\": 1,\n        \"max\": 581849,\n        \"num_unique_values\": 6772,\n        \"samples\": [\n          4220,\n          4187\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URLs-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repetitive-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 0,\n        \"max\": 2176,\n        \"num_unique_values\": 532,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unique-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 121,\n        \"min\": 1,\n        \"max\": 4327,\n        \"num_unique_values\": 1027,\n        \"samples\": [\n          457\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quoted-text-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question-Marks-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of co-occurring words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 463,\n        \"min\": 0,\n        \"max\": 97615,\n        \"num_unique_values\": 1583,\n        \"samples\": [\n          994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of capitalized words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number-of-noun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 331,\n        \"min\": 0,\n        \"max\": 74367,\n        \"num_unique_values\": 1316,\n        \"samples\": [\n          181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"semantic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"N/A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neg-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06153711262183712,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 458,\n        \"samples\": [\n          0.344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neu-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12359377327068606,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 731,\n        \"samples\": [\n          0.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pos-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10915010641293484,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 674,\n        \"samples\": [\n          0.541\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comp-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5516624816349067,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5642,\n        \"samples\": [\n          0.4058\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 167,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          47\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16745432210345848,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 35605,\n        \"samples\": [\n          0.009090909090909092\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18770613036936767,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 35397,\n        \"samples\": [\n          0.2628066378066378\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f1a6797e-23e2-4978-aeb5-64c76e518821\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>Cleaned_Text</th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>URLs-in-a-Email</th>\n",
              "      <th>Repetitive-Words-in-a-Email</th>\n",
              "      <th>Unique-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occurring words</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>semantic</th>\n",
              "      <th>Neg-Sentiment</th>\n",
              "      <th>Neu-Sentiment</th>\n",
              "      <th>Pos-Sentiment</th>\n",
              "      <th>Comp-Sentiment</th>\n",
              "      <th>Spam lexicon</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
              "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>wulvob get your medircations online qnb ikud v...</td>\n",
              "      <td>wulvob get medircations online qnb ikud viagra...</td>\n",
              "      <td>711</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>computer connection from cnn com wednesday es...</td>\n",
              "      <td>computer connection cnn com wednesday escapenu...</td>\n",
              "      <td>1962</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>162</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.9873</td>\n",
              "      <td>5</td>\n",
              "      <td>0.151120</td>\n",
              "      <td>0.308964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>university degree obtain a prosperous future m...</td>\n",
              "      <td>university degree obtain prosperous future mon...</td>\n",
              "      <td>499</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.8074</td>\n",
              "      <td>0</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>thanks for all your answers guys i know i shou...</td>\n",
              "      <td>thanks answer guy know checked rsync manual wo...</td>\n",
              "      <td>1079</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.205</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-0.9538</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.023958</td>\n",
              "      <td>0.591319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1a6797e-23e2-4978-aeb5-64c76e518821')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f1a6797e-23e2-4978-aeb5-64c76e518821 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f1a6797e-23e2-4978-aeb5-64c76e518821');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09459a14-cd85-4741-be2f-1ae1b005fc4b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09459a14-cd85-4741-be2f-1ae1b005fc4b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09459a14-cd85-4741-be2f-1ae1b005fc4b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   label                                               text  \\\n",
              "0      1  ounce feather bowl hummingbird opec moment ala...   \n",
              "1      1  wulvob get your medircations online qnb ikud v...   \n",
              "2      0   computer connection from cnn com wednesday es...   \n",
              "3      1  university degree obtain a prosperous future m...   \n",
              "4      0  thanks for all your answers guys i know i shou...   \n",
              "\n",
              "                                        Cleaned_Text  Length-of-Email  \\\n",
              "0  ounce feather bowl hummingbird opec moment ala...              148   \n",
              "1  wulvob get medircations online qnb ikud viagra...              711   \n",
              "2  computer connection cnn com wednesday escapenu...             1962   \n",
              "3  university degree obtain prosperous future mon...              499   \n",
              "4  thanks answer guy know checked rsync manual wo...             1079   \n",
              "\n",
              "   URLs-in-a-Email  Repetitive-Words-in-a-Email  Unique-Words-in-a-Email  \\\n",
              "0                0                            0                       20   \n",
              "1                0                            1                       53   \n",
              "2                0                           48                      143   \n",
              "3                0                            2                       44   \n",
              "4                0                           27                       93   \n",
              "\n",
              "   Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "0                       0                          0   \n",
              "1                       0                          0   \n",
              "2                       0                          0   \n",
              "3                       0                          0   \n",
              "4                       0                          0   \n",
              "\n",
              "   Number of co-occurring words  Number of capitalized words  Number-of-noun  \\\n",
              "0                             0                            0              17   \n",
              "1                            27                            0              41   \n",
              "2                           180                            0             162   \n",
              "3                            13                            0              26   \n",
              "4                            90                            0              71   \n",
              "\n",
              "  semantic  Neg-Sentiment  Neu-Sentiment  Pos-Sentiment  Comp-Sentiment  \\\n",
              "0      N/A          0.108          0.892          0.000         -0.3182   \n",
              "1      N/A          0.076          0.890          0.034         -0.3612   \n",
              "2      N/A          0.000          0.872          0.128          0.9873   \n",
              "3      N/A          0.000          0.862          0.138          0.8074   \n",
              "4      N/A          0.205          0.749          0.046         -0.9538   \n",
              "\n",
              "   Spam lexicon  Polarity  Subjective  \n",
              "0             0 -0.600000    1.000000  \n",
              "1             0 -0.012500    0.375000  \n",
              "2             5  0.151120    0.308964  \n",
              "3             0  0.033333    0.075000  \n",
              "4             0 -0.023958    0.591319  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMlRDUtG2BSn"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"final.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuJnnb9c2RbH"
      },
      "outputs": [],
      "source": [
        "df.drop(\"semantic\",axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5wLuPdcbkA2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/final.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "LblznZzr2lWy",
        "outputId": "cee6de3a-b8ce-4a6a-bebc-e44bc2258dc7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-cdfa32a8-228a-4f89-8030-777da0a86c4f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>Cleaned_Text</th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>URLs-in-a-Email</th>\n",
              "      <th>Repetitive-Words-in-a-Email</th>\n",
              "      <th>Unique-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>...</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>semantic</th>\n",
              "      <th>Neg-Sentiment</th>\n",
              "      <th>Neu-Sentiment</th>\n",
              "      <th>Pos-Sentiment</th>\n",
              "      <th>Comp-Sentiment</th>\n",
              "      <th>Spam lexicon</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
              "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>wulvob get your medircations online qnb ikud v...</td>\n",
              "      <td>wulvob get medircations online qnb ikud viagra...</td>\n",
              "      <td>711</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>computer connection from cnn com wednesday es...</td>\n",
              "      <td>computer connection cnn com wednesday escapenu...</td>\n",
              "      <td>1962</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>162</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.9873</td>\n",
              "      <td>5</td>\n",
              "      <td>0.151120</td>\n",
              "      <td>0.308964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>university degree obtain a prosperous future m...</td>\n",
              "      <td>university degree obtain prosperous future mon...</td>\n",
              "      <td>499</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.8074</td>\n",
              "      <td>0</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>thanks for all your answers guys i know i shou...</td>\n",
              "      <td>thanks answer guy know checked rsync manual wo...</td>\n",
              "      <td>1079</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.205</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-0.9538</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.023958</td>\n",
              "      <td>0.591319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdfa32a8-228a-4f89-8030-777da0a86c4f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cdfa32a8-228a-4f89-8030-777da0a86c4f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cdfa32a8-228a-4f89-8030-777da0a86c4f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8180f8b0-adee-4d8f-a53c-3589263e7243\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8180f8b0-adee-4d8f-a53c-3589263e7243')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8180f8b0-adee-4d8f-a53c-3589263e7243 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Unnamed: 0  label                                               text  \\\n",
              "0           0      1  ounce feather bowl hummingbird opec moment ala...   \n",
              "1           1      1  wulvob get your medircations online qnb ikud v...   \n",
              "2           2      0   computer connection from cnn com wednesday es...   \n",
              "3           3      1  university degree obtain a prosperous future m...   \n",
              "4           4      0  thanks for all your answers guys i know i shou...   \n",
              "\n",
              "                                        Cleaned_Text  Length-of-Email  \\\n",
              "0  ounce feather bowl hummingbird opec moment ala...              148   \n",
              "1  wulvob get medircations online qnb ikud viagra...              711   \n",
              "2  computer connection cnn com wednesday escapenu...             1962   \n",
              "3  university degree obtain prosperous future mon...              499   \n",
              "4  thanks answer guy know checked rsync manual wo...             1079   \n",
              "\n",
              "   URLs-in-a-Email  Repetitive-Words-in-a-Email  Unique-Words-in-a-Email  \\\n",
              "0                0                            0                       20   \n",
              "1                0                            1                       53   \n",
              "2                0                           48                      143   \n",
              "3                0                            2                       44   \n",
              "4                0                           27                       93   \n",
              "\n",
              "   Quoted-text-in-a-Email  Question-Marks-in-a-Email  ...  \\\n",
              "0                       0                          0  ...   \n",
              "1                       0                          0  ...   \n",
              "2                       0                          0  ...   \n",
              "3                       0                          0  ...   \n",
              "4                       0                          0  ...   \n",
              "\n",
              "   Number of capitalized words  Number-of-noun  semantic  Neg-Sentiment  \\\n",
              "0                            0              17       NaN          0.108   \n",
              "1                            0              41       NaN          0.076   \n",
              "2                            0             162       NaN          0.000   \n",
              "3                            0              26       NaN          0.000   \n",
              "4                            0              71       NaN          0.205   \n",
              "\n",
              "   Neu-Sentiment  Pos-Sentiment  Comp-Sentiment  Spam lexicon  Polarity  \\\n",
              "0          0.892          0.000         -0.3182             0 -0.600000   \n",
              "1          0.890          0.034         -0.3612             0 -0.012500   \n",
              "2          0.872          0.128          0.9873             5  0.151120   \n",
              "3          0.862          0.138          0.8074             0  0.033333   \n",
              "4          0.749          0.046         -0.9538             0 -0.023958   \n",
              "\n",
              "   Subjective  \n",
              "0    1.000000  \n",
              "1    0.375000  \n",
              "2    0.308964  \n",
              "3    0.075000  \n",
              "4    0.591319  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsEW0SDW2nCV"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['text', 'Cleaned_Text',\t'Unnamed: 0', 'semantic'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFDNFb1OuD6c",
        "outputId": "76fa323b-b01f-4f53-c324-f324dc712287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "N84tI-_H3hMf",
        "outputId": "30e6c832-6e52-4d61-eb56-ad600ee3d920"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 83421,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length-of-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3441,\n        \"min\": 1,\n        \"max\": 581849,\n        \"num_unique_values\": 6772,\n        \"samples\": [\n          4220,\n          4187\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URLs-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repetitive-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 0,\n        \"max\": 2176,\n        \"num_unique_values\": 532,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unique-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 121,\n        \"min\": 1,\n        \"max\": 4327,\n        \"num_unique_values\": 1027,\n        \"samples\": [\n          457\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quoted-text-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question-Marks-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of co-occurring words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 463,\n        \"min\": 0,\n        \"max\": 97615,\n        \"num_unique_values\": 1583,\n        \"samples\": [\n          994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of capitalized words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number-of-noun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 331,\n        \"min\": 0,\n        \"max\": 74367,\n        \"num_unique_values\": 1316,\n        \"samples\": [\n          181\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neg-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06153711262183712,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 458,\n        \"samples\": [\n          0.344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neu-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12359377327068606,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 731,\n        \"samples\": [\n          0.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pos-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10915010641293484,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 674,\n        \"samples\": [\n          0.541\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comp-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5516624816349067,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5642,\n        \"samples\": [\n          0.4058\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 167,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          47\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16745432210345848,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 30980,\n        \"samples\": [\n          0.1641666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1877061303693677,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 34053,\n        \"samples\": [\n          0.3962745098039215\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-18374d69-127c-4280-adc2-63588ce0a71c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>URLs-in-a-Email</th>\n",
              "      <th>Repetitive-Words-in-a-Email</th>\n",
              "      <th>Unique-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occurring words</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>Neg-Sentiment</th>\n",
              "      <th>Neu-Sentiment</th>\n",
              "      <th>Pos-Sentiment</th>\n",
              "      <th>Comp-Sentiment</th>\n",
              "      <th>Spam lexicon</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>711</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1962</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>162</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.9873</td>\n",
              "      <td>5</td>\n",
              "      <td>0.151120</td>\n",
              "      <td>0.308964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>499</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.8074</td>\n",
              "      <td>0</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1079</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>0.205</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-0.9538</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.023958</td>\n",
              "      <td>0.591319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18374d69-127c-4280-adc2-63588ce0a71c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18374d69-127c-4280-adc2-63588ce0a71c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18374d69-127c-4280-adc2-63588ce0a71c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8af5e218-9058-4432-9d2d-acd66bf78f09\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8af5e218-9058-4432-9d2d-acd66bf78f09')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8af5e218-9058-4432-9d2d-acd66bf78f09 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   label  Length-of-Email  URLs-in-a-Email  Repetitive-Words-in-a-Email  \\\n",
              "0      1              148                0                            0   \n",
              "1      1              711                0                            1   \n",
              "2      0             1962                0                           48   \n",
              "3      1              499                0                            2   \n",
              "4      0             1079                0                           27   \n",
              "\n",
              "   Unique-Words-in-a-Email  Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "0                       20                       0                          0   \n",
              "1                       53                       0                          0   \n",
              "2                      143                       0                          0   \n",
              "3                       44                       0                          0   \n",
              "4                       93                       0                          0   \n",
              "\n",
              "   Number of co-occurring words  Number of capitalized words  Number-of-noun  \\\n",
              "0                             0                            0              17   \n",
              "1                            27                            0              41   \n",
              "2                           180                            0             162   \n",
              "3                            13                            0              26   \n",
              "4                            90                            0              71   \n",
              "\n",
              "   Neg-Sentiment  Neu-Sentiment  Pos-Sentiment  Comp-Sentiment  Spam lexicon  \\\n",
              "0          0.108          0.892          0.000         -0.3182             0   \n",
              "1          0.076          0.890          0.034         -0.3612             0   \n",
              "2          0.000          0.872          0.128          0.9873             5   \n",
              "3          0.000          0.862          0.138          0.8074             0   \n",
              "4          0.205          0.749          0.046         -0.9538             0   \n",
              "\n",
              "   Polarity  Subjective  \n",
              "0 -0.600000    1.000000  \n",
              "1 -0.012500    0.375000  \n",
              "2  0.151120    0.308964  \n",
              "3  0.033333    0.075000  \n",
              "4 -0.023958    0.591319  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/1stprt1.csv')\n",
        "df1=pd.read_csv('/content/email_with_semantic_features.csv')\n",
        "df2=pd.read_csv('/content/new3.csv')"
      ],
      "metadata": {
        "id": "SF_RiWk8YNNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "k0d88TfgZIED",
        "outputId": "67ad1892-a453-4e5b-f449-812ef2ae2fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  label  Length-of-Email  Number of capitalized words  \\\n",
              "0           0      1              148                            0   \n",
              "1           1      1              808                            0   \n",
              "2           2      0             2235                            0   \n",
              "3           3      1              592                            0   \n",
              "4           4      0             1362                            0   \n",
              "\n",
              "   Repititive-Words-in-a-Email  Uinque-Words-in-a-Email  \\\n",
              "0                            0                       20   \n",
              "1                            5                       73   \n",
              "2                           61                      180   \n",
              "3                            5                       60   \n",
              "4                           38                      123   \n",
              "\n",
              "   Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "0                       0                          0   \n",
              "1                       0                          0   \n",
              "2                       0                          0   \n",
              "3                       0                          0   \n",
              "4                       0                          0   \n",
              "\n",
              "   Number of co-occuring words  Number-of-noun  Spam lexicon  \n",
              "0                           19              17             0  \n",
              "1                          102              41             1  \n",
              "2                          336             156             3  \n",
              "3                           75              33             1  \n",
              "4                          221             106             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcc22387-64e2-4ea0-8a45-66f79ca5fe44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Repititive-Words-in-a-Email</th>\n",
              "      <th>Uinque-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occuring words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>Spam lexicon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>808</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2235</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>336</td>\n",
              "      <td>156</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>592</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1362</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>221</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcc22387-64e2-4ea0-8a45-66f79ca5fe44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcc22387-64e2-4ea0-8a45-66f79ca5fe44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcc22387-64e2-4ea0-8a45-66f79ca5fe44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0e41c5c5-802b-42d4-9c6b-0b189bf611a9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e41c5c5-802b-42d4-9c6b-0b189bf611a9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0e41c5c5-802b-42d4-9c6b-0b189bf611a9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 83448,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24089,\n        \"min\": 0,\n        \"max\": 83447,\n        \"num_unique_values\": 83448,\n        \"samples\": [\n          67681,\n          61385,\n          41829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length-of-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4178,\n        \"min\": 1,\n        \"max\": 598705,\n        \"num_unique_values\": 7956,\n        \"samples\": [\n          10353,\n          4789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of capitalized words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repititive-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 0,\n        \"max\": 2675,\n        \"num_unique_values\": 614,\n        \"samples\": [\n          234,\n          946\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Uinque-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 145,\n        \"min\": 1,\n        \"max\": 5182,\n        \"num_unique_values\": 1184,\n        \"samples\": [\n          338,\n          1372\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quoted-text-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 338,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          28,\n          109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question-Marks-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 3188,\n        \"num_unique_values\": 103,\n        \"samples\": [\n          33,\n          1152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of co-occuring words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 724,\n        \"min\": 0,\n        \"max\": 101983,\n        \"num_unique_values\": 2509,\n        \"samples\": [\n          3413,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number-of-noun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334,\n        \"min\": 0,\n        \"max\": 72546,\n        \"num_unique_values\": 1358,\n        \"samples\": [\n          73,\n          1924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 816,\n        \"num_unique_values\": 169,\n        \"samples\": [\n          134,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Unnamed: 0','label'], axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "g0uhsLQUfkd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVWALqjkfvOP",
        "outputId": "5f4431bb-d16f-4377-8213-d27a134a331d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Length-of-Email', 'Number of capitalized words',\n",
              "       'Repititive-Words-in-a-Email', 'Uinque-Words-in-a-Email',\n",
              "       'Quoted-text-in-a-Email', 'Question-Marks-in-a-Email',\n",
              "       'Number of co-occuring words', 'Number-of-noun', 'Spam lexicon'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "u507qBfBZSoI",
        "outputId": "41fb51e8-54e1-4af9-b29f-0c919eb5ef90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text  \\\n",
              "0      1  ounce feather bowl hummingbird opec moment ala...   \n",
              "1      1  wulvob get your medircations online qnb ikud v...   \n",
              "2      0   computer connection from cnn com wednesday es...   \n",
              "3      1  university degree obtain a prosperous future m...   \n",
              "4      0  thanks for all your answers guys i know i shou...   \n",
              "\n",
              "                                        Cleaned_Text  Neg-Sentiment  \\\n",
              "0  ounce feather bowl hummingbird opec moment ala...          0.108   \n",
              "1  wulvob get medircations online qnb ikud viagra...          0.076   \n",
              "2  computer connection cnn com wednesday escapenu...          0.000   \n",
              "3  university degree obtain prosperous future mon...          0.000   \n",
              "4  thanks answer guy know checked rsync manual wo...          0.205   \n",
              "\n",
              "   Neu-Sentiment  Pos-Sentiment  Comp-Sentiment  Polarity  Subjective  \n",
              "0          0.892          0.000         -0.3182 -0.600000    1.000000  \n",
              "1          0.890          0.034         -0.3612 -0.012500    0.375000  \n",
              "2          0.872          0.128          0.9873  0.151120    0.308964  \n",
              "3          0.862          0.138          0.8074  0.033333    0.075000  \n",
              "4          0.749          0.046         -0.9538 -0.023958    0.591319  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4000b4f8-8e7d-4a0b-a4f3-4b4d546e2e5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>Cleaned_Text</th>\n",
              "      <th>Neg-Sentiment</th>\n",
              "      <th>Neu-Sentiment</th>\n",
              "      <th>Pos-Sentiment</th>\n",
              "      <th>Comp-Sentiment</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
              "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>wulvob get your medircations online qnb ikud v...</td>\n",
              "      <td>wulvob get medircations online qnb ikud viagra...</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>computer connection from cnn com wednesday es...</td>\n",
              "      <td>computer connection cnn com wednesday escapenu...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.9873</td>\n",
              "      <td>0.151120</td>\n",
              "      <td>0.308964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>university degree obtain a prosperous future m...</td>\n",
              "      <td>university degree obtain prosperous future mon...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.8074</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>thanks for all your answers guys i know i shou...</td>\n",
              "      <td>thanks answer guy know checked rsync manual wo...</td>\n",
              "      <td>0.205</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-0.9538</td>\n",
              "      <td>-0.023958</td>\n",
              "      <td>0.591319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4000b4f8-8e7d-4a0b-a4f3-4b4d546e2e5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4000b4f8-8e7d-4a0b-a4f3-4b4d546e2e5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4000b4f8-8e7d-4a0b-a4f3-4b4d546e2e5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0bae34ac-4b74-431a-8494-353d0343a295\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0bae34ac-4b74-431a-8494-353d0343a295')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0bae34ac-4b74-431a-8494-353d0343a295 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 83448,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 83446,\n        \"samples\": [\n          \"so hard that he can't find time to write to his friends escapenumberf take good care of him aescapenumber aescapenumber they also threatened to destroy fire away then since you are up commanded frank tell him without words so hard that he can't find time to write to his friends escapenumberf take good care of him so hard that he can't find time to write to his friends escapenumberf take good care of him bat's word was law in some things so molly had to submit and took boo away bow aescapenumber aescapenumberas if he had outgrown them and wanted something manlier he took to the hated as if he had outgrown them and wanted something manlier he took to the hated aescapenumber aescapenumberdown workwomen but wishes us to pay them well and economize in some other the house if you feel sociable and your evenings are always free come to me him near her and flapped her fan vigorously whenever he was in sight which with a bucket of water are not pleased for charlie is too presuming and you do need someone to help instantly laid away for repairs and its disappointed maker devoted his energies to helping aescapenumber aescapenumberhead wisely listening to my moral remarks mrs laurence and laurie paused for amy's aescapenumber escapelong how does she behave escapenumberf asked phebe longing for news but too grateful ants when their hill is disturbed of course half a dozen amiable souls posted to have you get thin and pale you know peggy was a jolly lass how beautiful it is cried fanny the drawer took up the little gray book which was her pride thinking christie when her hostess returned and found her warmed refreshed aescapenumber aescapenumber don't then emil who had got his breath by this time gave aescapenumber aescapenumberthen giving a great spring he shot through the air and landed safely anguish as she cried was himself again but it was evident that his sufferings were not smile and agile motion of every limb old ben carried the bag in one soon to tell her all about it you are your active life has done much in some ways to make a man warming and fill the kettle i'll see to the boy commanded mrs aescapenumber aescapenumberat work the sewing room was quite irresistible and he made himself aescapenumber aescapenumbereye showed that his love trials did not quite blind him to the comic aunt looked sober at first but he was so cool about it she couldn't from heart disease and the slightest excitement might kill us if pat while he curried lita till her coat shone like satin then drove is absent template better for it though the memory of it is still bitter and the cross aescapenumber aescapenumber i find don't be a with an unsparing hand institution had not yet made its rules as fixed as the laws of the medes aescapenumber aescapenumberuncle henry smiled and cuddled his little niece\",\n          \"bull market report lescapenumberkup adovcurrent escapenumber escapenumber day target price escapenumber escapelong steadily climb for the top this sym is gaining momentum adov have released very hot news check this out theorize and call to your brocker right now \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 81601,\n        \"samples\": [\n          \"received allocation deal purchase spinnaker sale dow volume actualized nothing volume management one look get back thanks joyce\",\n          \"dear customer usa web pharmacy expensive mexican web pharmacy sell fake medication order save money without risking health choose canadian quality matter expensive drug buy web still fake top canadian web pharmacy canadianpharmacy offer wide choice generic medication really low price youre looking cheap high quality medication visit canadianpharmacy right canadianpharmacy escapenumber source cheap generic drug canada sincerely candace tolbert\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neg-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061534251444246235,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 458,\n        \"samples\": [\n          0.344,\n          0.055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neu-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12437377692924996,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 731,\n        \"samples\": [\n          0.39,\n          0.791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pos-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10917272072015846,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 674,\n        \"samples\": [\n          0.541,\n          0.217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comp-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5516671967906014,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5642,\n        \"samples\": [\n          0.4058,\n          0.687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1674412025145324,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 30980,\n        \"samples\": [\n          0.1641666666666666,\n          0.1810064935064934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18782995916813944,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 34053,\n        \"samples\": [\n          0.3962745098039215,\n          0.5379629629629631\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(columns=['text','Cleaned_Text'], axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "qRKUHDI3f16a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns"
      ],
      "metadata": {
        "outputId": "34415d9c-f6c6-46e9-f866-dacfd1b17bc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yngVxjCGf16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['label', 'Neg-Sentiment', 'Neu-Sentiment', 'Pos-Sentiment',\n",
              "       'Comp-Sentiment', 'Polarity', 'Subjective'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "SZvALndcZYyq",
        "outputId": "8e7d8372-aa87-4446-d69d-6d51c8c4c750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  label                                               text  \\\n",
              "0           0      1  ounce feather bowl hummingbird opec moment ala...   \n",
              "1           1      1  wulvob get your medircations online qnb ikud v...   \n",
              "2           2      0   computer connection from cnn com wednesday es...   \n",
              "3           3      1  university degree obtain a prosperous future m...   \n",
              "4           4      0  thanks for all your answers guys i know i shou...   \n",
              "\n",
              "                                        Cleaned_Text  \n",
              "0  ounce feather bowl hummingbird opec moment ala...  \n",
              "1  wulvob get medircations online qnb ikud viagra...  \n",
              "2  computer connection cnn com wednesday escapenu...  \n",
              "3  university degree obtain prosperous future mon...  \n",
              "4  thanks answer guy know checked rsync manual wo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42c3a321-b9b1-4a79-b203-bf31a95a1194\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>Cleaned_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
              "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>wulvob get your medircations online qnb ikud v...</td>\n",
              "      <td>wulvob get medircations online qnb ikud viagra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>computer connection from cnn com wednesday es...</td>\n",
              "      <td>computer connection cnn com wednesday escapenu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>university degree obtain a prosperous future m...</td>\n",
              "      <td>university degree obtain prosperous future mon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>thanks for all your answers guys i know i shou...</td>\n",
              "      <td>thanks answer guy know checked rsync manual wo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42c3a321-b9b1-4a79-b203-bf31a95a1194')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42c3a321-b9b1-4a79-b203-bf31a95a1194 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42c3a321-b9b1-4a79-b203-bf31a95a1194');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9918e37e-43e0-43ea-b456-681d124c1411\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9918e37e-43e0-43ea-b456-681d124c1411')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9918e37e-43e0-43ea-b456-681d124c1411 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 83448,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24089,\n        \"min\": 0,\n        \"max\": 83447,\n        \"num_unique_values\": 83448,\n        \"samples\": [\n          67681,\n          61385,\n          41829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 83446,\n        \"samples\": [\n          \"so hard that he can't find time to write to his friends escapenumberf take good care of him aescapenumber aescapenumber they also threatened to destroy fire away then since you are up commanded frank tell him without words so hard that he can't find time to write to his friends escapenumberf take good care of him so hard that he can't find time to write to his friends escapenumberf take good care of him bat's word was law in some things so molly had to submit and took boo away bow aescapenumber aescapenumberas if he had outgrown them and wanted something manlier he took to the hated as if he had outgrown them and wanted something manlier he took to the hated aescapenumber aescapenumberdown workwomen but wishes us to pay them well and economize in some other the house if you feel sociable and your evenings are always free come to me him near her and flapped her fan vigorously whenever he was in sight which with a bucket of water are not pleased for charlie is too presuming and you do need someone to help instantly laid away for repairs and its disappointed maker devoted his energies to helping aescapenumber aescapenumberhead wisely listening to my moral remarks mrs laurence and laurie paused for amy's aescapenumber escapelong how does she behave escapenumberf asked phebe longing for news but too grateful ants when their hill is disturbed of course half a dozen amiable souls posted to have you get thin and pale you know peggy was a jolly lass how beautiful it is cried fanny the drawer took up the little gray book which was her pride thinking christie when her hostess returned and found her warmed refreshed aescapenumber aescapenumber don't then emil who had got his breath by this time gave aescapenumber aescapenumberthen giving a great spring he shot through the air and landed safely anguish as she cried was himself again but it was evident that his sufferings were not smile and agile motion of every limb old ben carried the bag in one soon to tell her all about it you are your active life has done much in some ways to make a man warming and fill the kettle i'll see to the boy commanded mrs aescapenumber aescapenumberat work the sewing room was quite irresistible and he made himself aescapenumber aescapenumbereye showed that his love trials did not quite blind him to the comic aunt looked sober at first but he was so cool about it she couldn't from heart disease and the slightest excitement might kill us if pat while he curried lita till her coat shone like satin then drove is absent template better for it though the memory of it is still bitter and the cross aescapenumber aescapenumber i find don't be a with an unsparing hand institution had not yet made its rules as fixed as the laws of the medes aescapenumber aescapenumberuncle henry smiled and cuddled his little niece\",\n          \"bull market report lescapenumberkup adovcurrent escapenumber escapenumber day target price escapenumber escapelong steadily climb for the top this sym is gaining momentum adov have released very hot news check this out theorize and call to your brocker right now \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 81601,\n        \"samples\": [\n          \"received allocation deal purchase spinnaker sale dow volume actualized nothing volume management one look get back thanks joyce\",\n          \"dear customer usa web pharmacy expensive mexican web pharmacy sell fake medication order save money without risking health choose canadian quality matter expensive drug buy web still fake top canadian web pharmacy canadianpharmacy offer wide choice generic medication really low price youre looking cheap high quality medication visit canadianpharmacy right canadianpharmacy escapenumber source cheap generic drug canada sincerely candace tolbert\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.concat([df, df1], axis=1)\n"
      ],
      "metadata": {
        "id": "aX_ihR5_Z2vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "2h65i_qQZ6PR",
        "outputId": "f16fa936-ff6b-4646-9f36-d09a3449dcda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Length-of-Email  Number of capitalized words  Repititive-Words-in-a-Email  \\\n",
              "0              148                            0                            0   \n",
              "1              808                            0                            5   \n",
              "2             2235                            0                           61   \n",
              "3              592                            0                            5   \n",
              "4             1362                            0                           38   \n",
              "\n",
              "   Uinque-Words-in-a-Email  Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "0                       20                       0                          0   \n",
              "1                       73                       0                          0   \n",
              "2                      180                       0                          0   \n",
              "3                       60                       0                          0   \n",
              "4                      123                       0                          0   \n",
              "\n",
              "   Number of co-occuring words  Number-of-noun  Spam lexicon  label  \\\n",
              "0                           19              17             0      1   \n",
              "1                          102              41             1      1   \n",
              "2                          336             156             3      0   \n",
              "3                           75              33             1      1   \n",
              "4                          221             106             0      0   \n",
              "\n",
              "   Neg-Sentiment  Neu-Sentiment  Pos-Sentiment  Comp-Sentiment  Polarity  \\\n",
              "0          0.108          0.892          0.000         -0.3182 -0.600000   \n",
              "1          0.076          0.890          0.034         -0.3612 -0.012500   \n",
              "2          0.000          0.872          0.128          0.9873  0.151120   \n",
              "3          0.000          0.862          0.138          0.8074  0.033333   \n",
              "4          0.205          0.749          0.046         -0.9538 -0.023958   \n",
              "\n",
              "   Subjective  \n",
              "0    1.000000  \n",
              "1    0.375000  \n",
              "2    0.308964  \n",
              "3    0.075000  \n",
              "4    0.591319  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cb8a78b-f436-4360-80bf-1e001c666064\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Repititive-Words-in-a-Email</th>\n",
              "      <th>Uinque-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occuring words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>Spam lexicon</th>\n",
              "      <th>label</th>\n",
              "      <th>Neg-Sentiment</th>\n",
              "      <th>Neu-Sentiment</th>\n",
              "      <th>Pos-Sentiment</th>\n",
              "      <th>Comp-Sentiment</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>808</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2235</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>180</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>336</td>\n",
              "      <td>156</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.9873</td>\n",
              "      <td>0.151120</td>\n",
              "      <td>0.308964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>592</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.8074</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.075000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1362</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>221</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.205</td>\n",
              "      <td>0.749</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-0.9538</td>\n",
              "      <td>-0.023958</td>\n",
              "      <td>0.591319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cb8a78b-f436-4360-80bf-1e001c666064')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cb8a78b-f436-4360-80bf-1e001c666064 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cb8a78b-f436-4360-80bf-1e001c666064');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-00713898-80e8-4f44-844f-09521211500d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00713898-80e8-4f44-844f-09521211500d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-00713898-80e8-4f44-844f-09521211500d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result",
              "summary": "{\n  \"name\": \"result\",\n  \"rows\": 83448,\n  \"fields\": [\n    {\n      \"column\": \"Length-of-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4178,\n        \"min\": 1,\n        \"max\": 598705,\n        \"num_unique_values\": 7956,\n        \"samples\": [\n          10353,\n          4789,\n          177\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of capitalized words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repititive-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 0,\n        \"max\": 2675,\n        \"num_unique_values\": 614,\n        \"samples\": [\n          234,\n          946,\n          147\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Uinque-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 145,\n        \"min\": 1,\n        \"max\": 5182,\n        \"num_unique_values\": 1184,\n        \"samples\": [\n          338,\n          1372,\n          971\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quoted-text-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 338,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          28,\n          109,\n          53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question-Marks-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 3188,\n        \"num_unique_values\": 103,\n        \"samples\": [\n          33,\n          1152,\n          333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of co-occuring words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 724,\n        \"min\": 0,\n        \"max\": 101983,\n        \"num_unique_values\": 2509,\n        \"samples\": [\n          3413,\n          44,\n          991\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number-of-noun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334,\n        \"min\": 0,\n        \"max\": 72546,\n        \"num_unique_values\": 1358,\n        \"samples\": [\n          73,\n          1924,\n          1274\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 816,\n        \"num_unique_values\": 169,\n        \"samples\": [\n          134,\n          17,\n          107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neg-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061534251444246235,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 458,\n        \"samples\": [\n          0.344,\n          0.055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neu-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12437377692924996,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 731,\n        \"samples\": [\n          0.39,\n          0.791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pos-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10917272072015846,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 674,\n        \"samples\": [\n          0.541,\n          0.217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comp-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5516671967906014,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5642,\n        \"samples\": [\n          0.4058,\n          0.687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1674412025145324,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 30980,\n        \"samples\": [\n          0.1641666666666666,\n          0.1810064935064934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18782995916813944,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 34053,\n        \"samples\": [\n          0.3962745098039215,\n          0.5379629629629631\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQYoZU9sdTJt",
        "outputId": "d64696dc-c37b-4e05-b0b7-7b1f9f505a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Length-of-Email', 'Number of capitalized words',\n",
              "       'Repititive-Words-in-a-Email', 'Uinque-Words-in-a-Email',\n",
              "       'Quoted-text-in-a-Email', 'Question-Marks-in-a-Email',\n",
              "       'Number of co-occuring words', 'Number-of-noun', 'Spam lexicon',\n",
              "       'label', 'Neg-Sentiment', 'Neu-Sentiment', 'Pos-Sentiment',\n",
              "       'Comp-Sentiment', 'Polarity', 'Subjective'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "CAP8uGL4d5oa",
        "outputId": "ca42fc68-8a6e-437d-b1e8-c4ea73cd633a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Length-of-Email                0\n",
              "Number of capitalized words    0\n",
              "Repititive-Words-in-a-Email    0\n",
              "Uinque-Words-in-a-Email        0\n",
              "Quoted-text-in-a-Email         0\n",
              "Question-Marks-in-a-Email      0\n",
              "Number of co-occuring words    0\n",
              "Number-of-noun                 0\n",
              "Spam lexicon                   0\n",
              "label                          0\n",
              "Neg-Sentiment                  0\n",
              "Neu-Sentiment                  0\n",
              "Pos-Sentiment                  0\n",
              "Comp-Sentiment                 0\n",
              "Polarity                       0\n",
              "Subjective                     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Length-of-Email</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Repititive-Words-in-a-Email</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Uinque-Words-in-a-Email</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number of co-occuring words</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number-of-noun</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Spam lexicon</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neg-Sentiment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neu-Sentiment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pos-Sentiment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Comp-Sentiment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polarity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Subjective</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhI_UdbWhD2a",
        "outputId": "534c38fb-4fad-4bbf-b135-8b209a027ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "# List of columns you want to normalize\n",
        "columns_to_normalize = ['Length-of-Email', 'Number of capitalized words',\n",
        "       'Repititive-Words-in-a-Email', 'Uinque-Words-in-a-Email',\n",
        "       'Quoted-text-in-a-Email', 'Question-Marks-in-a-Email',\n",
        "       'Number of co-occuring words', 'Number-of-noun', 'Spam lexicon']\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform the specified columns\n",
        "result[columns_to_normalize] = scaler.fit_transform(result[columns_to_normalize])\n",
        "\n",
        "# Display the DataFrame with normalized columns\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FGesNQagOb9",
        "outputId": "2bb84b7e-87d1-4d3c-820a-74f3184dcaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Length-of-Email  Number of capitalized words  \\\n",
            "0             0.000246                          0.0   \n",
            "1             0.001348                          0.0   \n",
            "2             0.003731                          0.0   \n",
            "3             0.000987                          0.0   \n",
            "4             0.002273                          0.0   \n",
            "...                ...                          ...   \n",
            "83443         0.004323                          0.0   \n",
            "83444         0.001027                          0.0   \n",
            "83445         0.000890                          0.0   \n",
            "83446         0.003528                          0.0   \n",
            "83447         0.000371                          0.0   \n",
            "\n",
            "       Repititive-Words-in-a-Email  Uinque-Words-in-a-Email  \\\n",
            "0                         0.000000                 0.003667   \n",
            "1                         0.001869                 0.013897   \n",
            "2                         0.022804                 0.034549   \n",
            "3                         0.001869                 0.011388   \n",
            "4                         0.014206                 0.023548   \n",
            "...                            ...                      ...   \n",
            "83443                     0.014953                 0.019880   \n",
            "83444                     0.004860                 0.011967   \n",
            "83445                     0.004486                 0.010809   \n",
            "83446                     0.014953                 0.019494   \n",
            "83447                     0.003364                 0.007141   \n",
            "\n",
            "       Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
            "0                         0.0                        0.0   \n",
            "1                         0.0                        0.0   \n",
            "2                         0.0                        0.0   \n",
            "3                         0.0                        0.0   \n",
            "4                         0.0                        0.0   \n",
            "...                       ...                        ...   \n",
            "83443                     0.0                        0.0   \n",
            "83444                     0.0                        0.0   \n",
            "83445                     0.0                        0.0   \n",
            "83446                     0.0                        0.0   \n",
            "83447                     0.0                        0.0   \n",
            "\n",
            "       Number of co-occuring words  Number-of-noun  Spam lexicon  label  \\\n",
            "0                         0.000186        0.000234      0.000000      1   \n",
            "1                         0.001000        0.000565      0.001225      1   \n",
            "2                         0.003295        0.002150      0.003676      0   \n",
            "3                         0.000735        0.000455      0.001225      1   \n",
            "4                         0.002167        0.001461      0.000000      0   \n",
            "...                            ...             ...           ...    ...   \n",
            "83443                     0.003334        0.002233      0.001225      0   \n",
            "83444                     0.001147        0.000441      0.003676      1   \n",
            "83445                     0.000735        0.000345      0.006127      1   \n",
            "83446                     0.002706        0.001861      0.001225      0   \n",
            "83447                     0.000490        0.000193      0.000000      1   \n",
            "\n",
            "       Neg-Sentiment  Neu-Sentiment  Pos-Sentiment  Comp-Sentiment  Polarity  \\\n",
            "0              0.108          0.892          0.000         -0.3182 -0.600000   \n",
            "1              0.076          0.890          0.034         -0.3612 -0.012500   \n",
            "2              0.000          0.872          0.128          0.9873  0.151120   \n",
            "3              0.000          0.862          0.138          0.8074  0.033333   \n",
            "4              0.205          0.749          0.046         -0.9538 -0.023958   \n",
            "...              ...            ...            ...             ...       ...   \n",
            "83443          0.000          0.934          0.066          0.9477  0.211905   \n",
            "83444          0.178          0.822          0.000         -0.8481  0.050000   \n",
            "83445          0.000          0.693          0.307          0.9403  0.233333   \n",
            "83446          0.052          0.912          0.036         -0.1779  0.068333   \n",
            "83447          0.000          0.664          0.336          0.7650  0.700000   \n",
            "\n",
            "       Subjective  \n",
            "0        1.000000  \n",
            "1        0.375000  \n",
            "2        0.308964  \n",
            "3        0.075000  \n",
            "4        0.591319  \n",
            "...           ...  \n",
            "83443    0.276190  \n",
            "83444    0.066667  \n",
            "83445    0.533333  \n",
            "83446    0.412917  \n",
            "83447    0.600000  \n",
            "\n",
            "[83448 rows x 16 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.head(2\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "wh16x2tmhZA2",
        "outputId": "bb906619-3e9d-4d02-d6d4-9d08b419e034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Length-of-Email  Number of capitalized words  Repititive-Words-in-a-Email  \\\n",
              "0         0.000246                          0.0                     0.000000   \n",
              "1         0.001348                          0.0                     0.001869   \n",
              "\n",
              "   Uinque-Words-in-a-Email  Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "0                 0.003667                     0.0                        0.0   \n",
              "1                 0.013897                     0.0                        0.0   \n",
              "\n",
              "   Number of co-occuring words  Number-of-noun  Spam lexicon  label  \\\n",
              "0                     0.000186        0.000234      0.000000      1   \n",
              "1                     0.001000        0.000565      0.001225      1   \n",
              "\n",
              "   Neg-Sentiment  Neu-Sentiment  Pos-Sentiment  Comp-Sentiment  Polarity  \\\n",
              "0          0.108          0.892          0.000         -0.3182   -0.6000   \n",
              "1          0.076          0.890          0.034         -0.3612   -0.0125   \n",
              "\n",
              "   Subjective  \n",
              "0       1.000  \n",
              "1       0.375  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b0002c4-0ce6-4ec4-8ab6-9f4b9eb7ad12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Repititive-Words-in-a-Email</th>\n",
              "      <th>Uinque-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occuring words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>Spam lexicon</th>\n",
              "      <th>label</th>\n",
              "      <th>Neg-Sentiment</th>\n",
              "      <th>Neu-Sentiment</th>\n",
              "      <th>Pos-Sentiment</th>\n",
              "      <th>Comp-Sentiment</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>-0.6000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001348</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001869</td>\n",
              "      <td>0.013897</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000565</td>\n",
              "      <td>0.001225</td>\n",
              "      <td>1</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.890</td>\n",
              "      <td>0.034</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>-0.0125</td>\n",
              "      <td>0.375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b0002c4-0ce6-4ec4-8ab6-9f4b9eb7ad12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b0002c4-0ce6-4ec4-8ab6-9f4b9eb7ad12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b0002c4-0ce6-4ec4-8ab6-9f4b9eb7ad12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e915a47f-3591-4492-84a0-efdffad2e00b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e915a47f-3591-4492-84a0-efdffad2e00b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e915a47f-3591-4492-84a0-efdffad2e00b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"            )\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Length-of-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007795011818580155,\n        \"min\": 0.0002455303455463802,\n        \"max\": 0.001347911488815842,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.001347911488815842,\n          0.0002455303455463802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of capitalized words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repititive-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013216949181056963,\n        \"min\": 0.0,\n        \"max\": 0.0018691588785046728,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0018691588785046728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Uinque-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007233479907911023,\n        \"min\": 0.003667245705462266,\n        \"max\": 0.013896931094383322,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.013896931094383322\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quoted-text-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question-Marks-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of co-occuring words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005754867265964274,\n        \"min\": 0.00018630556073071002,\n        \"max\": 0.0010001666944490749,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0010001666944490749\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number-of-noun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00023392830408950377,\n        \"min\": 0.00023433407768863894,\n        \"max\": 0.0005651586579549527,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0005651586579549527\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0008665524279246906,\n        \"min\": 0.0,\n        \"max\": 0.0012254901960784314,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0012254901960784314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neg-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02262741699796952,\n        \"min\": 0.076,\n        \"max\": 0.108,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.076\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neu-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0014142135623730963,\n        \"min\": 0.89,\n        \"max\": 0.892,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.89\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pos-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.024041630560342617,\n        \"min\": 0.0,\n        \"max\": 0.034,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comp-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03040559159102157,\n        \"min\": -0.3612,\n        \"max\": -0.3182,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.3612\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41542523394709663,\n        \"min\": -0.6,\n        \"max\": -0.0125,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          -0.0125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4419417382415922,\n        \"min\": 0.375,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.to_csv('finalFeatures.csv')"
      ],
      "metadata": {
        "id": "DF1iDIlgheFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=result.copy()"
      ],
      "metadata": {
        "id": "jO0TDFO4h8QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/finalFeatures.csv')\n",
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "IYMO-3CV_mpQ",
        "outputId": "67930720-b1d8-4822-a739-3d218f02c812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Length-of-Email  Number of capitalized words  \\\n",
              "0           0         0.000246                          0.0   \n",
              "\n",
              "   Repititive-Words-in-a-Email  Uinque-Words-in-a-Email  \\\n",
              "0                          0.0                 0.003667   \n",
              "\n",
              "   Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "0                     0.0                        0.0   \n",
              "\n",
              "   Number of co-occuring words  Number-of-noun  Spam lexicon  label  \\\n",
              "0                     0.000186        0.000234           0.0      1   \n",
              "\n",
              "   Neg-Sentiment  Neu-Sentiment  Pos-Sentiment  Comp-Sentiment  Polarity  \\\n",
              "0          0.108          0.892            0.0         -0.3182      -0.6   \n",
              "\n",
              "   Subjective  \n",
              "0         1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c662aef7-fd6a-42fc-a483-85cce326cc4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Repititive-Words-in-a-Email</th>\n",
              "      <th>Uinque-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occuring words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>Spam lexicon</th>\n",
              "      <th>label</th>\n",
              "      <th>Neg-Sentiment</th>\n",
              "      <th>Neu-Sentiment</th>\n",
              "      <th>Pos-Sentiment</th>\n",
              "      <th>Comp-Sentiment</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c662aef7-fd6a-42fc-a483-85cce326cc4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c662aef7-fd6a-42fc-a483-85cce326cc4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c662aef7-fd6a-42fc-a483-85cce326cc4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 83448,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24089,\n        \"min\": 0,\n        \"max\": 83447,\n        \"num_unique_values\": 83448,\n        \"samples\": [\n          67681,\n          61385,\n          41829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length-of-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0069793722241669135,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 7956,\n        \"samples\": [\n          0.0172906812047355,\n          0.007997274112082,\n          0.0002939683048718\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of capitalized words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004469001600244551,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3333333333333333,\n          0.6666666666666666,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repititive-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022305691466995316,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 614,\n        \"samples\": [\n          0.0874766355140186,\n          0.3536448598130841,\n          0.0549532710280373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Uinque-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02815831639889422,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1184,\n        \"samples\": [\n          0.0650453580389886,\n          0.2646207295888824,\n          0.187222543910442\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quoted-text-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014785310265820185,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          0.0828402366863905,\n          0.3224852071005917,\n          0.1568047337278106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question-Marks-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006316381939540536,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 103,\n        \"samples\": [\n          0.0103513174404015,\n          0.3613550815558343,\n          0.1044542032622333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of co-occuring words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007107244858234746,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2509,\n        \"samples\": [\n          0.0334663620407322,\n          0.000431444456429,\n          0.0097173058254807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number-of-noun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004615418184700771,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1358,\n        \"samples\": [\n          0.00100625809831,\n          0.0265211038513494,\n          0.0175612714691368\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013190503304589766,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 169,\n        \"samples\": [\n          0.1642156862745098,\n          0.0208333333333333,\n          0.1311274509803921\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neg-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061534251444246235,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 458,\n        \"samples\": [\n          0.344,\n          0.055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neu-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12437377692924996,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 731,\n        \"samples\": [\n          0.39,\n          0.791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pos-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10917272072015846,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 674,\n        \"samples\": [\n          0.541,\n          0.217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comp-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5516671967906014,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5642,\n        \"samples\": [\n          0.4058,\n          0.687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1674412025145324,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 30980,\n        \"samples\": [\n          0.1641666666666666,\n          0.1810064935064934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18782995916813944,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 34053,\n        \"samples\": [\n          0.3962745098039215,\n          0.5379629629629631\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFndeKc8Wg1T"
      },
      "source": [
        "improved rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upQ1XhQJWkjR",
        "outputId": "699aa1cf-69b3-468c-dc13-3a20eb4f18fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 22ms/step - accuracy: 0.7090 - loss: 0.5748 - val_accuracy: 0.7994 - val_loss: 0.4349\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.7906 - loss: 0.4594 - val_accuracy: 0.8095 - val_loss: 0.4351\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8033 - loss: 0.4412 - val_accuracy: 0.8158 - val_loss: 0.4107\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 20ms/step - accuracy: 0.8105 - loss: 0.4280 - val_accuracy: 0.8256 - val_loss: 0.3931\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 21ms/step - accuracy: 0.8123 - loss: 0.4219 - val_accuracy: 0.8266 - val_loss: 0.3983\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8215 - loss: 0.4087 - val_accuracy: 0.8182 - val_loss: 0.3928\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 21ms/step - accuracy: 0.8226 - loss: 0.4056 - val_accuracy: 0.8308 - val_loss: 0.3808\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.8236 - loss: 0.4020 - val_accuracy: 0.8256 - val_loss: 0.3988\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.8190 - loss: 0.4018 - val_accuracy: 0.8310 - val_loss: 0.3788\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 21ms/step - accuracy: 0.8267 - loss: 0.3976 - val_accuracy: 0.8307 - val_loss: 0.3836\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 22ms/step - accuracy: 0.8286 - loss: 0.3929 - val_accuracy: 0.8362 - val_loss: 0.3692\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8298 - loss: 0.3858 - val_accuracy: 0.8370 - val_loss: 0.3691\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8292 - loss: 0.3890 - val_accuracy: 0.8367 - val_loss: 0.3684\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 13ms/step - accuracy: 0.8310 - loss: 0.3816 - val_accuracy: 0.8304 - val_loss: 0.3738\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8327 - loss: 0.3812 - val_accuracy: 0.8426 - val_loss: 0.3563\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8300 - loss: 0.3852 - val_accuracy: 0.8238 - val_loss: 0.3983\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8320 - loss: 0.3814 - val_accuracy: 0.8384 - val_loss: 0.3581\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8335 - loss: 0.3769 - val_accuracy: 0.8381 - val_loss: 0.3628\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8360 - loss: 0.3764 - val_accuracy: 0.8382 - val_loss: 0.3621\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8342 - loss: 0.3735 - val_accuracy: 0.8416 - val_loss: 0.3576\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8404 - loss: 0.3704 - val_accuracy: 0.8419 - val_loss: 0.3565\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8352 - loss: 0.3676 - val_accuracy: 0.8417 - val_loss: 0.3591\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8366 - loss: 0.3680 - val_accuracy: 0.8438 - val_loss: 0.3518\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8390 - loss: 0.3641 - val_accuracy: 0.8443 - val_loss: 0.3555\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8389 - loss: 0.3671 - val_accuracy: 0.8470 - val_loss: 0.3475\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8385 - loss: 0.3669 - val_accuracy: 0.8435 - val_loss: 0.3531\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8408 - loss: 0.3620 - val_accuracy: 0.8479 - val_loss: 0.3499\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8398 - loss: 0.3631 - val_accuracy: 0.8444 - val_loss: 0.3492\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8418 - loss: 0.3593 - val_accuracy: 0.8444 - val_loss: 0.3520\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8428 - loss: 0.3660 - val_accuracy: 0.8459 - val_loss: 0.3467\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - accuracy: 0.8442 - loss: 0.3574 - val_accuracy: 0.8459 - val_loss: 0.3451\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8414 - loss: 0.3602 - val_accuracy: 0.8435 - val_loss: 0.3563\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8443 - loss: 0.3575 - val_accuracy: 0.8498 - val_loss: 0.3413\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8443 - loss: 0.3572 - val_accuracy: 0.8498 - val_loss: 0.3412\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8472 - loss: 0.3493 - val_accuracy: 0.8473 - val_loss: 0.3463\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8436 - loss: 0.3535 - val_accuracy: 0.8461 - val_loss: 0.3451\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8501 - loss: 0.3479 - val_accuracy: 0.8418 - val_loss: 0.3671\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8470 - loss: 0.3495 - val_accuracy: 0.8495 - val_loss: 0.3394\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8432 - loss: 0.3529 - val_accuracy: 0.8405 - val_loss: 0.3642\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8486 - loss: 0.3486 - val_accuracy: 0.8436 - val_loss: 0.3535\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8453 - loss: 0.3526 - val_accuracy: 0.8490 - val_loss: 0.3425\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8484 - loss: 0.3479 - val_accuracy: 0.8505 - val_loss: 0.3397\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8495 - loss: 0.3457 - val_accuracy: 0.8488 - val_loss: 0.3455\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8476 - loss: 0.3492 - val_accuracy: 0.8352 - val_loss: 0.3649\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8510 - loss: 0.3481 - val_accuracy: 0.8513 - val_loss: 0.3384\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8517 - loss: 0.3436 - val_accuracy: 0.8529 - val_loss: 0.3389\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8499 - loss: 0.3451 - val_accuracy: 0.8500 - val_loss: 0.3372\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8484 - loss: 0.3487 - val_accuracy: 0.8489 - val_loss: 0.3420\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8530 - loss: 0.3435 - val_accuracy: 0.8475 - val_loss: 0.3442\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8526 - loss: 0.3410 - val_accuracy: 0.8507 - val_loss: 0.3388\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8507 - loss: 0.3386\n",
            "Test Loss: 0.3360\n",
            "Test Accuracy: 0.8533\n",
            "Confusion Matrix:\n",
            "[[6845 1093]\n",
            " [1356 7396]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85      7938\n",
            "           1       0.87      0.85      0.86      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8533\n",
            "Precision: 0.8712\n",
            "Recall: 0.8451\n",
            "F1 Score: 0.8580\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# RNN layers\n",
        "model.add(SimpleRNN(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(SimpleRNN(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usdy5YUaW0cf"
      },
      "source": [
        "improved rnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfqt_f8vW3Mn",
        "outputId": "0fa686de-acef-4f65-81f1-d81113b04921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - accuracy: 0.6560 - loss: 0.6345 - val_accuracy: 0.7377 - val_loss: 0.5360\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.7181 - loss: 0.5568 - val_accuracy: 0.7488 - val_loss: 0.5154\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.7342 - loss: 0.5366 - val_accuracy: 0.7481 - val_loss: 0.5179\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.7450 - loss: 0.5225 - val_accuracy: 0.7399 - val_loss: 0.5232\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.7555 - loss: 0.5082 - val_accuracy: 0.7490 - val_loss: 0.5092\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.7628 - loss: 0.4985 - val_accuracy: 0.7925 - val_loss: 0.4507\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.7773 - loss: 0.4774 - val_accuracy: 0.7991 - val_loss: 0.4442\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.7863 - loss: 0.4682 - val_accuracy: 0.8055 - val_loss: 0.4278\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.7947 - loss: 0.4492 - val_accuracy: 0.8074 - val_loss: 0.4172\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.8013 - loss: 0.4427 - val_accuracy: 0.8147 - val_loss: 0.4089\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - accuracy: 0.8049 - loss: 0.4341 - val_accuracy: 0.8167 - val_loss: 0.4093\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8052 - loss: 0.4306 - val_accuracy: 0.8101 - val_loss: 0.4124\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.8103 - loss: 0.4267 - val_accuracy: 0.8218 - val_loss: 0.4006\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8150 - loss: 0.4189 - val_accuracy: 0.8262 - val_loss: 0.3928\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8130 - loss: 0.4204 - val_accuracy: 0.8188 - val_loss: 0.3989\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8153 - loss: 0.4118 - val_accuracy: 0.8274 - val_loss: 0.3940\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8198 - loss: 0.4067 - val_accuracy: 0.8258 - val_loss: 0.3900\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8181 - loss: 0.4051 - val_accuracy: 0.8319 - val_loss: 0.3778\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - accuracy: 0.8217 - loss: 0.4017 - val_accuracy: 0.8188 - val_loss: 0.4014\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8205 - loss: 0.4031 - val_accuracy: 0.8325 - val_loss: 0.3833\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.8227 - loss: 0.3998 - val_accuracy: 0.8311 - val_loss: 0.3740\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.8267 - loss: 0.3926 - val_accuracy: 0.8358 - val_loss: 0.3697\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.8242 - loss: 0.3921 - val_accuracy: 0.8083 - val_loss: 0.4099\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8248 - loss: 0.3932 - val_accuracy: 0.8366 - val_loss: 0.3633\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.8268 - loss: 0.3886 - val_accuracy: 0.8319 - val_loss: 0.3763\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8297 - loss: 0.3873 - val_accuracy: 0.8238 - val_loss: 0.3850\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8284 - loss: 0.3859 - val_accuracy: 0.8342 - val_loss: 0.3683\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8293 - loss: 0.3854 - val_accuracy: 0.8365 - val_loss: 0.3631\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8341 - loss: 0.3760 - val_accuracy: 0.8388 - val_loss: 0.3633\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8321 - loss: 0.3831 - val_accuracy: 0.8327 - val_loss: 0.3646\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 24ms/step - accuracy: 0.8337 - loss: 0.3803 - val_accuracy: 0.8402 - val_loss: 0.3576\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8359 - loss: 0.3770 - val_accuracy: 0.8412 - val_loss: 0.3640\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 24ms/step - accuracy: 0.8324 - loss: 0.3772 - val_accuracy: 0.8404 - val_loss: 0.3548\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8339 - loss: 0.3739 - val_accuracy: 0.8463 - val_loss: 0.3510\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 31ms/step - accuracy: 0.8343 - loss: 0.3747 - val_accuracy: 0.8402 - val_loss: 0.3561\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 39ms/step - accuracy: 0.8360 - loss: 0.3713 - val_accuracy: 0.8421 - val_loss: 0.3546\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 40ms/step - accuracy: 0.8370 - loss: 0.3725 - val_accuracy: 0.8426 - val_loss: 0.3522\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 37ms/step - accuracy: 0.8331 - loss: 0.3713 - val_accuracy: 0.8442 - val_loss: 0.3480\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 35ms/step - accuracy: 0.8355 - loss: 0.3697 - val_accuracy: 0.8435 - val_loss: 0.3505\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 37ms/step - accuracy: 0.8344 - loss: 0.3689 - val_accuracy: 0.8421 - val_loss: 0.3579\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.8398 - loss: 0.3662 - val_accuracy: 0.8476 - val_loss: 0.3476\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 27ms/step - accuracy: 0.8393 - loss: 0.3633 - val_accuracy: 0.8463 - val_loss: 0.3468\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 23ms/step - accuracy: 0.8405 - loss: 0.3614 - val_accuracy: 0.8465 - val_loss: 0.3430\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8426 - loss: 0.3612 - val_accuracy: 0.8465 - val_loss: 0.3428\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8396 - loss: 0.3618 - val_accuracy: 0.8286 - val_loss: 0.3777\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8416 - loss: 0.3582 - val_accuracy: 0.8446 - val_loss: 0.3457\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 24ms/step - accuracy: 0.8421 - loss: 0.3565 - val_accuracy: 0.8468 - val_loss: 0.3445\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8424 - loss: 0.3553 - val_accuracy: 0.8475 - val_loss: 0.3442\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8461 - loss: 0.3554 - val_accuracy: 0.8518 - val_loss: 0.3390\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8431 - loss: 0.3546 - val_accuracy: 0.8497 - val_loss: 0.3413\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8531 - loss: 0.3389\n",
            "Test Loss: 0.3409\n",
            "Test Accuracy: 0.8527\n",
            "Confusion Matrix:\n",
            "[[6768 1170]\n",
            " [1288 7464]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85      7938\n",
            "           1       0.86      0.85      0.86      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8527\n",
            "Precision: 0.8645\n",
            "Recall: 0.8528\n",
            "F1 Score: 0.8586\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvQWJGvOW66P"
      },
      "source": [
        "improved rnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DVlnRZAXbAu",
        "outputId": "90601821-ebc7-42a8-ea5b-e17e0d50e085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 26ms/step - accuracy: 0.6069 - loss: 0.6746 - val_accuracy: 0.7224 - val_loss: 0.5583\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.7235 - loss: 0.5509 - val_accuracy: 0.7457 - val_loss: 0.5176\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - accuracy: 0.7385 - loss: 0.5316 - val_accuracy: 0.7356 - val_loss: 0.5224\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.7461 - loss: 0.5253 - val_accuracy: 0.7525 - val_loss: 0.5041\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - accuracy: 0.7523 - loss: 0.5130 - val_accuracy: 0.7608 - val_loss: 0.4913\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.7551 - loss: 0.5095 - val_accuracy: 0.7708 - val_loss: 0.4790\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - accuracy: 0.7658 - loss: 0.4910 - val_accuracy: 0.7835 - val_loss: 0.4564\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.7845 - loss: 0.4642 - val_accuracy: 0.8035 - val_loss: 0.4256\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.7921 - loss: 0.4476 - val_accuracy: 0.8066 - val_loss: 0.4168\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 27ms/step - accuracy: 0.8013 - loss: 0.4395 - val_accuracy: 0.8107 - val_loss: 0.4203\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 26ms/step - accuracy: 0.8107 - loss: 0.4239 - val_accuracy: 0.8053 - val_loss: 0.4209\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 29ms/step - accuracy: 0.8141 - loss: 0.4173 - val_accuracy: 0.8226 - val_loss: 0.3933\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8170 - loss: 0.4118 - val_accuracy: 0.8256 - val_loss: 0.3910\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 27ms/step - accuracy: 0.8234 - loss: 0.4006 - val_accuracy: 0.8316 - val_loss: 0.3833\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.8205 - loss: 0.4044 - val_accuracy: 0.8338 - val_loss: 0.3756\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.8251 - loss: 0.3991 - val_accuracy: 0.8326 - val_loss: 0.3767\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 29ms/step - accuracy: 0.8258 - loss: 0.3930 - val_accuracy: 0.8267 - val_loss: 0.3911\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 27ms/step - accuracy: 0.8290 - loss: 0.3877 - val_accuracy: 0.8293 - val_loss: 0.3851\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.8270 - loss: 0.3898 - val_accuracy: 0.8376 - val_loss: 0.3651\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.8305 - loss: 0.3848 - val_accuracy: 0.8378 - val_loss: 0.3643\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 27ms/step - accuracy: 0.8315 - loss: 0.3844 - val_accuracy: 0.8420 - val_loss: 0.3611\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - accuracy: 0.8332 - loss: 0.3796 - val_accuracy: 0.8258 - val_loss: 0.3810\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - accuracy: 0.8320 - loss: 0.3768 - val_accuracy: 0.8326 - val_loss: 0.3704\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.8338 - loss: 0.3763 - val_accuracy: 0.8382 - val_loss: 0.3631\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.8349 - loss: 0.3743 - val_accuracy: 0.8310 - val_loss: 0.3774\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.8350 - loss: 0.3706 - val_accuracy: 0.8405 - val_loss: 0.3542\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - accuracy: 0.8378 - loss: 0.3692 - val_accuracy: 0.8411 - val_loss: 0.3570\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 27ms/step - accuracy: 0.8378 - loss: 0.3685 - val_accuracy: 0.8444 - val_loss: 0.3563\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.8402 - loss: 0.3627 - val_accuracy: 0.8414 - val_loss: 0.3583\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - accuracy: 0.8404 - loss: 0.3634 - val_accuracy: 0.8417 - val_loss: 0.3514\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8431 - loss: 0.3581 - val_accuracy: 0.8373 - val_loss: 0.3569\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8449 - loss: 0.3560 - val_accuracy: 0.8423 - val_loss: 0.3516\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - accuracy: 0.8452 - loss: 0.3566 - val_accuracy: 0.8439 - val_loss: 0.3508\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - accuracy: 0.8419 - loss: 0.3584 - val_accuracy: 0.8447 - val_loss: 0.3499\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 29ms/step - accuracy: 0.8443 - loss: 0.3539 - val_accuracy: 0.8477 - val_loss: 0.3431\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 27ms/step - accuracy: 0.8455 - loss: 0.3508 - val_accuracy: 0.8429 - val_loss: 0.3439\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8421 - loss: 0.3573 - val_accuracy: 0.8466 - val_loss: 0.3415\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 29ms/step - accuracy: 0.8452 - loss: 0.3518 - val_accuracy: 0.8507 - val_loss: 0.3385\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 27ms/step - accuracy: 0.8452 - loss: 0.3515 - val_accuracy: 0.8212 - val_loss: 0.3882\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.8456 - loss: 0.3525 - val_accuracy: 0.8481 - val_loss: 0.3400\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - accuracy: 0.8478 - loss: 0.3438 - val_accuracy: 0.8451 - val_loss: 0.3441\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.8485 - loss: 0.3445 - val_accuracy: 0.8473 - val_loss: 0.3476\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 27ms/step - accuracy: 0.8481 - loss: 0.3473 - val_accuracy: 0.8517 - val_loss: 0.3390\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 27ms/step - accuracy: 0.8510 - loss: 0.3446 - val_accuracy: 0.8533 - val_loss: 0.3308\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8520 - loss: 0.3366 - val_accuracy: 0.8492 - val_loss: 0.3367\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 29ms/step - accuracy: 0.8544 - loss: 0.3356 - val_accuracy: 0.8552 - val_loss: 0.3298\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8533 - loss: 0.3384 - val_accuracy: 0.8492 - val_loss: 0.3383\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8525 - loss: 0.3365 - val_accuracy: 0.8544 - val_loss: 0.3295\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 29ms/step - accuracy: 0.8504 - loss: 0.3392 - val_accuracy: 0.8546 - val_loss: 0.3307\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 27ms/step - accuracy: 0.8572 - loss: 0.3335 - val_accuracy: 0.8513 - val_loss: 0.3358\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8570 - loss: 0.3246\n",
            "Test Loss: 0.3255\n",
            "Test Accuracy: 0.8581\n",
            "Confusion Matrix:\n",
            "[[6977  961]\n",
            " [1407 7345]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85      7938\n",
            "           1       0.88      0.84      0.86      8752\n",
            "\n",
            "    accuracy                           0.86     16690\n",
            "   macro avg       0.86      0.86      0.86     16690\n",
            "weighted avg       0.86      0.86      0.86     16690\n",
            "\n",
            "Accuracy: 0.8581\n",
            "Precision: 0.8843\n",
            "Recall: 0.8392\n",
            "F1 Score: 0.8612\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNWK9SrgMteA"
      },
      "source": [
        "improved cnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-709UZiMvyB",
        "outputId": "805f81b6-f39b-4e4c-a878-e49d7fdf76cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 11ms/step - accuracy: 0.6502 - loss: 0.6837 - val_accuracy: 0.7685 - val_loss: 0.4875\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.7484 - loss: 0.5164 - val_accuracy: 0.7933 - val_loss: 0.4440\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.7727 - loss: 0.4837 - val_accuracy: 0.7994 - val_loss: 0.4397\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.7825 - loss: 0.4636 - val_accuracy: 0.7960 - val_loss: 0.4436\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 10ms/step - accuracy: 0.7897 - loss: 0.4543 - val_accuracy: 0.8049 - val_loss: 0.4152\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7977 - loss: 0.4409 - val_accuracy: 0.8089 - val_loss: 0.4116\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7969 - loss: 0.4434 - val_accuracy: 0.8134 - val_loss: 0.4100\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8030 - loss: 0.4365 - val_accuracy: 0.8188 - val_loss: 0.4058\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8047 - loss: 0.4278 - val_accuracy: 0.8230 - val_loss: 0.4002\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8030 - loss: 0.4309 - val_accuracy: 0.8188 - val_loss: 0.3964\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.8074 - loss: 0.4231 - val_accuracy: 0.8234 - val_loss: 0.3950\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8092 - loss: 0.4235 - val_accuracy: 0.8244 - val_loss: 0.3905\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8093 - loss: 0.4186 - val_accuracy: 0.8255 - val_loss: 0.3903\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - accuracy: 0.8104 - loss: 0.4183 - val_accuracy: 0.8254 - val_loss: 0.3901\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8101 - loss: 0.4173 - val_accuracy: 0.8264 - val_loss: 0.3915\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.8133 - loss: 0.4152 - val_accuracy: 0.8265 - val_loss: 0.3922\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8147 - loss: 0.4116 - val_accuracy: 0.8308 - val_loss: 0.3841\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8141 - loss: 0.4088 - val_accuracy: 0.8301 - val_loss: 0.3901\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8167 - loss: 0.4110 - val_accuracy: 0.8346 - val_loss: 0.3796\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8194 - loss: 0.4065 - val_accuracy: 0.8373 - val_loss: 0.3764\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.8204 - loss: 0.4032 - val_accuracy: 0.8362 - val_loss: 0.3790\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8211 - loss: 0.4032 - val_accuracy: 0.8212 - val_loss: 0.4110\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8176 - loss: 0.4058 - val_accuracy: 0.8350 - val_loss: 0.3759\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8210 - loss: 0.4050 - val_accuracy: 0.8319 - val_loss: 0.3875\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8177 - loss: 0.4020 - val_accuracy: 0.8367 - val_loss: 0.3770\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8213 - loss: 0.4020 - val_accuracy: 0.8390 - val_loss: 0.3699\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8169 - loss: 0.4065 - val_accuracy: 0.8353 - val_loss: 0.3743\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.8188 - loss: 0.4042 - val_accuracy: 0.8348 - val_loss: 0.3737\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8218 - loss: 0.3968 - val_accuracy: 0.8379 - val_loss: 0.3726\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.4015 - val_accuracy: 0.8352 - val_loss: 0.3746\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8206 - loss: 0.3976 - val_accuracy: 0.8401 - val_loss: 0.3693\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8218 - loss: 0.3999 - val_accuracy: 0.8414 - val_loss: 0.3665\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8247 - loss: 0.3895 - val_accuracy: 0.8355 - val_loss: 0.3790\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8239 - loss: 0.3995 - val_accuracy: 0.8360 - val_loss: 0.3771\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8175 - loss: 0.4019 - val_accuracy: 0.8392 - val_loss: 0.3685\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8221 - loss: 0.3945 - val_accuracy: 0.8049 - val_loss: 0.4105\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8205 - loss: 0.3965 - val_accuracy: 0.8188 - val_loss: 0.3903\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8234 - loss: 0.3936 - val_accuracy: 0.8405 - val_loss: 0.3691\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8222 - loss: 0.3925 - val_accuracy: 0.8407 - val_loss: 0.3678\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8257 - loss: 0.3971 - val_accuracy: 0.8376 - val_loss: 0.3697\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8279 - loss: 0.3900 - val_accuracy: 0.8319 - val_loss: 0.3797\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8238 - loss: 0.3924 - val_accuracy: 0.8401 - val_loss: 0.3645\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 0.3953 - val_accuracy: 0.8419 - val_loss: 0.3641\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8229 - loss: 0.3950 - val_accuracy: 0.8398 - val_loss: 0.3713\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8198 - loss: 0.3969 - val_accuracy: 0.8329 - val_loss: 0.3730\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8196 - loss: 0.4018 - val_accuracy: 0.8402 - val_loss: 0.3690\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.3965 - val_accuracy: 0.8417 - val_loss: 0.3639\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.3932 - val_accuracy: 0.8253 - val_loss: 0.3986\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8255 - loss: 0.3927 - val_accuracy: 0.8371 - val_loss: 0.3694\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8263 - loss: 0.3884 - val_accuracy: 0.8396 - val_loss: 0.3647\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8393 - loss: 0.3693\n",
            "Test Loss: 0.3654\n",
            "Test Accuracy: 0.8420\n",
            "Confusion Matrix:\n",
            "[[6809 1129]\n",
            " [1508 7244]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84      7938\n",
            "           1       0.87      0.83      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8420\n",
            "Precision: 0.8652\n",
            "Recall: 0.8277\n",
            "F1 Score: 0.8460\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the optimized CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDOsaTxTVCYG"
      },
      "source": [
        "improved cnn-lstm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpxnijV3VEmS",
        "outputId": "af4f0c8e-f8ac-433c-aeb1-d0a5a3bcd27a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - accuracy: 0.6688 - loss: 0.5980 - val_accuracy: 0.7825 - val_loss: 0.4631\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7691 - loss: 0.4869 - val_accuracy: 0.7948 - val_loss: 0.4444\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.7812 - loss: 0.4683 - val_accuracy: 0.8072 - val_loss: 0.4215\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7873 - loss: 0.4550 - val_accuracy: 0.8135 - val_loss: 0.4109\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.7957 - loss: 0.4456 - val_accuracy: 0.8137 - val_loss: 0.4081\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8009 - loss: 0.4330 - val_accuracy: 0.8176 - val_loss: 0.4021\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8029 - loss: 0.4290 - val_accuracy: 0.8111 - val_loss: 0.4166\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8051 - loss: 0.4274 - val_accuracy: 0.8055 - val_loss: 0.4214\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8069 - loss: 0.4226 - val_accuracy: 0.8256 - val_loss: 0.3912\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8124 - loss: 0.4158 - val_accuracy: 0.8201 - val_loss: 0.4021\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8148 - loss: 0.4137 - val_accuracy: 0.8217 - val_loss: 0.3939\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8120 - loss: 0.4137 - val_accuracy: 0.8038 - val_loss: 0.4192\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8144 - loss: 0.4140 - val_accuracy: 0.8265 - val_loss: 0.3802\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8163 - loss: 0.4094 - val_accuracy: 0.8326 - val_loss: 0.3785\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8167 - loss: 0.4079 - val_accuracy: 0.8383 - val_loss: 0.3730\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8182 - loss: 0.4044 - val_accuracy: 0.8309 - val_loss: 0.3742\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8189 - loss: 0.4031 - val_accuracy: 0.8310 - val_loss: 0.3753\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8203 - loss: 0.4020 - val_accuracy: 0.8363 - val_loss: 0.3682\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8239 - loss: 0.3985 - val_accuracy: 0.8012 - val_loss: 0.4169\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8203 - loss: 0.3985 - val_accuracy: 0.8361 - val_loss: 0.3695\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8236 - loss: 0.3932 - val_accuracy: 0.8331 - val_loss: 0.3698\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8222 - loss: 0.3954 - val_accuracy: 0.8383 - val_loss: 0.3638\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8204 - loss: 0.3975 - val_accuracy: 0.8399 - val_loss: 0.3621\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8244 - loss: 0.3895 - val_accuracy: 0.8405 - val_loss: 0.3641\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8239 - loss: 0.3938 - val_accuracy: 0.8301 - val_loss: 0.3730\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8277 - loss: 0.3861 - val_accuracy: 0.8326 - val_loss: 0.3708\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8255 - loss: 0.3915 - val_accuracy: 0.8373 - val_loss: 0.3664\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8256 - loss: 0.3923 - val_accuracy: 0.8429 - val_loss: 0.3574\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8235 - loss: 0.3943 - val_accuracy: 0.8364 - val_loss: 0.3620\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8260 - loss: 0.3892 - val_accuracy: 0.8420 - val_loss: 0.3587\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8259 - loss: 0.3876 - val_accuracy: 0.8439 - val_loss: 0.3515\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8296 - loss: 0.3840 - val_accuracy: 0.8443 - val_loss: 0.3511\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8301 - loss: 0.3837 - val_accuracy: 0.8437 - val_loss: 0.3528\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8293 - loss: 0.3787 - val_accuracy: 0.8286 - val_loss: 0.3727\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8307 - loss: 0.3816 - val_accuracy: 0.8324 - val_loss: 0.3607\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8280 - loss: 0.3823 - val_accuracy: 0.8429 - val_loss: 0.3513\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8301 - loss: 0.3805 - val_accuracy: 0.8466 - val_loss: 0.3474\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8298 - loss: 0.3822 - val_accuracy: 0.8303 - val_loss: 0.3684\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8335 - loss: 0.3777 - val_accuracy: 0.8455 - val_loss: 0.3478\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8306 - loss: 0.3763 - val_accuracy: 0.8447 - val_loss: 0.3478\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8297 - loss: 0.3804 - val_accuracy: 0.8420 - val_loss: 0.3520\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8286 - loss: 0.3776 - val_accuracy: 0.8470 - val_loss: 0.3451\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8283 - loss: 0.3802 - val_accuracy: 0.8464 - val_loss: 0.3447\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8301 - loss: 0.3772 - val_accuracy: 0.8471 - val_loss: 0.3435\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8307 - loss: 0.3801 - val_accuracy: 0.8459 - val_loss: 0.3472\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8300 - loss: 0.3776 - val_accuracy: 0.8417 - val_loss: 0.3520\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8340 - loss: 0.3763 - val_accuracy: 0.8475 - val_loss: 0.3409\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8297 - loss: 0.3766 - val_accuracy: 0.8441 - val_loss: 0.3505\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8337 - loss: 0.3755 - val_accuracy: 0.8456 - val_loss: 0.3451\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8312 - loss: 0.3768 - val_accuracy: 0.8483 - val_loss: 0.3406\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8456 - loss: 0.3503\n",
            "Test Loss: 0.3476\n",
            "Test Accuracy: 0.8463\n",
            "Confusion Matrix:\n",
            "[[6656 1282]\n",
            " [1283 7469]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84      7938\n",
            "           1       0.85      0.85      0.85      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8463\n",
            "Precision: 0.8535\n",
            "Recall: 0.8534\n",
            "F1 Score: 0.8535\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAt1Z7nUVrWD"
      },
      "source": [
        "improved cnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gY9gMapVuqh",
        "outputId": "da22f98b-6980-4bae-a68b-8d8e7d785d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11ms/step - accuracy: 0.6657 - loss: 0.6031 - val_accuracy: 0.7884 - val_loss: 0.4547\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7666 - loss: 0.4912 - val_accuracy: 0.7965 - val_loss: 0.4324\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7796 - loss: 0.4702 - val_accuracy: 0.8056 - val_loss: 0.4227\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7926 - loss: 0.4512 - val_accuracy: 0.8090 - val_loss: 0.4104\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.7931 - loss: 0.4468 - val_accuracy: 0.8144 - val_loss: 0.4083\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7996 - loss: 0.4376 - val_accuracy: 0.7958 - val_loss: 0.4384\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8032 - loss: 0.4369 - val_accuracy: 0.8197 - val_loss: 0.3987\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8049 - loss: 0.4253 - val_accuracy: 0.8229 - val_loss: 0.3953\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8083 - loss: 0.4241 - val_accuracy: 0.8174 - val_loss: 0.4007\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8092 - loss: 0.4225 - val_accuracy: 0.8276 - val_loss: 0.3917\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8080 - loss: 0.4225 - val_accuracy: 0.8244 - val_loss: 0.3873\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8085 - loss: 0.4198 - val_accuracy: 0.8284 - val_loss: 0.3814\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8133 - loss: 0.4152 - val_accuracy: 0.8265 - val_loss: 0.3916\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8127 - loss: 0.4164 - val_accuracy: 0.8277 - val_loss: 0.3797\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8148 - loss: 0.4126 - val_accuracy: 0.8319 - val_loss: 0.3772\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8197 - loss: 0.4055 - val_accuracy: 0.8299 - val_loss: 0.3786\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8196 - loss: 0.4035 - val_accuracy: 0.8290 - val_loss: 0.3761\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8165 - loss: 0.4085 - val_accuracy: 0.8328 - val_loss: 0.3747\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8211 - loss: 0.4007 - val_accuracy: 0.8286 - val_loss: 0.3780\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8207 - loss: 0.4011 - val_accuracy: 0.8373 - val_loss: 0.3688\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8195 - loss: 0.4005 - val_accuracy: 0.8298 - val_loss: 0.3880\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8211 - loss: 0.4033 - val_accuracy: 0.8349 - val_loss: 0.3725\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8202 - loss: 0.3984 - val_accuracy: 0.8352 - val_loss: 0.3702\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8207 - loss: 0.4006 - val_accuracy: 0.8393 - val_loss: 0.3641\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8205 - loss: 0.3991 - val_accuracy: 0.8333 - val_loss: 0.3714\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8250 - loss: 0.3896 - val_accuracy: 0.8253 - val_loss: 0.3785\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8221 - loss: 0.3958 - val_accuracy: 0.8383 - val_loss: 0.3656\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8259 - loss: 0.3933 - val_accuracy: 0.8362 - val_loss: 0.3663\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8243 - loss: 0.3931 - val_accuracy: 0.8368 - val_loss: 0.3735\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8227 - loss: 0.3926 - val_accuracy: 0.8320 - val_loss: 0.3712\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8250 - loss: 0.3899 - val_accuracy: 0.8394 - val_loss: 0.3603\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8226 - loss: 0.3915 - val_accuracy: 0.8400 - val_loss: 0.3673\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8277 - loss: 0.3885 - val_accuracy: 0.8399 - val_loss: 0.3614\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8250 - loss: 0.3896 - val_accuracy: 0.8383 - val_loss: 0.3638\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8253 - loss: 0.3849 - val_accuracy: 0.8268 - val_loss: 0.3873\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8289 - loss: 0.3844 - val_accuracy: 0.8436 - val_loss: 0.3599\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8272 - loss: 0.3887 - val_accuracy: 0.8403 - val_loss: 0.3566\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8310 - loss: 0.3826 - val_accuracy: 0.8391 - val_loss: 0.3662\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8277 - loss: 0.3854 - val_accuracy: 0.8436 - val_loss: 0.3553\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8256 - loss: 0.3835 - val_accuracy: 0.8382 - val_loss: 0.3611\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8301 - loss: 0.3808 - val_accuracy: 0.8337 - val_loss: 0.3686\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8314 - loss: 0.3803 - val_accuracy: 0.8381 - val_loss: 0.3583\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8307 - loss: 0.3822 - val_accuracy: 0.8420 - val_loss: 0.3557\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8321 - loss: 0.3784 - val_accuracy: 0.8431 - val_loss: 0.3526\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8281 - loss: 0.3808 - val_accuracy: 0.8423 - val_loss: 0.3547\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8312 - loss: 0.3786 - val_accuracy: 0.8396 - val_loss: 0.3612\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8297 - loss: 0.3799 - val_accuracy: 0.8371 - val_loss: 0.3642\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8313 - loss: 0.3767 - val_accuracy: 0.8459 - val_loss: 0.3492\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8294 - loss: 0.3819 - val_accuracy: 0.8397 - val_loss: 0.3558\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8314 - loss: 0.3780 - val_accuracy: 0.8455 - val_loss: 0.3477\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.3586\n",
            "Test Loss: 0.3532\n",
            "Test Accuracy: 0.8457\n",
            "Confusion Matrix:\n",
            "[[6871 1067]\n",
            " [1508 7244]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84      7938\n",
            "           1       0.87      0.83      0.85      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8457\n",
            "Precision: 0.8716\n",
            "Recall: 0.8277\n",
            "F1 Score: 0.8491\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, GRU, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(GRU(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw_9CJ4IXwrF"
      },
      "source": [
        "improved DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbTOJScEXzNv",
        "outputId": "d5f43e7e-e9e7-4d8e-c27c-b24da044c4d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6713 - loss: 0.6446 - val_accuracy: 0.7849 - val_loss: 0.4553\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7695 - loss: 0.4885 - val_accuracy: 0.8008 - val_loss: 0.4378\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7842 - loss: 0.4619 - val_accuracy: 0.8065 - val_loss: 0.4274\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.4484 - val_accuracy: 0.8135 - val_loss: 0.4150\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.4338 - val_accuracy: 0.8182 - val_loss: 0.4152\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.4293 - val_accuracy: 0.8227 - val_loss: 0.4124\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.4300 - val_accuracy: 0.8287 - val_loss: 0.3969\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.4221 - val_accuracy: 0.8282 - val_loss: 0.3989\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.4169 - val_accuracy: 0.8287 - val_loss: 0.3980\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8079 - loss: 0.4210 - val_accuracy: 0.8337 - val_loss: 0.3844\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.4017 - val_accuracy: 0.8360 - val_loss: 0.3819\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 0.4074 - val_accuracy: 0.8370 - val_loss: 0.3744\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8183 - loss: 0.4016 - val_accuracy: 0.8411 - val_loss: 0.3761\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8227 - loss: 0.3997 - val_accuracy: 0.8385 - val_loss: 0.3788\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.3951 - val_accuracy: 0.8376 - val_loss: 0.3750\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.3926 - val_accuracy: 0.8309 - val_loss: 0.3763\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8263 - loss: 0.3887 - val_accuracy: 0.8428 - val_loss: 0.3633\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8256 - loss: 0.3913 - val_accuracy: 0.8446 - val_loss: 0.3619\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.3925 - val_accuracy: 0.8393 - val_loss: 0.3808\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8249 - loss: 0.3892 - val_accuracy: 0.8408 - val_loss: 0.3775\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8311 - loss: 0.3861 - val_accuracy: 0.8462 - val_loss: 0.3569\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8302 - loss: 0.3822 - val_accuracy: 0.8468 - val_loss: 0.3614\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.3817 - val_accuracy: 0.8471 - val_loss: 0.3592\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8322 - loss: 0.3837 - val_accuracy: 0.8497 - val_loss: 0.3529\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.3760 - val_accuracy: 0.8499 - val_loss: 0.3533\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3756 - val_accuracy: 0.8508 - val_loss: 0.3500\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.3798 - val_accuracy: 0.8527 - val_loss: 0.3564\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.3790 - val_accuracy: 0.8543 - val_loss: 0.3533\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.3742 - val_accuracy: 0.8417 - val_loss: 0.3571\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.3769 - val_accuracy: 0.8480 - val_loss: 0.3629\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.3768 - val_accuracy: 0.8546 - val_loss: 0.3492\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8304 - loss: 0.3788 - val_accuracy: 0.8531 - val_loss: 0.3473\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8352 - loss: 0.3693 - val_accuracy: 0.8361 - val_loss: 0.3981\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3727 - val_accuracy: 0.8525 - val_loss: 0.3548\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8353 - loss: 0.3680 - val_accuracy: 0.8498 - val_loss: 0.3538\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8316 - loss: 0.3761 - val_accuracy: 0.8406 - val_loss: 0.3628\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.3692 - val_accuracy: 0.8522 - val_loss: 0.3632\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.3668 - val_accuracy: 0.8519 - val_loss: 0.3472\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.3705 - val_accuracy: 0.8507 - val_loss: 0.3538\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8376 - loss: 0.3678 - val_accuracy: 0.8599 - val_loss: 0.3346\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8366 - loss: 0.3656 - val_accuracy: 0.8530 - val_loss: 0.3456\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.3694 - val_accuracy: 0.8552 - val_loss: 0.3407\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.3663 - val_accuracy: 0.8475 - val_loss: 0.3450\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3651 - val_accuracy: 0.8572 - val_loss: 0.3439\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8394 - loss: 0.3648 - val_accuracy: 0.8468 - val_loss: 0.3728\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8428 - loss: 0.3636 - val_accuracy: 0.8553 - val_loss: 0.3381\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8390 - loss: 0.3608 - val_accuracy: 0.8490 - val_loss: 0.3532\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8401 - loss: 0.3654 - val_accuracy: 0.8526 - val_loss: 0.3621\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.3613 - val_accuracy: 0.8561 - val_loss: 0.3527\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8391 - loss: 0.3667 - val_accuracy: 0.8515 - val_loss: 0.3490\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8582 - loss: 0.3310\n",
            "Test Loss: 0.3331\n",
            "Test Accuracy: 0.8573\n",
            "Confusion Matrix:\n",
            "[[6745 1193]\n",
            " [1189 7563]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85      7938\n",
            "           1       0.86      0.86      0.86      8752\n",
            "\n",
            "    accuracy                           0.86     16690\n",
            "   macro avg       0.86      0.86      0.86     16690\n",
            "weighted avg       0.86      0.86      0.86     16690\n",
            "\n",
            "Accuracy: 0.8573\n",
            "Precision: 0.8638\n",
            "Recall: 0.8641\n",
            "F1 Score: 0.8639\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the DNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input and hidden layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZY_UNNjYORL"
      },
      "source": [
        "improved dnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nflkIrA4YRq0",
        "outputId": "f94d65a0-6d6e-40bb-bee7-779a9b11c862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 20ms/step - accuracy: 0.5924 - loss: 0.6782 - val_accuracy: 0.6893 - val_loss: 0.5881\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.7017 - loss: 0.5821 - val_accuracy: 0.7065 - val_loss: 0.5569\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7279 - loss: 0.5560 - val_accuracy: 0.7400 - val_loss: 0.5251\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - accuracy: 0.7324 - loss: 0.5469 - val_accuracy: 0.7501 - val_loss: 0.5216\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7387 - loss: 0.5394 - val_accuracy: 0.7470 - val_loss: 0.5166\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.7433 - loss: 0.5316 - val_accuracy: 0.7495 - val_loss: 0.5060\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - accuracy: 0.7507 - loss: 0.5197 - val_accuracy: 0.7532 - val_loss: 0.5047\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7498 - loss: 0.5204 - val_accuracy: 0.7633 - val_loss: 0.4907\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.7592 - loss: 0.5057 - val_accuracy: 0.7958 - val_loss: 0.4553\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.7755 - loss: 0.4788 - val_accuracy: 0.7949 - val_loss: 0.4458\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7925 - loss: 0.4622 - val_accuracy: 0.7997 - val_loss: 0.4308\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.7989 - loss: 0.4497 - val_accuracy: 0.7836 - val_loss: 0.4671\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8014 - loss: 0.4465 - val_accuracy: 0.8146 - val_loss: 0.4109\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.8075 - loss: 0.4378 - val_accuracy: 0.8174 - val_loss: 0.4092\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8060 - loss: 0.4348 - val_accuracy: 0.8137 - val_loss: 0.4235\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8049 - loss: 0.4413 - val_accuracy: 0.8164 - val_loss: 0.4096\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.8122 - loss: 0.4261 - val_accuracy: 0.8121 - val_loss: 0.4061\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8136 - loss: 0.4263 - val_accuracy: 0.8163 - val_loss: 0.4097\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8125 - loss: 0.4226 - val_accuracy: 0.8261 - val_loss: 0.4005\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8164 - loss: 0.4205 - val_accuracy: 0.8188 - val_loss: 0.4016\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.8179 - loss: 0.4187 - val_accuracy: 0.8183 - val_loss: 0.4051\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8163 - loss: 0.4176 - val_accuracy: 0.8270 - val_loss: 0.3883\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8193 - loss: 0.4136 - val_accuracy: 0.8302 - val_loss: 0.3900\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8146 - loss: 0.4199 - val_accuracy: 0.8229 - val_loss: 0.3937\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8221 - loss: 0.4126 - val_accuracy: 0.8290 - val_loss: 0.3840\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.8194 - loss: 0.4082 - val_accuracy: 0.8252 - val_loss: 0.3970\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8214 - loss: 0.4073 - val_accuracy: 0.8314 - val_loss: 0.3818\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8207 - loss: 0.4072 - val_accuracy: 0.8236 - val_loss: 0.3960\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8236 - loss: 0.4023 - val_accuracy: 0.8281 - val_loss: 0.3812\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8275 - loss: 0.3976 - val_accuracy: 0.8261 - val_loss: 0.3913\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8265 - loss: 0.4011 - val_accuracy: 0.8328 - val_loss: 0.3802\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8211 - loss: 0.4027 - val_accuracy: 0.8241 - val_loss: 0.3848\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.8275 - loss: 0.3965 - val_accuracy: 0.8358 - val_loss: 0.3753\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8279 - loss: 0.3937 - val_accuracy: 0.8343 - val_loss: 0.3727\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8341 - loss: 0.3879 - val_accuracy: 0.8155 - val_loss: 0.3966\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8311 - loss: 0.3917 - val_accuracy: 0.8377 - val_loss: 0.3690\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8295 - loss: 0.3915 - val_accuracy: 0.8390 - val_loss: 0.3689\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8298 - loss: 0.3904 - val_accuracy: 0.8304 - val_loss: 0.3799\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - accuracy: 0.8286 - loss: 0.3911 - val_accuracy: 0.8390 - val_loss: 0.3655\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8295 - loss: 0.3889 - val_accuracy: 0.8402 - val_loss: 0.3642\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8329 - loss: 0.3834 - val_accuracy: 0.8367 - val_loss: 0.3657\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8339 - loss: 0.3804 - val_accuracy: 0.8359 - val_loss: 0.3749\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.8314 - loss: 0.3845 - val_accuracy: 0.8392 - val_loss: 0.3661\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8326 - loss: 0.3814 - val_accuracy: 0.8421 - val_loss: 0.3639\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8379 - loss: 0.3769 - val_accuracy: 0.8385 - val_loss: 0.3591\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8334 - loss: 0.3782 - val_accuracy: 0.8391 - val_loss: 0.3591\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8336 - loss: 0.3804 - val_accuracy: 0.8372 - val_loss: 0.3646\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.8341 - loss: 0.3792 - val_accuracy: 0.8359 - val_loss: 0.3625\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 21ms/step - accuracy: 0.8380 - loss: 0.3771 - val_accuracy: 0.8382 - val_loss: 0.3579\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 19ms/step - accuracy: 0.8379 - loss: 0.3739 - val_accuracy: 0.8446 - val_loss: 0.3530\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 0.3607\n",
            "Test Loss: 0.3583\n",
            "Test Accuracy: 0.8421\n",
            "Confusion Matrix:\n",
            "[[6650 1288]\n",
            " [1347 7405]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.83      7938\n",
            "           1       0.85      0.85      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8421\n",
            "Precision: 0.8518\n",
            "Recall: 0.8461\n",
            "F1 Score: 0.8490\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm_XrzveegPa"
      },
      "source": [
        "improved dnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvzUO8n4eirA",
        "outputId": "aaf8e591-0163-45f6-8862-ee449448a6c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 28ms/step - accuracy: 0.5710 - loss: 0.7430 - val_accuracy: 0.6872 - val_loss: 0.5912\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 28ms/step - accuracy: 0.6904 - loss: 0.5849 - val_accuracy: 0.7109 - val_loss: 0.5591\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 29ms/step - accuracy: 0.7389 - loss: 0.5292 - val_accuracy: 0.7762 - val_loss: 0.4799\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 28ms/step - accuracy: 0.7648 - loss: 0.4933 - val_accuracy: 0.7951 - val_loss: 0.4495\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 29ms/step - accuracy: 0.7776 - loss: 0.4741 - val_accuracy: 0.8092 - val_loss: 0.4234\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 28ms/step - accuracy: 0.7922 - loss: 0.4568 - val_accuracy: 0.8137 - val_loss: 0.4096\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - accuracy: 0.7944 - loss: 0.4497 - val_accuracy: 0.8128 - val_loss: 0.4163\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 29ms/step - accuracy: 0.8013 - loss: 0.4380 - val_accuracy: 0.8168 - val_loss: 0.4088\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - accuracy: 0.8035 - loss: 0.4344 - val_accuracy: 0.8202 - val_loss: 0.3996\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 29ms/step - accuracy: 0.8090 - loss: 0.4247 - val_accuracy: 0.8272 - val_loss: 0.3850\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 28ms/step - accuracy: 0.8062 - loss: 0.4229 - val_accuracy: 0.8276 - val_loss: 0.3876\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 28ms/step - accuracy: 0.8094 - loss: 0.4176 - val_accuracy: 0.8212 - val_loss: 0.3949\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 28ms/step - accuracy: 0.8155 - loss: 0.4112 - val_accuracy: 0.8352 - val_loss: 0.3759\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 28ms/step - accuracy: 0.8122 - loss: 0.4159 - val_accuracy: 0.8269 - val_loss: 0.3890\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 29ms/step - accuracy: 0.8204 - loss: 0.4052 - val_accuracy: 0.8344 - val_loss: 0.3787\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 29ms/step - accuracy: 0.8194 - loss: 0.4005 - val_accuracy: 0.8370 - val_loss: 0.3683\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 28ms/step - accuracy: 0.8230 - loss: 0.3966 - val_accuracy: 0.8337 - val_loss: 0.3731\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 28ms/step - accuracy: 0.8212 - loss: 0.3989 - val_accuracy: 0.8359 - val_loss: 0.3687\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - accuracy: 0.8213 - loss: 0.3971 - val_accuracy: 0.8326 - val_loss: 0.3734\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 28ms/step - accuracy: 0.8250 - loss: 0.3938 - val_accuracy: 0.8374 - val_loss: 0.3668\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 27ms/step - accuracy: 0.8309 - loss: 0.3846 - val_accuracy: 0.8394 - val_loss: 0.3706\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 28ms/step - accuracy: 0.8287 - loss: 0.3860 - val_accuracy: 0.8358 - val_loss: 0.3737\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 27ms/step - accuracy: 0.8304 - loss: 0.3822 - val_accuracy: 0.8422 - val_loss: 0.3587\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 28ms/step - accuracy: 0.8286 - loss: 0.3862 - val_accuracy: 0.8460 - val_loss: 0.3562\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 28ms/step - accuracy: 0.8308 - loss: 0.3775 - val_accuracy: 0.8465 - val_loss: 0.3552\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 28ms/step - accuracy: 0.8307 - loss: 0.3846 - val_accuracy: 0.8364 - val_loss: 0.3728\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 28ms/step - accuracy: 0.8295 - loss: 0.3828 - val_accuracy: 0.8415 - val_loss: 0.3573\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 27ms/step - accuracy: 0.8336 - loss: 0.3768 - val_accuracy: 0.8459 - val_loss: 0.3527\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 28ms/step - accuracy: 0.8366 - loss: 0.3722 - val_accuracy: 0.8446 - val_loss: 0.3563\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - accuracy: 0.8378 - loss: 0.3714 - val_accuracy: 0.8481 - val_loss: 0.3490\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 28ms/step - accuracy: 0.8366 - loss: 0.3743 - val_accuracy: 0.8381 - val_loss: 0.3561\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 28ms/step - accuracy: 0.8363 - loss: 0.3751 - val_accuracy: 0.8268 - val_loss: 0.3932\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 29ms/step - accuracy: 0.8372 - loss: 0.3676 - val_accuracy: 0.8440 - val_loss: 0.3550\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - accuracy: 0.8351 - loss: 0.3700 - val_accuracy: 0.8445 - val_loss: 0.3472\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 28ms/step - accuracy: 0.8397 - loss: 0.3653 - val_accuracy: 0.8459 - val_loss: 0.3520\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 28ms/step - accuracy: 0.8405 - loss: 0.3657 - val_accuracy: 0.8500 - val_loss: 0.3467\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 28ms/step - accuracy: 0.8435 - loss: 0.3606 - val_accuracy: 0.8502 - val_loss: 0.3450\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 28ms/step - accuracy: 0.8343 - loss: 0.3694 - val_accuracy: 0.8511 - val_loss: 0.3394\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - accuracy: 0.8417 - loss: 0.3569 - val_accuracy: 0.8503 - val_loss: 0.3427\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 29ms/step - accuracy: 0.8411 - loss: 0.3626 - val_accuracy: 0.8475 - val_loss: 0.3472\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 28ms/step - accuracy: 0.8406 - loss: 0.3617 - val_accuracy: 0.8133 - val_loss: 0.4183\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 29ms/step - accuracy: 0.8443 - loss: 0.3566 - val_accuracy: 0.8483 - val_loss: 0.3430\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 28ms/step - accuracy: 0.8454 - loss: 0.3550 - val_accuracy: 0.8483 - val_loss: 0.3456\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 27ms/step - accuracy: 0.8426 - loss: 0.3596 - val_accuracy: 0.8534 - val_loss: 0.3378\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 28ms/step - accuracy: 0.8448 - loss: 0.3537 - val_accuracy: 0.8492 - val_loss: 0.3415\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - accuracy: 0.8473 - loss: 0.3484 - val_accuracy: 0.8428 - val_loss: 0.3592\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 28ms/step - accuracy: 0.8410 - loss: 0.3571 - val_accuracy: 0.8512 - val_loss: 0.3409\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 28ms/step - accuracy: 0.8473 - loss: 0.3542 - val_accuracy: 0.8523 - val_loss: 0.3383\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 28ms/step - accuracy: 0.8453 - loss: 0.3523 - val_accuracy: 0.8367 - val_loss: 0.3601\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - accuracy: 0.8462 - loss: 0.3500 - val_accuracy: 0.8524 - val_loss: 0.3375\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8591 - loss: 0.3349\n",
            "Test Loss: 0.3343\n",
            "Test Accuracy: 0.8571\n",
            "Confusion Matrix:\n",
            "[[7041  897]\n",
            " [1488 7264]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.89      0.86      7938\n",
            "           1       0.89      0.83      0.86      8752\n",
            "\n",
            "    accuracy                           0.86     16690\n",
            "   macro avg       0.86      0.86      0.86     16690\n",
            "weighted avg       0.86      0.86      0.86     16690\n",
            "\n",
            "Accuracy: 0.8571\n",
            "Precision: 0.8901\n",
            "Recall: 0.8300\n",
            "F1 Score: 0.8590\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Reshape output from Dense layers to be suitable for GRU layers\n",
        "model.add(tf.keras.layers.Reshape((X_train_reshaped.shape[1], 32)))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxvZ7ER6DHv2"
      },
      "source": [
        "##Extra Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLFXZ2J86abR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "bfbdb2c9-dfc5-482e-b931-f334e6ec5b78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "                        Feature  Importance\n",
            "3   Repititive-Words-in-a-Email    0.132370\n",
            "11                Neu-Sentiment    0.105212\n",
            "9                  Spam lexicon    0.089922\n",
            "4       Uinque-Words-in-a-Email    0.082214\n",
            "12                Pos-Sentiment    0.073654\n",
            "1               Length-of-Email    0.071235\n",
            "7   Number of co-occuring words    0.070482\n",
            "8                Number-of-noun    0.066480\n",
            "15                   Subjective    0.065552\n",
            "14                     Polarity    0.065409\n",
            "10                Neg-Sentiment    0.060965\n",
            "13               Comp-Sentiment    0.054855\n",
            "0                    Unnamed: 0    0.034896\n",
            "6     Question-Marks-in-a-Email    0.021821\n",
            "5        Quoted-text-in-a-Email    0.004919\n",
            "2   Number of capitalized words    0.000013\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data=df.copy()\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label','Unnamed: 0'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the Extra Trees Classifier\n",
        "clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display feature importances\n",
        "print(\"Feature Importances:\")\n",
        "print(feature_importances)\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
        "plt.title('Feature Importances from Extra Trees Classifier')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj4oSvX2GPNF"
      },
      "source": [
        "10-Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfhKto9L8FAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8123825-3587-42ce-9101-a2f5aeb64927"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Repititive-Words-in-a-Email',\n",
              " 'Neu-Sentiment',\n",
              " 'Spam lexicon',\n",
              " 'Uinque-Words-in-a-Email',\n",
              " 'Pos-Sentiment',\n",
              " 'Length-of-Email',\n",
              " 'Number of co-occuring words',\n",
              " 'Number-of-noun',\n",
              " 'Subjective',\n",
              " 'Polarity']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "features=feature_importances.nlargest(n=10, columns='Importance')['Feature'].to_list()\n",
        "features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_SbNNKfwu5Z"
      },
      "source": [
        "improved rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8TUO8Utwu5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36773378-9fb4-4091-e56d-ada734d9c531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.7004 - loss: 0.5792 - val_accuracy: 0.7905 - val_loss: 0.4492\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7790 - loss: 0.4776 - val_accuracy: 0.7970 - val_loss: 0.4390\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7901 - loss: 0.4586 - val_accuracy: 0.8119 - val_loss: 0.4244\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7963 - loss: 0.4487 - val_accuracy: 0.8038 - val_loss: 0.4286\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8026 - loss: 0.4422 - val_accuracy: 0.8093 - val_loss: 0.4130\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8063 - loss: 0.4358 - val_accuracy: 0.8133 - val_loss: 0.4138\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8058 - loss: 0.4304 - val_accuracy: 0.8135 - val_loss: 0.4158\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8100 - loss: 0.4208 - val_accuracy: 0.7976 - val_loss: 0.4408\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8093 - loss: 0.4245 - val_accuracy: 0.8124 - val_loss: 0.4107\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8117 - loss: 0.4175 - val_accuracy: 0.8195 - val_loss: 0.4026\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8123 - loss: 0.4161 - val_accuracy: 0.8203 - val_loss: 0.3959\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8140 - loss: 0.4127 - val_accuracy: 0.8259 - val_loss: 0.3965\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8173 - loss: 0.4103 - val_accuracy: 0.8226 - val_loss: 0.4021\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8179 - loss: 0.4111 - val_accuracy: 0.8222 - val_loss: 0.3945\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8177 - loss: 0.4027 - val_accuracy: 0.8284 - val_loss: 0.3814\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8216 - loss: 0.3965 - val_accuracy: 0.8107 - val_loss: 0.3986\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8208 - loss: 0.4002 - val_accuracy: 0.8174 - val_loss: 0.3937\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8178 - loss: 0.4032 - val_accuracy: 0.8152 - val_loss: 0.3952\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8200 - loss: 0.4012 - val_accuracy: 0.8238 - val_loss: 0.3894\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8268 - loss: 0.3936 - val_accuracy: 0.8153 - val_loss: 0.4050\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8226 - loss: 0.3972 - val_accuracy: 0.8218 - val_loss: 0.3944\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8240 - loss: 0.3955 - val_accuracy: 0.8193 - val_loss: 0.4000\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8254 - loss: 0.3911 - val_accuracy: 0.8280 - val_loss: 0.3911\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8292 - loss: 0.3903 - val_accuracy: 0.8258 - val_loss: 0.3849\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8292 - loss: 0.3905 - val_accuracy: 0.8298 - val_loss: 0.3806\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8284 - loss: 0.3852 - val_accuracy: 0.8346 - val_loss: 0.3790\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8305 - loss: 0.3867 - val_accuracy: 0.8277 - val_loss: 0.3784\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8266 - loss: 0.3913 - val_accuracy: 0.8307 - val_loss: 0.3757\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8285 - loss: 0.3858 - val_accuracy: 0.8345 - val_loss: 0.3739\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8315 - loss: 0.3825 - val_accuracy: 0.8274 - val_loss: 0.3807\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8310 - loss: 0.3833 - val_accuracy: 0.8274 - val_loss: 0.3792\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8310 - loss: 0.3821 - val_accuracy: 0.8390 - val_loss: 0.3680\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8314 - loss: 0.3851 - val_accuracy: 0.8365 - val_loss: 0.3681\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8340 - loss: 0.3775 - val_accuracy: 0.8333 - val_loss: 0.3710\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8360 - loss: 0.3755 - val_accuracy: 0.8323 - val_loss: 0.3799\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8346 - loss: 0.3752 - val_accuracy: 0.8349 - val_loss: 0.3733\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8356 - loss: 0.3766 - val_accuracy: 0.8358 - val_loss: 0.3741\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8339 - loss: 0.3728 - val_accuracy: 0.8373 - val_loss: 0.3676\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8382 - loss: 0.3716 - val_accuracy: 0.8360 - val_loss: 0.3668\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8328 - loss: 0.3746 - val_accuracy: 0.8418 - val_loss: 0.3607\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8408 - loss: 0.3672 - val_accuracy: 0.8392 - val_loss: 0.3640\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8364 - loss: 0.3748 - val_accuracy: 0.8373 - val_loss: 0.3680\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8349 - loss: 0.3740 - val_accuracy: 0.8396 - val_loss: 0.3660\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8393 - loss: 0.3668 - val_accuracy: 0.8399 - val_loss: 0.3634\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8348 - loss: 0.3719 - val_accuracy: 0.8377 - val_loss: 0.3636\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8422 - loss: 0.3619 - val_accuracy: 0.8378 - val_loss: 0.3668\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.3652 - val_accuracy: 0.8358 - val_loss: 0.3627\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.3672 - val_accuracy: 0.8309 - val_loss: 0.3794\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8429 - loss: 0.3601 - val_accuracy: 0.8426 - val_loss: 0.3613\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8393 - loss: 0.3656 - val_accuracy: 0.8389 - val_loss: 0.3680\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.3632\n",
            "Test Loss: 0.3619\n",
            "Test Accuracy: 0.8416\n",
            "Confusion Matrix:\n",
            "[[6476 1462]\n",
            " [1181 7571]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.82      0.83      7938\n",
            "           1       0.84      0.87      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8416\n",
            "Precision: 0.8381\n",
            "Recall: 0.8651\n",
            "F1 Score: 0.8514\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# RNN layers\n",
        "model.add(SimpleRNN(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(SimpleRNN(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAecFGFHwu5b"
      },
      "source": [
        "improved rnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1ed1r3lwu5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a18a2b4f-3f37-45e8-8a35-cf8a4605dcfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.6308 - loss: 0.6546 - val_accuracy: 0.7283 - val_loss: 0.5528\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.7183 - loss: 0.5650 - val_accuracy: 0.7634 - val_loss: 0.4952\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.7552 - loss: 0.5130 - val_accuracy: 0.7864 - val_loss: 0.4639\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7674 - loss: 0.4934 - val_accuracy: 0.7836 - val_loss: 0.4640\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.7830 - loss: 0.4717 - val_accuracy: 0.7940 - val_loss: 0.4384\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7855 - loss: 0.4669 - val_accuracy: 0.8024 - val_loss: 0.4346\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7934 - loss: 0.4538 - val_accuracy: 0.7946 - val_loss: 0.4490\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7957 - loss: 0.4501 - val_accuracy: 0.8050 - val_loss: 0.4226\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8027 - loss: 0.4407 - val_accuracy: 0.8141 - val_loss: 0.4195\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8023 - loss: 0.4382 - val_accuracy: 0.8099 - val_loss: 0.4172\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8023 - loss: 0.4371 - val_accuracy: 0.8083 - val_loss: 0.4206\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8024 - loss: 0.4336 - val_accuracy: 0.8142 - val_loss: 0.4136\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8072 - loss: 0.4265 - val_accuracy: 0.8057 - val_loss: 0.4159\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8079 - loss: 0.4256 - val_accuracy: 0.8127 - val_loss: 0.4149\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8095 - loss: 0.4248 - val_accuracy: 0.8069 - val_loss: 0.4189\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8104 - loss: 0.4247 - val_accuracy: 0.8157 - val_loss: 0.4093\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8099 - loss: 0.4209 - val_accuracy: 0.8239 - val_loss: 0.4029\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8132 - loss: 0.4185 - val_accuracy: 0.8160 - val_loss: 0.4032\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8135 - loss: 0.4136 - val_accuracy: 0.8236 - val_loss: 0.3968\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8167 - loss: 0.4120 - val_accuracy: 0.8145 - val_loss: 0.4110\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8154 - loss: 0.4112 - val_accuracy: 0.8232 - val_loss: 0.3918\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8195 - loss: 0.4092 - val_accuracy: 0.8139 - val_loss: 0.4004\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8166 - loss: 0.4091 - val_accuracy: 0.8152 - val_loss: 0.4021\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8154 - loss: 0.4102 - val_accuracy: 0.8249 - val_loss: 0.3907\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8140 - loss: 0.4069 - val_accuracy: 0.8158 - val_loss: 0.4033\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8204 - loss: 0.4041 - val_accuracy: 0.8246 - val_loss: 0.3887\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8227 - loss: 0.3988 - val_accuracy: 0.8272 - val_loss: 0.3900\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8213 - loss: 0.4023 - val_accuracy: 0.8260 - val_loss: 0.3857\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8215 - loss: 0.4008 - val_accuracy: 0.8267 - val_loss: 0.3904\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8226 - loss: 0.4026 - val_accuracy: 0.8289 - val_loss: 0.3814\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8230 - loss: 0.4009 - val_accuracy: 0.8253 - val_loss: 0.3918\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8238 - loss: 0.3961 - val_accuracy: 0.8306 - val_loss: 0.3795\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8237 - loss: 0.3922 - val_accuracy: 0.8006 - val_loss: 0.4164\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8211 - loss: 0.3973 - val_accuracy: 0.8349 - val_loss: 0.3744\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8251 - loss: 0.3967 - val_accuracy: 0.8308 - val_loss: 0.3775\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8268 - loss: 0.3906 - val_accuracy: 0.8328 - val_loss: 0.3792\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8286 - loss: 0.3883 - val_accuracy: 0.8289 - val_loss: 0.3783\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8295 - loss: 0.3864 - val_accuracy: 0.8368 - val_loss: 0.3700\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - accuracy: 0.8261 - loss: 0.3901 - val_accuracy: 0.8382 - val_loss: 0.3719\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8318 - loss: 0.3829 - val_accuracy: 0.8346 - val_loss: 0.3728\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8263 - loss: 0.3894 - val_accuracy: 0.8336 - val_loss: 0.3716\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8330 - loss: 0.3800 - val_accuracy: 0.8330 - val_loss: 0.3723\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8319 - loss: 0.3835 - val_accuracy: 0.8328 - val_loss: 0.3726\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8321 - loss: 0.3852 - val_accuracy: 0.8352 - val_loss: 0.3704\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8312 - loss: 0.3830 - val_accuracy: 0.8380 - val_loss: 0.3694\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8284 - loss: 0.3856 - val_accuracy: 0.8343 - val_loss: 0.3748\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8346 - loss: 0.3769 - val_accuracy: 0.8343 - val_loss: 0.3742\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8339 - loss: 0.3775 - val_accuracy: 0.8320 - val_loss: 0.3731\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8324 - loss: 0.3808 - val_accuracy: 0.8366 - val_loss: 0.3692\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8335 - loss: 0.3815 - val_accuracy: 0.8346 - val_loss: 0.3774\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8326 - loss: 0.3781\n",
            "Test Loss: 0.3726\n",
            "Test Accuracy: 0.8365\n",
            "Confusion Matrix:\n",
            "[[6833 1105]\n",
            " [1623 7129]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.83      7938\n",
            "           1       0.87      0.81      0.84      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8365\n",
            "Precision: 0.8658\n",
            "Recall: 0.8146\n",
            "F1 Score: 0.8394\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu1ntDNBwu5b"
      },
      "source": [
        "improved rnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6djyPTyxwu5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2372c58c-c8df-4692-8582-6f3fd1caede3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 15ms/step - accuracy: 0.5983 - loss: 0.6980 - val_accuracy: 0.7522 - val_loss: 0.5282\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.7386 - loss: 0.5376 - val_accuracy: 0.7675 - val_loss: 0.4815\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.7757 - loss: 0.4821 - val_accuracy: 0.7861 - val_loss: 0.4673\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.7926 - loss: 0.4603 - val_accuracy: 0.7772 - val_loss: 0.4655\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.7945 - loss: 0.4542 - val_accuracy: 0.7916 - val_loss: 0.4528\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.7930 - loss: 0.4492 - val_accuracy: 0.7516 - val_loss: 0.4905\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8016 - loss: 0.4400 - val_accuracy: 0.8072 - val_loss: 0.4258\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step - accuracy: 0.8010 - loss: 0.4397 - val_accuracy: 0.8174 - val_loss: 0.4140\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8049 - loss: 0.4350 - val_accuracy: 0.8208 - val_loss: 0.4064\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8041 - loss: 0.4340 - val_accuracy: 0.8119 - val_loss: 0.4169\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8080 - loss: 0.4285 - val_accuracy: 0.8015 - val_loss: 0.4680\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8089 - loss: 0.4238 - val_accuracy: 0.8248 - val_loss: 0.3989\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8115 - loss: 0.4196 - val_accuracy: 0.8123 - val_loss: 0.4066\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8127 - loss: 0.4168 - val_accuracy: 0.8155 - val_loss: 0.3992\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8150 - loss: 0.4162 - val_accuracy: 0.8276 - val_loss: 0.3911\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8126 - loss: 0.4166 - val_accuracy: 0.8221 - val_loss: 0.4029\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8133 - loss: 0.4155 - val_accuracy: 0.8288 - val_loss: 0.3942\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8129 - loss: 0.4126 - val_accuracy: 0.8258 - val_loss: 0.3922\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step - accuracy: 0.8152 - loss: 0.4059 - val_accuracy: 0.7998 - val_loss: 0.4160\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8188 - loss: 0.4063 - val_accuracy: 0.8295 - val_loss: 0.3869\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8175 - loss: 0.4063 - val_accuracy: 0.7886 - val_loss: 0.4880\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8170 - loss: 0.4053 - val_accuracy: 0.8271 - val_loss: 0.3843\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8217 - loss: 0.4027 - val_accuracy: 0.8322 - val_loss: 0.3785\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8211 - loss: 0.4024 - val_accuracy: 0.8326 - val_loss: 0.3753\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8222 - loss: 0.3987 - val_accuracy: 0.8270 - val_loss: 0.3852\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8217 - loss: 0.4010 - val_accuracy: 0.8305 - val_loss: 0.3826\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8225 - loss: 0.3995 - val_accuracy: 0.8331 - val_loss: 0.3798\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8237 - loss: 0.3968 - val_accuracy: 0.8355 - val_loss: 0.3708\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8267 - loss: 0.3951 - val_accuracy: 0.8290 - val_loss: 0.3876\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8225 - loss: 0.3981 - val_accuracy: 0.8316 - val_loss: 0.3797\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8258 - loss: 0.3945 - val_accuracy: 0.8353 - val_loss: 0.3728\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8260 - loss: 0.3925 - val_accuracy: 0.8359 - val_loss: 0.3697\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8245 - loss: 0.3967 - val_accuracy: 0.8339 - val_loss: 0.3785\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8265 - loss: 0.3912 - val_accuracy: 0.8373 - val_loss: 0.3669\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8259 - loss: 0.3894 - val_accuracy: 0.8355 - val_loss: 0.3677\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8237 - loss: 0.3931 - val_accuracy: 0.8309 - val_loss: 0.3760\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8276 - loss: 0.3913 - val_accuracy: 0.8324 - val_loss: 0.3726\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8309 - loss: 0.3864 - val_accuracy: 0.8349 - val_loss: 0.3669\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8259 - loss: 0.3898 - val_accuracy: 0.8343 - val_loss: 0.3682\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.8295 - loss: 0.3875 - val_accuracy: 0.8085 - val_loss: 0.3954\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8302 - loss: 0.3868 - val_accuracy: 0.8298 - val_loss: 0.3752\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8320 - loss: 0.3846 - val_accuracy: 0.8334 - val_loss: 0.3765\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8318 - loss: 0.3797 - val_accuracy: 0.8364 - val_loss: 0.3683\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8315 - loss: 0.3803 - val_accuracy: 0.8358 - val_loss: 0.3671\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8381 - loss: 0.3732\n",
            "Test Loss: 0.3698\n",
            "Test Accuracy: 0.8403\n",
            "Confusion Matrix:\n",
            "[[6708 1230]\n",
            " [1436 7316]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.83      7938\n",
            "           1       0.86      0.84      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8403\n",
            "Precision: 0.8561\n",
            "Recall: 0.8359\n",
            "F1 Score: 0.8459\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvVVznXN4VmD"
      },
      "source": [
        "improved cnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5HCFPZM4VmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b175d71-e165-4314-819b-b4da70859d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6668 - loss: 0.6363 - val_accuracy: 0.7829 - val_loss: 0.4747\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7557 - loss: 0.5081 - val_accuracy: 0.7872 - val_loss: 0.4547\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7698 - loss: 0.4866 - val_accuracy: 0.7971 - val_loss: 0.4396\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.4708 - val_accuracy: 0.7932 - val_loss: 0.4380\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.4677 - val_accuracy: 0.7925 - val_loss: 0.4420\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7852 - loss: 0.4621 - val_accuracy: 0.7893 - val_loss: 0.4478\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7900 - loss: 0.4526 - val_accuracy: 0.8024 - val_loss: 0.4210\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.7911 - loss: 0.4491 - val_accuracy: 0.8040 - val_loss: 0.4200\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.4520 - val_accuracy: 0.8080 - val_loss: 0.4183\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.4430 - val_accuracy: 0.8048 - val_loss: 0.4192\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.4482 - val_accuracy: 0.8086 - val_loss: 0.4115\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7957 - loss: 0.4431 - val_accuracy: 0.8102 - val_loss: 0.4131\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4379 - val_accuracy: 0.8091 - val_loss: 0.4095\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7975 - loss: 0.4437 - val_accuracy: 0.8143 - val_loss: 0.4097\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4355 - val_accuracy: 0.8089 - val_loss: 0.4098\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4363 - val_accuracy: 0.8119 - val_loss: 0.4070\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.4343 - val_accuracy: 0.8161 - val_loss: 0.4058\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4322 - val_accuracy: 0.8124 - val_loss: 0.4032\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8001 - loss: 0.4331 - val_accuracy: 0.8104 - val_loss: 0.4101\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.4328 - val_accuracy: 0.8141 - val_loss: 0.4037\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4337 - val_accuracy: 0.8000 - val_loss: 0.4250\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4281 - val_accuracy: 0.8162 - val_loss: 0.4043\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4295 - val_accuracy: 0.8152 - val_loss: 0.3995\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4271 - val_accuracy: 0.8086 - val_loss: 0.4161\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8033 - loss: 0.4271 - val_accuracy: 0.8167 - val_loss: 0.4037\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4224 - val_accuracy: 0.8188 - val_loss: 0.3987\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.4246 - val_accuracy: 0.8167 - val_loss: 0.4014\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4300 - val_accuracy: 0.8182 - val_loss: 0.3981\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4237 - val_accuracy: 0.8183 - val_loss: 0.3971\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4268 - val_accuracy: 0.8173 - val_loss: 0.3965\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8082 - loss: 0.4204 - val_accuracy: 0.8173 - val_loss: 0.3967\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.4270 - val_accuracy: 0.8176 - val_loss: 0.3966\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.4200 - val_accuracy: 0.8199 - val_loss: 0.3952\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.4214 - val_accuracy: 0.8113 - val_loss: 0.4166\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4251 - val_accuracy: 0.8182 - val_loss: 0.3975\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.4248 - val_accuracy: 0.8175 - val_loss: 0.3974\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4236 - val_accuracy: 0.8170 - val_loss: 0.3966\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4212 - val_accuracy: 0.8168 - val_loss: 0.3978\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8089 - loss: 0.4203 - val_accuracy: 0.8176 - val_loss: 0.4019\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.4227 - val_accuracy: 0.8192 - val_loss: 0.3940\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.4238 - val_accuracy: 0.8202 - val_loss: 0.3931\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.4222 - val_accuracy: 0.8155 - val_loss: 0.3962\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4232 - val_accuracy: 0.8207 - val_loss: 0.3919\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4195 - val_accuracy: 0.8223 - val_loss: 0.3926\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4212 - val_accuracy: 0.8207 - val_loss: 0.3984\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8060 - loss: 0.4227 - val_accuracy: 0.8191 - val_loss: 0.3988\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8106 - loss: 0.4192 - val_accuracy: 0.8175 - val_loss: 0.3992\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.4168 - val_accuracy: 0.8239 - val_loss: 0.3925\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.4163 - val_accuracy: 0.8182 - val_loss: 0.3980\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8077 - loss: 0.4235 - val_accuracy: 0.8212 - val_loss: 0.3918\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.3925\n",
            "Test Loss: 0.3898\n",
            "Test Accuracy: 0.8267\n",
            "Confusion Matrix:\n",
            "[[6492 1446]\n",
            " [1446 7306]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82      7938\n",
            "           1       0.83      0.83      0.83      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8267\n",
            "Precision: 0.8348\n",
            "Recall: 0.8348\n",
            "F1 Score: 0.8348\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the optimized CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnjzIn8v4VmE"
      },
      "source": [
        "improved cnn-lstm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwJNBH944VmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa436523-a45d-4757-ac03-8fb8a7eaecca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6943 - loss: 0.5768 - val_accuracy: 0.7929 - val_loss: 0.4529\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.7759 - loss: 0.4820 - val_accuracy: 0.7929 - val_loss: 0.4480\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.7829 - loss: 0.4673 - val_accuracy: 0.8003 - val_loss: 0.4340\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.7881 - loss: 0.4610 - val_accuracy: 0.8030 - val_loss: 0.4258\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.7898 - loss: 0.4556 - val_accuracy: 0.8109 - val_loss: 0.4145\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7950 - loss: 0.4464 - val_accuracy: 0.8101 - val_loss: 0.4120\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7986 - loss: 0.4446 - val_accuracy: 0.8083 - val_loss: 0.4118\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.7966 - loss: 0.4405 - val_accuracy: 0.8086 - val_loss: 0.4136\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.7975 - loss: 0.4406 - val_accuracy: 0.8075 - val_loss: 0.4108\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7977 - loss: 0.4368 - val_accuracy: 0.8129 - val_loss: 0.4052\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8046 - loss: 0.4297 - val_accuracy: 0.8136 - val_loss: 0.4047\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8049 - loss: 0.4292 - val_accuracy: 0.8176 - val_loss: 0.4015\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8035 - loss: 0.4312 - val_accuracy: 0.8145 - val_loss: 0.4049\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8040 - loss: 0.4338 - val_accuracy: 0.8145 - val_loss: 0.4063\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8023 - loss: 0.4331 - val_accuracy: 0.8168 - val_loss: 0.4004\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8059 - loss: 0.4234 - val_accuracy: 0.8163 - val_loss: 0.3957\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8043 - loss: 0.4271 - val_accuracy: 0.8136 - val_loss: 0.4030\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8059 - loss: 0.4265 - val_accuracy: 0.8209 - val_loss: 0.3932\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8080 - loss: 0.4241 - val_accuracy: 0.8193 - val_loss: 0.3920\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8098 - loss: 0.4199 - val_accuracy: 0.8166 - val_loss: 0.3983\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8060 - loss: 0.4249 - val_accuracy: 0.8209 - val_loss: 0.3914\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8065 - loss: 0.4235 - val_accuracy: 0.8183 - val_loss: 0.4004\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8062 - loss: 0.4192 - val_accuracy: 0.8241 - val_loss: 0.3853\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8034 - loss: 0.4252 - val_accuracy: 0.8235 - val_loss: 0.3896\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8069 - loss: 0.4207 - val_accuracy: 0.8223 - val_loss: 0.3879\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8103 - loss: 0.4172 - val_accuracy: 0.8283 - val_loss: 0.3858\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8096 - loss: 0.4189 - val_accuracy: 0.8228 - val_loss: 0.3853\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8115 - loss: 0.4179 - val_accuracy: 0.8238 - val_loss: 0.3875\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8073 - loss: 0.4187 - val_accuracy: 0.8233 - val_loss: 0.3859\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8132 - loss: 0.4127 - val_accuracy: 0.8229 - val_loss: 0.3849\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8127 - loss: 0.4135 - val_accuracy: 0.8247 - val_loss: 0.3817\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8112 - loss: 0.4160 - val_accuracy: 0.8248 - val_loss: 0.3850\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8078 - loss: 0.4185 - val_accuracy: 0.8256 - val_loss: 0.3820\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8103 - loss: 0.4132 - val_accuracy: 0.8247 - val_loss: 0.3815\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8102 - loss: 0.4144 - val_accuracy: 0.8268 - val_loss: 0.3797\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8128 - loss: 0.4138 - val_accuracy: 0.8247 - val_loss: 0.3833\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8114 - loss: 0.4143 - val_accuracy: 0.8268 - val_loss: 0.3842\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8131 - loss: 0.4147 - val_accuracy: 0.8285 - val_loss: 0.3826\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8147 - loss: 0.4102 - val_accuracy: 0.8262 - val_loss: 0.3836\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8124 - loss: 0.4094 - val_accuracy: 0.8292 - val_loss: 0.3798\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8154 - loss: 0.4069 - val_accuracy: 0.8281 - val_loss: 0.3796\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8094 - loss: 0.4165 - val_accuracy: 0.8259 - val_loss: 0.3845\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8116 - loss: 0.4171 - val_accuracy: 0.8327 - val_loss: 0.3772\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8166 - loss: 0.4066 - val_accuracy: 0.8264 - val_loss: 0.3804\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8123 - loss: 0.4102 - val_accuracy: 0.8232 - val_loss: 0.3856\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8152 - loss: 0.4107 - val_accuracy: 0.8207 - val_loss: 0.3934\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8106 - loss: 0.4120 - val_accuracy: 0.8302 - val_loss: 0.3768\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8143 - loss: 0.4065 - val_accuracy: 0.8319 - val_loss: 0.3746\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8177 - loss: 0.4057 - val_accuracy: 0.8279 - val_loss: 0.3854\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8171 - loss: 0.4054 - val_accuracy: 0.8289 - val_loss: 0.3772\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.3775\n",
            "Test Loss: 0.3760\n",
            "Test Accuracy: 0.8346\n",
            "Confusion Matrix:\n",
            "[[6537 1401]\n",
            " [1359 7393]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.83      7938\n",
            "           1       0.84      0.84      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8346\n",
            "Precision: 0.8407\n",
            "Recall: 0.8447\n",
            "F1 Score: 0.8427\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0fERr4O4VmF"
      },
      "source": [
        "improved cnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsBDgYXS4VmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb5fb5de-3b79-4ff8-8c73-8aec7b16b86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.6799 - loss: 0.5876 - val_accuracy: 0.7866 - val_loss: 0.4622\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.7702 - loss: 0.4915 - val_accuracy: 0.7991 - val_loss: 0.4390\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.7804 - loss: 0.4743 - val_accuracy: 0.8026 - val_loss: 0.4329\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.7909 - loss: 0.4590 - val_accuracy: 0.8024 - val_loss: 0.4270\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.7877 - loss: 0.4567 - val_accuracy: 0.8086 - val_loss: 0.4169\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.7903 - loss: 0.4509 - val_accuracy: 0.8072 - val_loss: 0.4173\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7951 - loss: 0.4473 - val_accuracy: 0.8068 - val_loss: 0.4189\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.7936 - loss: 0.4459 - val_accuracy: 0.8113 - val_loss: 0.4120\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.7986 - loss: 0.4402 - val_accuracy: 0.8127 - val_loss: 0.4048\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.7977 - loss: 0.4388 - val_accuracy: 0.8163 - val_loss: 0.4031\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7981 - loss: 0.4375 - val_accuracy: 0.8113 - val_loss: 0.4103\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8023 - loss: 0.4329 - val_accuracy: 0.8173 - val_loss: 0.3994\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8011 - loss: 0.4344 - val_accuracy: 0.8175 - val_loss: 0.4020\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.7993 - loss: 0.4354 - val_accuracy: 0.8085 - val_loss: 0.4100\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8030 - loss: 0.4304 - val_accuracy: 0.8198 - val_loss: 0.3967\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8022 - loss: 0.4293 - val_accuracy: 0.8187 - val_loss: 0.3970\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8012 - loss: 0.4305 - val_accuracy: 0.8170 - val_loss: 0.3984\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8024 - loss: 0.4310 - val_accuracy: 0.8188 - val_loss: 0.3957\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8073 - loss: 0.4231 - val_accuracy: 0.8212 - val_loss: 0.3913\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8048 - loss: 0.4264 - val_accuracy: 0.8204 - val_loss: 0.3919\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8074 - loss: 0.4195 - val_accuracy: 0.8225 - val_loss: 0.3920\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.8079 - loss: 0.4249 - val_accuracy: 0.8211 - val_loss: 0.3897\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8066 - loss: 0.4207 - val_accuracy: 0.8229 - val_loss: 0.3883\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8078 - loss: 0.4216 - val_accuracy: 0.8213 - val_loss: 0.3923\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8084 - loss: 0.4197 - val_accuracy: 0.8235 - val_loss: 0.3862\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8083 - loss: 0.4195 - val_accuracy: 0.8218 - val_loss: 0.3913\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8104 - loss: 0.4170 - val_accuracy: 0.8167 - val_loss: 0.4027\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8094 - loss: 0.4167 - val_accuracy: 0.8240 - val_loss: 0.3903\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8112 - loss: 0.4195 - val_accuracy: 0.8250 - val_loss: 0.3855\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8111 - loss: 0.4166 - val_accuracy: 0.8149 - val_loss: 0.4018\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8101 - loss: 0.4150 - val_accuracy: 0.8300 - val_loss: 0.3815\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8085 - loss: 0.4173 - val_accuracy: 0.8244 - val_loss: 0.3855\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8065 - loss: 0.4198 - val_accuracy: 0.8235 - val_loss: 0.3852\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8102 - loss: 0.4162 - val_accuracy: 0.8214 - val_loss: 0.3880\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8135 - loss: 0.4119 - val_accuracy: 0.8265 - val_loss: 0.3845\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8105 - loss: 0.4165 - val_accuracy: 0.8309 - val_loss: 0.3788\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8128 - loss: 0.4140 - val_accuracy: 0.8236 - val_loss: 0.3845\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8101 - loss: 0.4142 - val_accuracy: 0.8256 - val_loss: 0.3825\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8094 - loss: 0.4193 - val_accuracy: 0.8283 - val_loss: 0.3778\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8133 - loss: 0.4100 - val_accuracy: 0.8273 - val_loss: 0.3792\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8126 - loss: 0.4135 - val_accuracy: 0.8249 - val_loss: 0.3833\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8120 - loss: 0.4126 - val_accuracy: 0.8258 - val_loss: 0.3841\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8110 - loss: 0.4151 - val_accuracy: 0.8285 - val_loss: 0.3781\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8143 - loss: 0.4070 - val_accuracy: 0.8278 - val_loss: 0.3768\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.8136 - loss: 0.4107 - val_accuracy: 0.8265 - val_loss: 0.3804\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8130 - loss: 0.4132 - val_accuracy: 0.8231 - val_loss: 0.3855\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8152 - loss: 0.4098 - val_accuracy: 0.8330 - val_loss: 0.3744\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8145 - loss: 0.4071 - val_accuracy: 0.8283 - val_loss: 0.3770\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8118 - loss: 0.4140 - val_accuracy: 0.8303 - val_loss: 0.3766\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8118 - loss: 0.4153 - val_accuracy: 0.8269 - val_loss: 0.3899\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8352 - loss: 0.3761\n",
            "Test Loss: 0.3742\n",
            "Test Accuracy: 0.8362\n",
            "Confusion Matrix:\n",
            "[[6530 1408]\n",
            " [1325 7427]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.83      7938\n",
            "           1       0.84      0.85      0.84      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8362\n",
            "Precision: 0.8406\n",
            "Recall: 0.8486\n",
            "F1 Score: 0.8446\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, GRU, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(GRU(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq6FPN9R4VmF"
      },
      "source": [
        "improved DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2UZgOv34VmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bbab848-85a8-4bd2-dd12-e6597d172aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6905 - loss: 0.6091 - val_accuracy: 0.7924 - val_loss: 0.4430\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.7837 - loss: 0.4647 - val_accuracy: 0.8055 - val_loss: 0.4287\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7917 - loss: 0.4514 - val_accuracy: 0.8094 - val_loss: 0.4200\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4409 - val_accuracy: 0.8184 - val_loss: 0.4080\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.4343 - val_accuracy: 0.8191 - val_loss: 0.4064\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.4241 - val_accuracy: 0.8308 - val_loss: 0.3926\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8089 - loss: 0.4217 - val_accuracy: 0.8290 - val_loss: 0.3894\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8135 - loss: 0.4128 - val_accuracy: 0.8254 - val_loss: 0.4041\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.4128 - val_accuracy: 0.8248 - val_loss: 0.3999\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8134 - loss: 0.4072 - val_accuracy: 0.8344 - val_loss: 0.3803\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 0.4076 - val_accuracy: 0.8375 - val_loss: 0.3747\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.4042 - val_accuracy: 0.8286 - val_loss: 0.3823\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.4030 - val_accuracy: 0.8309 - val_loss: 0.3777\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8173 - loss: 0.4043 - val_accuracy: 0.8393 - val_loss: 0.3706\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8192 - loss: 0.4012 - val_accuracy: 0.8367 - val_loss: 0.3688\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8194 - loss: 0.4002 - val_accuracy: 0.8352 - val_loss: 0.3657\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8218 - loss: 0.3957 - val_accuracy: 0.8381 - val_loss: 0.3647\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.3955 - val_accuracy: 0.8305 - val_loss: 0.3720\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8248 - loss: 0.3909 - val_accuracy: 0.8405 - val_loss: 0.3630\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8234 - loss: 0.3930 - val_accuracy: 0.8468 - val_loss: 0.3574\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.3878 - val_accuracy: 0.8383 - val_loss: 0.3644\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 0.3835 - val_accuracy: 0.8441 - val_loss: 0.3592\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.3837 - val_accuracy: 0.8385 - val_loss: 0.3573\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8280 - loss: 0.3837 - val_accuracy: 0.8452 - val_loss: 0.3534\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.3824 - val_accuracy: 0.8455 - val_loss: 0.3527\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.3790 - val_accuracy: 0.8477 - val_loss: 0.3487\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.3765 - val_accuracy: 0.8465 - val_loss: 0.3522\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.3804 - val_accuracy: 0.8465 - val_loss: 0.3546\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.3750 - val_accuracy: 0.8510 - val_loss: 0.3463\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.3759 - val_accuracy: 0.8489 - val_loss: 0.3503\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8312 - loss: 0.3783 - val_accuracy: 0.8525 - val_loss: 0.3457\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8317 - loss: 0.3757 - val_accuracy: 0.8503 - val_loss: 0.3474\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.3787 - val_accuracy: 0.8498 - val_loss: 0.3472\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.3751 - val_accuracy: 0.8516 - val_loss: 0.3486\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.3759 - val_accuracy: 0.8510 - val_loss: 0.3530\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.3783 - val_accuracy: 0.8490 - val_loss: 0.3595\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.3757 - val_accuracy: 0.8516 - val_loss: 0.3462\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8304 - loss: 0.3797 - val_accuracy: 0.8515 - val_loss: 0.3440\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8314 - loss: 0.3757 - val_accuracy: 0.8531 - val_loss: 0.3447\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.3783 - val_accuracy: 0.8399 - val_loss: 0.3666\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.3705 - val_accuracy: 0.8411 - val_loss: 0.3552\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.3774 - val_accuracy: 0.8468 - val_loss: 0.3552\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.3745 - val_accuracy: 0.8456 - val_loss: 0.3602\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.3705 - val_accuracy: 0.8534 - val_loss: 0.3417\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.3673 - val_accuracy: 0.8543 - val_loss: 0.3403\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8396 - loss: 0.3666 - val_accuracy: 0.8524 - val_loss: 0.3426\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.3687 - val_accuracy: 0.8525 - val_loss: 0.3403\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.3752 - val_accuracy: 0.8569 - val_loss: 0.3380\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8381 - loss: 0.3669 - val_accuracy: 0.8456 - val_loss: 0.3496\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8378 - loss: 0.3650 - val_accuracy: 0.8564 - val_loss: 0.3387\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8524 - loss: 0.3424\n",
            "Test Loss: 0.3419\n",
            "Test Accuracy: 0.8530\n",
            "Confusion Matrix:\n",
            "[[6726 1212]\n",
            " [1241 7511]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85      7938\n",
            "           1       0.86      0.86      0.86      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8530\n",
            "Precision: 0.8611\n",
            "Recall: 0.8582\n",
            "F1 Score: 0.8596\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the DNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input and hidden layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgxgCE0y4VmF"
      },
      "source": [
        "improved dnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6sD4sof4VmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e82138d-2d04-4ca0-c84c-01241e44c7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - accuracy: 0.6239 - loss: 0.6589 - val_accuracy: 0.6900 - val_loss: 0.5934\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.7263 - loss: 0.5589 - val_accuracy: 0.7528 - val_loss: 0.4987\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7563 - loss: 0.5204 - val_accuracy: 0.7585 - val_loss: 0.4796\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.7743 - loss: 0.4927 - val_accuracy: 0.7948 - val_loss: 0.4437\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.7795 - loss: 0.4811 - val_accuracy: 0.7854 - val_loss: 0.4691\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7863 - loss: 0.4686 - val_accuracy: 0.8003 - val_loss: 0.4343\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.7919 - loss: 0.4637 - val_accuracy: 0.8031 - val_loss: 0.4346\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.7933 - loss: 0.4590 - val_accuracy: 0.7937 - val_loss: 0.4444\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7955 - loss: 0.4555 - val_accuracy: 0.8059 - val_loss: 0.4325\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8007 - loss: 0.4475 - val_accuracy: 0.8063 - val_loss: 0.4193\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8010 - loss: 0.4453 - val_accuracy: 0.8127 - val_loss: 0.4138\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8021 - loss: 0.4402 - val_accuracy: 0.8140 - val_loss: 0.4116\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8051 - loss: 0.4381 - val_accuracy: 0.8192 - val_loss: 0.4058\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8058 - loss: 0.4316 - val_accuracy: 0.8188 - val_loss: 0.4120\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8073 - loss: 0.4311 - val_accuracy: 0.7707 - val_loss: 0.4572\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8096 - loss: 0.4253 - val_accuracy: 0.8027 - val_loss: 0.4190\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8088 - loss: 0.4278 - val_accuracy: 0.8155 - val_loss: 0.4083\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8156 - loss: 0.4201 - val_accuracy: 0.8188 - val_loss: 0.4019\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8154 - loss: 0.4172 - val_accuracy: 0.8158 - val_loss: 0.4040\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8111 - loss: 0.4186 - val_accuracy: 0.8171 - val_loss: 0.3958\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 0.4152 - val_accuracy: 0.8243 - val_loss: 0.3955\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8142 - loss: 0.4184 - val_accuracy: 0.8206 - val_loss: 0.3927\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8163 - loss: 0.4170 - val_accuracy: 0.8235 - val_loss: 0.3984\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8173 - loss: 0.4155 - val_accuracy: 0.8198 - val_loss: 0.4019\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8164 - loss: 0.4143 - val_accuracy: 0.8265 - val_loss: 0.3901\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8183 - loss: 0.4140 - val_accuracy: 0.8329 - val_loss: 0.3811\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8202 - loss: 0.4073 - val_accuracy: 0.8223 - val_loss: 0.3940\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8195 - loss: 0.4052 - val_accuracy: 0.8191 - val_loss: 0.3933\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8217 - loss: 0.4054 - val_accuracy: 0.8071 - val_loss: 0.4047\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8198 - loss: 0.4045 - val_accuracy: 0.8273 - val_loss: 0.3875\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8215 - loss: 0.4039 - val_accuracy: 0.8269 - val_loss: 0.3905\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8221 - loss: 0.4009 - val_accuracy: 0.8248 - val_loss: 0.3838\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8214 - loss: 0.4051 - val_accuracy: 0.8293 - val_loss: 0.3797\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8254 - loss: 0.3994 - val_accuracy: 0.8335 - val_loss: 0.3779\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8245 - loss: 0.3972 - val_accuracy: 0.8274 - val_loss: 0.3795\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8218 - loss: 0.4009 - val_accuracy: 0.8212 - val_loss: 0.3831\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8273 - loss: 0.3928 - val_accuracy: 0.8269 - val_loss: 0.3780\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8236 - loss: 0.3960 - val_accuracy: 0.8250 - val_loss: 0.3911\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8236 - loss: 0.4012 - val_accuracy: 0.8318 - val_loss: 0.3735\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8298 - loss: 0.3884 - val_accuracy: 0.8292 - val_loss: 0.3784\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8269 - loss: 0.3960 - val_accuracy: 0.8212 - val_loss: 0.3817\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8288 - loss: 0.3919 - val_accuracy: 0.8365 - val_loss: 0.3733\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8288 - loss: 0.3892 - val_accuracy: 0.8309 - val_loss: 0.3785\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8268 - loss: 0.3892 - val_accuracy: 0.8319 - val_loss: 0.3740\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8293 - loss: 0.3888 - val_accuracy: 0.8337 - val_loss: 0.3721\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8270 - loss: 0.3951 - val_accuracy: 0.8371 - val_loss: 0.3701\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8292 - loss: 0.3877 - val_accuracy: 0.8360 - val_loss: 0.3718\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8303 - loss: 0.3840 - val_accuracy: 0.8352 - val_loss: 0.3724\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8308 - loss: 0.3839 - val_accuracy: 0.8367 - val_loss: 0.3673\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8303 - loss: 0.3857 - val_accuracy: 0.8359 - val_loss: 0.3671\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8366 - loss: 0.3739\n",
            "Test Loss: 0.3703\n",
            "Test Accuracy: 0.8377\n",
            "Confusion Matrix:\n",
            "[[6671 1267]\n",
            " [1442 7310]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      7938\n",
            "           1       0.85      0.84      0.84      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8377\n",
            "Precision: 0.8523\n",
            "Recall: 0.8352\n",
            "F1 Score: 0.8437\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soVqGdYl4VmF"
      },
      "source": [
        "improved dnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PARypOi_4VmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da60f59-5688-4779-c3bd-6f4abe818616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.5682 - loss: 0.7479 - val_accuracy: 0.6971 - val_loss: 0.5776\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.6870 - loss: 0.5943 - val_accuracy: 0.7633 - val_loss: 0.4998\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.7471 - loss: 0.5228 - val_accuracy: 0.7828 - val_loss: 0.4594\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.7767 - loss: 0.4829 - val_accuracy: 0.8011 - val_loss: 0.4329\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.7868 - loss: 0.4663 - val_accuracy: 0.8114 - val_loss: 0.4193\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.7914 - loss: 0.4528 - val_accuracy: 0.8123 - val_loss: 0.4115\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.7960 - loss: 0.4428 - val_accuracy: 0.8040 - val_loss: 0.4286\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7956 - loss: 0.4430 - val_accuracy: 0.8198 - val_loss: 0.4004\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8033 - loss: 0.4334 - val_accuracy: 0.8225 - val_loss: 0.3959\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8035 - loss: 0.4305 - val_accuracy: 0.8207 - val_loss: 0.4000\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8057 - loss: 0.4270 - val_accuracy: 0.8241 - val_loss: 0.3935\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.8074 - loss: 0.4219 - val_accuracy: 0.8169 - val_loss: 0.4021\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8112 - loss: 0.4182 - val_accuracy: 0.8268 - val_loss: 0.3859\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8096 - loss: 0.4169 - val_accuracy: 0.8282 - val_loss: 0.3852\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8112 - loss: 0.4160 - val_accuracy: 0.8305 - val_loss: 0.3835\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8085 - loss: 0.4193 - val_accuracy: 0.8194 - val_loss: 0.4021\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8160 - loss: 0.4066 - val_accuracy: 0.8316 - val_loss: 0.3773\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8162 - loss: 0.4061 - val_accuracy: 0.8275 - val_loss: 0.3848\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8128 - loss: 0.4086 - val_accuracy: 0.8255 - val_loss: 0.3924\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8145 - loss: 0.4061 - val_accuracy: 0.8325 - val_loss: 0.3788\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8145 - loss: 0.4049 - val_accuracy: 0.8270 - val_loss: 0.3841\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8174 - loss: 0.4012 - val_accuracy: 0.8342 - val_loss: 0.3718\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.8199 - loss: 0.3994 - val_accuracy: 0.8366 - val_loss: 0.3708\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8182 - loss: 0.4002 - val_accuracy: 0.8281 - val_loss: 0.3853\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8229 - loss: 0.3968 - val_accuracy: 0.8355 - val_loss: 0.3736\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8205 - loss: 0.3973 - val_accuracy: 0.8305 - val_loss: 0.3797\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.8209 - loss: 0.3935 - val_accuracy: 0.8331 - val_loss: 0.3762\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8214 - loss: 0.3959 - val_accuracy: 0.8376 - val_loss: 0.3695\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8247 - loss: 0.3899 - val_accuracy: 0.8339 - val_loss: 0.3726\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.8221 - loss: 0.3936 - val_accuracy: 0.8271 - val_loss: 0.3775\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8247 - loss: 0.3923 - val_accuracy: 0.8322 - val_loss: 0.3775\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8199 - loss: 0.3956 - val_accuracy: 0.8382 - val_loss: 0.3692\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8274 - loss: 0.3878 - val_accuracy: 0.8392 - val_loss: 0.3608\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.8234 - loss: 0.3878 - val_accuracy: 0.8386 - val_loss: 0.3687\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8235 - loss: 0.3907 - val_accuracy: 0.8376 - val_loss: 0.3644\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8242 - loss: 0.3872 - val_accuracy: 0.8344 - val_loss: 0.3726\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.8273 - loss: 0.3838 - val_accuracy: 0.8400 - val_loss: 0.3580\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8279 - loss: 0.3818 - val_accuracy: 0.8411 - val_loss: 0.3620\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8285 - loss: 0.3828 - val_accuracy: 0.8388 - val_loss: 0.3639\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8275 - loss: 0.3842 - val_accuracy: 0.8406 - val_loss: 0.3560\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8278 - loss: 0.3810 - val_accuracy: 0.8396 - val_loss: 0.3645\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 20ms/step - accuracy: 0.8313 - loss: 0.3817 - val_accuracy: 0.8435 - val_loss: 0.3590\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8291 - loss: 0.3819 - val_accuracy: 0.8404 - val_loss: 0.3592\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8327 - loss: 0.3758 - val_accuracy: 0.8411 - val_loss: 0.3639\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8324 - loss: 0.3767 - val_accuracy: 0.8301 - val_loss: 0.3819\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8321 - loss: 0.3784 - val_accuracy: 0.8388 - val_loss: 0.3728\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8323 - loss: 0.3783 - val_accuracy: 0.8448 - val_loss: 0.3602\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8316 - loss: 0.3772 - val_accuracy: 0.8452 - val_loss: 0.3574\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8332 - loss: 0.3744 - val_accuracy: 0.8457 - val_loss: 0.3553\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8311 - loss: 0.3797 - val_accuracy: 0.8435 - val_loss: 0.3541\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8401 - loss: 0.3587\n",
            "Test Loss: 0.3565\n",
            "Test Accuracy: 0.8418\n",
            "Confusion Matrix:\n",
            "[[6865 1073]\n",
            " [1568 7184]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.84      7938\n",
            "           1       0.87      0.82      0.84      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8418\n",
            "Precision: 0.8700\n",
            "Recall: 0.8208\n",
            "F1 Score: 0.8447\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Reshape output from Dense layers to be suitable for GRU layers\n",
        "model.add(tf.keras.layers.Reshape((X_train_reshaped.shape[1], 32)))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH7FBmviGSxW"
      },
      "source": [
        "12-features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfzW6_EW-GUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0a1125-49b4-46e8-dd96-a996e4ad45d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Repititive-Words-in-a-Email',\n",
              " 'Neu-Sentiment',\n",
              " 'Spam lexicon',\n",
              " 'Uinque-Words-in-a-Email',\n",
              " 'Pos-Sentiment',\n",
              " 'Length-of-Email',\n",
              " 'Number of co-occuring words',\n",
              " 'Number-of-noun',\n",
              " 'Subjective',\n",
              " 'Polarity',\n",
              " 'Neg-Sentiment',\n",
              " 'Comp-Sentiment']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "features=feature_importances.nlargest(n=12, columns='Importance')['Feature'].to_list()\n",
        "features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVDisNCnx01g"
      },
      "source": [
        "improved rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1NYj1xax01h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109d206a-025d-402e-8262-7bea57086081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.6872 - loss: 0.5916 - val_accuracy: 0.7840 - val_loss: 0.4634\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.7791 - loss: 0.4742 - val_accuracy: 0.7851 - val_loss: 0.4541\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7895 - loss: 0.4543 - val_accuracy: 0.7827 - val_loss: 0.4540\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.7976 - loss: 0.4423 - val_accuracy: 0.7895 - val_loss: 0.4411\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8008 - loss: 0.4379 - val_accuracy: 0.8081 - val_loss: 0.4103\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8054 - loss: 0.4310 - val_accuracy: 0.8125 - val_loss: 0.4232\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8064 - loss: 0.4225 - val_accuracy: 0.8155 - val_loss: 0.4055\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8057 - loss: 0.4228 - val_accuracy: 0.8150 - val_loss: 0.4004\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8131 - loss: 0.4183 - val_accuracy: 0.8207 - val_loss: 0.3966\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8149 - loss: 0.4136 - val_accuracy: 0.8184 - val_loss: 0.3943\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8158 - loss: 0.4081 - val_accuracy: 0.8234 - val_loss: 0.3917\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8179 - loss: 0.4026 - val_accuracy: 0.8150 - val_loss: 0.4238\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8187 - loss: 0.4053 - val_accuracy: 0.8256 - val_loss: 0.3888\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8199 - loss: 0.3990 - val_accuracy: 0.8252 - val_loss: 0.3915\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8246 - loss: 0.3981 - val_accuracy: 0.8209 - val_loss: 0.3875\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8200 - loss: 0.3960 - val_accuracy: 0.8259 - val_loss: 0.3857\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8285 - loss: 0.3906 - val_accuracy: 0.8214 - val_loss: 0.3940\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8261 - loss: 0.3930 - val_accuracy: 0.8247 - val_loss: 0.3935\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8266 - loss: 0.3907 - val_accuracy: 0.8301 - val_loss: 0.3777\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8285 - loss: 0.3902 - val_accuracy: 0.8208 - val_loss: 0.3794\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8302 - loss: 0.3853 - val_accuracy: 0.8307 - val_loss: 0.3837\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8240 - loss: 0.3892 - val_accuracy: 0.8267 - val_loss: 0.3803\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8298 - loss: 0.3841 - val_accuracy: 0.8286 - val_loss: 0.3870\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8313 - loss: 0.3790 - val_accuracy: 0.8226 - val_loss: 0.4038\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8305 - loss: 0.3801 - val_accuracy: 0.8374 - val_loss: 0.3717\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8353 - loss: 0.3764 - val_accuracy: 0.8323 - val_loss: 0.3818\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8353 - loss: 0.3784 - val_accuracy: 0.8318 - val_loss: 0.3745\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8337 - loss: 0.3736 - val_accuracy: 0.8374 - val_loss: 0.3667\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8316 - loss: 0.3796 - val_accuracy: 0.8407 - val_loss: 0.3669\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8375 - loss: 0.3726 - val_accuracy: 0.8362 - val_loss: 0.3728\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8346 - loss: 0.3753 - val_accuracy: 0.8334 - val_loss: 0.3707\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8379 - loss: 0.3719 - val_accuracy: 0.8349 - val_loss: 0.3760\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8363 - loss: 0.3714 - val_accuracy: 0.8355 - val_loss: 0.3725\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8353 - loss: 0.3682 - val_accuracy: 0.8397 - val_loss: 0.3655\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8387 - loss: 0.3682 - val_accuracy: 0.8321 - val_loss: 0.3769\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8363 - loss: 0.3709 - val_accuracy: 0.8319 - val_loss: 0.3691\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8390 - loss: 0.3685 - val_accuracy: 0.8426 - val_loss: 0.3579\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.3636 - val_accuracy: 0.8406 - val_loss: 0.3618\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8417 - loss: 0.3601 - val_accuracy: 0.8382 - val_loss: 0.3647\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8407 - loss: 0.3647 - val_accuracy: 0.8300 - val_loss: 0.3902\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8402 - loss: 0.3635 - val_accuracy: 0.8395 - val_loss: 0.3683\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8425 - loss: 0.3589 - val_accuracy: 0.8379 - val_loss: 0.3715\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8431 - loss: 0.3591 - val_accuracy: 0.8254 - val_loss: 0.3770\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8448 - loss: 0.3581 - val_accuracy: 0.8420 - val_loss: 0.3586\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8421 - loss: 0.3627 - val_accuracy: 0.8413 - val_loss: 0.3622\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8432 - loss: 0.3601 - val_accuracy: 0.8382 - val_loss: 0.3682\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8422 - loss: 0.3595 - val_accuracy: 0.8378 - val_loss: 0.3640\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.3609\n",
            "Test Loss: 0.3588\n",
            "Test Accuracy: 0.8432\n",
            "Confusion Matrix:\n",
            "[[6677 1261]\n",
            " [1356 7396]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.84      7938\n",
            "           1       0.85      0.85      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8432\n",
            "Precision: 0.8543\n",
            "Recall: 0.8451\n",
            "F1 Score: 0.8497\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# RNN layers\n",
        "model.add(SimpleRNN(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(SimpleRNN(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU2YxbP_x01i"
      },
      "source": [
        "improved rnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmct8GOlx01j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29320d2d-f63b-4cc8-c5ad-c9015a8a967a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 14ms/step - accuracy: 0.6425 - loss: 0.6501 - val_accuracy: 0.6936 - val_loss: 0.5749\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.7012 - loss: 0.5775 - val_accuracy: 0.7522 - val_loss: 0.5259\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7550 - loss: 0.5109 - val_accuracy: 0.7848 - val_loss: 0.4604\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7681 - loss: 0.4934 - val_accuracy: 0.7800 - val_loss: 0.4618\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7784 - loss: 0.4746 - val_accuracy: 0.7845 - val_loss: 0.4501\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.7848 - loss: 0.4626 - val_accuracy: 0.8018 - val_loss: 0.4328\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7874 - loss: 0.4576 - val_accuracy: 0.7970 - val_loss: 0.4417\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7928 - loss: 0.4496 - val_accuracy: 0.8076 - val_loss: 0.4216\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.7963 - loss: 0.4451 - val_accuracy: 0.8097 - val_loss: 0.4139\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.7989 - loss: 0.4441 - val_accuracy: 0.7920 - val_loss: 0.4485\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8036 - loss: 0.4303 - val_accuracy: 0.8140 - val_loss: 0.4086\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8070 - loss: 0.4293 - val_accuracy: 0.8205 - val_loss: 0.4037\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8054 - loss: 0.4316 - val_accuracy: 0.8096 - val_loss: 0.4174\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step - accuracy: 0.8074 - loss: 0.4268 - val_accuracy: 0.7573 - val_loss: 0.4718\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8069 - loss: 0.4251 - val_accuracy: 0.8206 - val_loss: 0.4005\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8090 - loss: 0.4209 - val_accuracy: 0.8170 - val_loss: 0.4075\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8122 - loss: 0.4181 - val_accuracy: 0.8053 - val_loss: 0.4155\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8141 - loss: 0.4130 - val_accuracy: 0.8236 - val_loss: 0.3956\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8121 - loss: 0.4149 - val_accuracy: 0.8045 - val_loss: 0.4073\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8133 - loss: 0.4118 - val_accuracy: 0.8138 - val_loss: 0.4001\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8166 - loss: 0.4088 - val_accuracy: 0.8142 - val_loss: 0.4050\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8171 - loss: 0.4067 - val_accuracy: 0.8104 - val_loss: 0.4022\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8170 - loss: 0.4085 - val_accuracy: 0.8109 - val_loss: 0.3930\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8212 - loss: 0.4026 - val_accuracy: 0.8224 - val_loss: 0.3926\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8209 - loss: 0.4013 - val_accuracy: 0.8280 - val_loss: 0.3860\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8205 - loss: 0.4014 - val_accuracy: 0.8313 - val_loss: 0.3761\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8200 - loss: 0.4038 - val_accuracy: 0.8279 - val_loss: 0.3818\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8234 - loss: 0.3965 - val_accuracy: 0.8269 - val_loss: 0.3808\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8225 - loss: 0.3979 - val_accuracy: 0.8164 - val_loss: 0.4007\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8214 - loss: 0.3973 - val_accuracy: 0.8255 - val_loss: 0.3810\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8260 - loss: 0.3917 - val_accuracy: 0.8330 - val_loss: 0.3771\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8245 - loss: 0.3950 - val_accuracy: 0.8280 - val_loss: 0.3741\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8236 - loss: 0.3961 - val_accuracy: 0.8299 - val_loss: 0.3756\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8288 - loss: 0.3887 - val_accuracy: 0.8263 - val_loss: 0.3805\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8219 - loss: 0.3971 - val_accuracy: 0.8126 - val_loss: 0.4008\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8249 - loss: 0.3906 - val_accuracy: 0.8325 - val_loss: 0.3724\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8296 - loss: 0.3866 - val_accuracy: 0.8359 - val_loss: 0.3669\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8260 - loss: 0.3881 - val_accuracy: 0.8340 - val_loss: 0.3668\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8270 - loss: 0.3852 - val_accuracy: 0.8330 - val_loss: 0.3730\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8312 - loss: 0.3794 - val_accuracy: 0.8347 - val_loss: 0.3620\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8284 - loss: 0.3835 - val_accuracy: 0.8364 - val_loss: 0.3653\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8289 - loss: 0.3840 - val_accuracy: 0.8298 - val_loss: 0.3777\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8313 - loss: 0.3798 - val_accuracy: 0.8328 - val_loss: 0.3691\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8304 - loss: 0.3794 - val_accuracy: 0.8355 - val_loss: 0.3712\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 18ms/step - accuracy: 0.8296 - loss: 0.3809 - val_accuracy: 0.8339 - val_loss: 0.3642\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - accuracy: 0.8342 - loss: 0.3768 - val_accuracy: 0.8384 - val_loss: 0.3594\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.8303 - loss: 0.3792 - val_accuracy: 0.8310 - val_loss: 0.3714\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 19ms/step - accuracy: 0.8305 - loss: 0.3818 - val_accuracy: 0.8370 - val_loss: 0.3646\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - accuracy: 0.8317 - loss: 0.3770 - val_accuracy: 0.8376 - val_loss: 0.3623\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15ms/step - accuracy: 0.8322 - loss: 0.3766 - val_accuracy: 0.8377 - val_loss: 0.3592\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8402 - loss: 0.3625\n",
            "Test Loss: 0.3603\n",
            "Test Accuracy: 0.8433\n",
            "Confusion Matrix:\n",
            "[[6774 1164]\n",
            " [1452 7300]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.84      7938\n",
            "           1       0.86      0.83      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8433\n",
            "Precision: 0.8625\n",
            "Recall: 0.8341\n",
            "F1 Score: 0.8480\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2rq1Ebwx01j"
      },
      "source": [
        "improved rnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHmT0t_x01k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2d3397-1196-424f-948a-afa0c5b3cd95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.6201 - loss: 0.6735 - val_accuracy: 0.6303 - val_loss: 0.6247\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.7119 - loss: 0.5680 - val_accuracy: 0.7255 - val_loss: 0.5379\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.7737 - loss: 0.4841 - val_accuracy: 0.7447 - val_loss: 0.5112\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.7863 - loss: 0.4641 - val_accuracy: 0.8050 - val_loss: 0.4248\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7935 - loss: 0.4517 - val_accuracy: 0.8053 - val_loss: 0.4241\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.7981 - loss: 0.4455 - val_accuracy: 0.7885 - val_loss: 0.4488\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.7988 - loss: 0.4428 - val_accuracy: 0.8020 - val_loss: 0.4310\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8022 - loss: 0.4387 - val_accuracy: 0.8170 - val_loss: 0.4148\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8051 - loss: 0.4290 - val_accuracy: 0.7931 - val_loss: 0.4582\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.8062 - loss: 0.4291 - val_accuracy: 0.8119 - val_loss: 0.4125\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8082 - loss: 0.4282 - val_accuracy: 0.8200 - val_loss: 0.4059\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8137 - loss: 0.4174 - val_accuracy: 0.7743 - val_loss: 0.4567\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8133 - loss: 0.4174 - val_accuracy: 0.8242 - val_loss: 0.3951\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.8121 - loss: 0.4178 - val_accuracy: 0.8000 - val_loss: 0.4271\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8136 - loss: 0.4137 - val_accuracy: 0.8043 - val_loss: 0.4149\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8167 - loss: 0.4077 - val_accuracy: 0.8253 - val_loss: 0.3895\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.8139 - loss: 0.4115 - val_accuracy: 0.8117 - val_loss: 0.4039\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.8213 - loss: 0.4064 - val_accuracy: 0.8269 - val_loss: 0.3879\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8170 - loss: 0.4074 - val_accuracy: 0.8229 - val_loss: 0.3893\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8176 - loss: 0.4082 - val_accuracy: 0.8080 - val_loss: 0.4339\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.8198 - loss: 0.4030 - val_accuracy: 0.8063 - val_loss: 0.4268\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8156 - loss: 0.4086 - val_accuracy: 0.8304 - val_loss: 0.3845\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8207 - loss: 0.4044 - val_accuracy: 0.8344 - val_loss: 0.3767\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8230 - loss: 0.4004 - val_accuracy: 0.8311 - val_loss: 0.3788\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.8241 - loss: 0.4002 - val_accuracy: 0.8310 - val_loss: 0.3787\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8230 - loss: 0.3970 - val_accuracy: 0.8265 - val_loss: 0.3829\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 19ms/step - accuracy: 0.8219 - loss: 0.3995 - val_accuracy: 0.8281 - val_loss: 0.3772\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.8242 - loss: 0.3989 - val_accuracy: 0.8332 - val_loss: 0.3732\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.8267 - loss: 0.3909 - val_accuracy: 0.8302 - val_loss: 0.3751\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 19ms/step - accuracy: 0.8205 - loss: 0.3979 - val_accuracy: 0.8343 - val_loss: 0.3703\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8271 - loss: 0.3894 - val_accuracy: 0.8372 - val_loss: 0.3693\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8298 - loss: 0.3876 - val_accuracy: 0.8250 - val_loss: 0.3801\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8297 - loss: 0.3827 - val_accuracy: 0.8293 - val_loss: 0.3756\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8302 - loss: 0.3853 - val_accuracy: 0.8043 - val_loss: 0.4032\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8282 - loss: 0.3858 - val_accuracy: 0.8276 - val_loss: 0.3817\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.8279 - loss: 0.3889 - val_accuracy: 0.8310 - val_loss: 0.3703\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.8285 - loss: 0.3881 - val_accuracy: 0.8322 - val_loss: 0.3653\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8307 - loss: 0.3838 - val_accuracy: 0.8402 - val_loss: 0.3607\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8300 - loss: 0.3817 - val_accuracy: 0.8389 - val_loss: 0.3633\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8367 - loss: 0.3764 - val_accuracy: 0.8337 - val_loss: 0.3645\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8314 - loss: 0.3831 - val_accuracy: 0.8341 - val_loss: 0.3693\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8303 - loss: 0.3806 - val_accuracy: 0.8382 - val_loss: 0.3620\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8328 - loss: 0.3807 - val_accuracy: 0.8378 - val_loss: 0.3602\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8310 - loss: 0.3818 - val_accuracy: 0.8367 - val_loss: 0.3620\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8318 - loss: 0.3801 - val_accuracy: 0.8355 - val_loss: 0.3620\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8373 - loss: 0.3702 - val_accuracy: 0.8388 - val_loss: 0.3566\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8341 - loss: 0.3758 - val_accuracy: 0.8406 - val_loss: 0.3558\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.8354 - loss: 0.3742 - val_accuracy: 0.8406 - val_loss: 0.3595\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.8361 - loss: 0.3769 - val_accuracy: 0.8414 - val_loss: 0.3538\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8359 - loss: 0.3717 - val_accuracy: 0.8382 - val_loss: 0.3582\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8408 - loss: 0.3611\n",
            "Test Loss: 0.3578\n",
            "Test Accuracy: 0.8433\n",
            "Confusion Matrix:\n",
            "[[6619 1319]\n",
            " [1297 7455]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.83      0.83      7938\n",
            "           1       0.85      0.85      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8433\n",
            "Precision: 0.8497\n",
            "Recall: 0.8518\n",
            "F1 Score: 0.8507\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50eZldm84fjZ"
      },
      "source": [
        "improved cnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjSV2yTv4fja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a178c48-b397-49d1-8cf6-a345faec5e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6489 - loss: 0.6942 - val_accuracy: 0.7700 - val_loss: 0.4828\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7501 - loss: 0.5141 - val_accuracy: 0.7907 - val_loss: 0.4521\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7745 - loss: 0.4797 - val_accuracy: 0.7982 - val_loss: 0.4342\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.4673 - val_accuracy: 0.8010 - val_loss: 0.4268\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7875 - loss: 0.4636 - val_accuracy: 0.8062 - val_loss: 0.4220\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7896 - loss: 0.4539 - val_accuracy: 0.8081 - val_loss: 0.4194\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7950 - loss: 0.4450 - val_accuracy: 0.8130 - val_loss: 0.4136\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7933 - loss: 0.4473 - val_accuracy: 0.8140 - val_loss: 0.4118\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7939 - loss: 0.4444 - val_accuracy: 0.8128 - val_loss: 0.4066\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7969 - loss: 0.4443 - val_accuracy: 0.8155 - val_loss: 0.4050\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7971 - loss: 0.4405 - val_accuracy: 0.8116 - val_loss: 0.4070\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7981 - loss: 0.4419 - val_accuracy: 0.8170 - val_loss: 0.4007\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8020 - loss: 0.4338 - val_accuracy: 0.8117 - val_loss: 0.4070\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.4344 - val_accuracy: 0.8192 - val_loss: 0.3984\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8023 - loss: 0.4355 - val_accuracy: 0.8113 - val_loss: 0.4072\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.4299 - val_accuracy: 0.8190 - val_loss: 0.3969\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8055 - loss: 0.4272 - val_accuracy: 0.8183 - val_loss: 0.3960\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4276 - val_accuracy: 0.8197 - val_loss: 0.3941\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4195 - val_accuracy: 0.8193 - val_loss: 0.3982\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4254 - val_accuracy: 0.8217 - val_loss: 0.3939\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 0.4233 - val_accuracy: 0.8085 - val_loss: 0.4152\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8074 - loss: 0.4246 - val_accuracy: 0.8240 - val_loss: 0.3897\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8049 - loss: 0.4263 - val_accuracy: 0.8186 - val_loss: 0.3920\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4249 - val_accuracy: 0.8149 - val_loss: 0.4028\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4242 - val_accuracy: 0.8178 - val_loss: 0.3981\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8100 - loss: 0.4168 - val_accuracy: 0.8226 - val_loss: 0.3927\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8116 - loss: 0.4230 - val_accuracy: 0.8199 - val_loss: 0.3919\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4208 - val_accuracy: 0.8223 - val_loss: 0.3882\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.4181 - val_accuracy: 0.8224 - val_loss: 0.3871\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4202 - val_accuracy: 0.8253 - val_loss: 0.3887\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4173 - val_accuracy: 0.8219 - val_loss: 0.3899\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4187 - val_accuracy: 0.8230 - val_loss: 0.3887\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8092 - loss: 0.4196 - val_accuracy: 0.8239 - val_loss: 0.3889\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8134 - loss: 0.4144 - val_accuracy: 0.8223 - val_loss: 0.3890\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4208 - val_accuracy: 0.8254 - val_loss: 0.3869\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8130 - loss: 0.4134 - val_accuracy: 0.8243 - val_loss: 0.3857\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.4151 - val_accuracy: 0.8272 - val_loss: 0.3824\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8102 - loss: 0.4118 - val_accuracy: 0.8255 - val_loss: 0.3851\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.4169 - val_accuracy: 0.8249 - val_loss: 0.3853\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 0.4134 - val_accuracy: 0.8167 - val_loss: 0.4003\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8131 - loss: 0.4134 - val_accuracy: 0.8262 - val_loss: 0.3825\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4162 - val_accuracy: 0.8272 - val_loss: 0.3809\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8117 - loss: 0.4107 - val_accuracy: 0.8261 - val_loss: 0.3827\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8141 - loss: 0.4087 - val_accuracy: 0.8223 - val_loss: 0.3874\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4141 - val_accuracy: 0.8263 - val_loss: 0.3822\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8108 - loss: 0.4193 - val_accuracy: 0.8226 - val_loss: 0.3878\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4136 - val_accuracy: 0.8254 - val_loss: 0.3850\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 0.4170 - val_accuracy: 0.8249 - val_loss: 0.3831\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.4136 - val_accuracy: 0.8280 - val_loss: 0.3815\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.4146 - val_accuracy: 0.8243 - val_loss: 0.3847\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3823\n",
            "Test Loss: 0.3807\n",
            "Test Accuracy: 0.8290\n",
            "Confusion Matrix:\n",
            "[[6303 1635]\n",
            " [1219 7533]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.79      0.82      7938\n",
            "           1       0.82      0.86      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8290\n",
            "Precision: 0.8217\n",
            "Recall: 0.8607\n",
            "F1 Score: 0.8407\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the optimized CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2AKfX9N4fja"
      },
      "source": [
        "improved cnn-lstm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDJzyoJK4fjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640be64e-8a07-435e-c916-5d4538489787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.6989 - loss: 0.5725 - val_accuracy: 0.7961 - val_loss: 0.4418\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.7786 - loss: 0.4790 - val_accuracy: 0.8044 - val_loss: 0.4311\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7813 - loss: 0.4663 - val_accuracy: 0.8055 - val_loss: 0.4340\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.7875 - loss: 0.4573 - val_accuracy: 0.8080 - val_loss: 0.4237\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 10ms/step - accuracy: 0.7898 - loss: 0.4542 - val_accuracy: 0.8101 - val_loss: 0.4203\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7980 - loss: 0.4443 - val_accuracy: 0.8065 - val_loss: 0.4267\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7977 - loss: 0.4411 - val_accuracy: 0.8126 - val_loss: 0.4132\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7975 - loss: 0.4388 - val_accuracy: 0.8119 - val_loss: 0.4175\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8002 - loss: 0.4409 - val_accuracy: 0.8144 - val_loss: 0.4089\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7963 - loss: 0.4403 - val_accuracy: 0.8172 - val_loss: 0.4068\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8013 - loss: 0.4357 - val_accuracy: 0.8174 - val_loss: 0.4109\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8038 - loss: 0.4312 - val_accuracy: 0.8197 - val_loss: 0.3994\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8039 - loss: 0.4296 - val_accuracy: 0.8194 - val_loss: 0.3977\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8009 - loss: 0.4333 - val_accuracy: 0.8209 - val_loss: 0.4000\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8068 - loss: 0.4249 - val_accuracy: 0.8163 - val_loss: 0.4017\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8114 - loss: 0.4176 - val_accuracy: 0.8190 - val_loss: 0.3989\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8088 - loss: 0.4200 - val_accuracy: 0.8200 - val_loss: 0.4013\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8093 - loss: 0.4226 - val_accuracy: 0.8215 - val_loss: 0.3879\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8056 - loss: 0.4245 - val_accuracy: 0.8222 - val_loss: 0.3908\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8084 - loss: 0.4201 - val_accuracy: 0.8217 - val_loss: 0.3864\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8119 - loss: 0.4210 - val_accuracy: 0.8232 - val_loss: 0.3874\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8121 - loss: 0.4166 - val_accuracy: 0.8192 - val_loss: 0.3931\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8119 - loss: 0.4167 - val_accuracy: 0.8247 - val_loss: 0.3837\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8083 - loss: 0.4185 - val_accuracy: 0.8229 - val_loss: 0.3868\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8085 - loss: 0.4157 - val_accuracy: 0.8235 - val_loss: 0.3859\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8119 - loss: 0.4129 - val_accuracy: 0.8222 - val_loss: 0.3873\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8131 - loss: 0.4123 - val_accuracy: 0.8229 - val_loss: 0.3874\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8139 - loss: 0.4129 - val_accuracy: 0.8265 - val_loss: 0.3801\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8107 - loss: 0.4128 - val_accuracy: 0.8257 - val_loss: 0.3833\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8105 - loss: 0.4163 - val_accuracy: 0.8216 - val_loss: 0.3895\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8152 - loss: 0.4092 - val_accuracy: 0.8271 - val_loss: 0.3808\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8161 - loss: 0.4060 - val_accuracy: 0.8272 - val_loss: 0.3810\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8147 - loss: 0.4058 - val_accuracy: 0.8262 - val_loss: 0.3796\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8154 - loss: 0.4083 - val_accuracy: 0.8285 - val_loss: 0.3764\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8145 - loss: 0.4140 - val_accuracy: 0.8254 - val_loss: 0.3801\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8156 - loss: 0.4047 - val_accuracy: 0.8284 - val_loss: 0.3769\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8180 - loss: 0.4044 - val_accuracy: 0.8276 - val_loss: 0.3774\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8202 - loss: 0.4013 - val_accuracy: 0.8302 - val_loss: 0.3791\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8177 - loss: 0.4031 - val_accuracy: 0.8325 - val_loss: 0.3761\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8171 - loss: 0.4023 - val_accuracy: 0.8238 - val_loss: 0.3893\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8184 - loss: 0.4034 - val_accuracy: 0.8286 - val_loss: 0.3766\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8190 - loss: 0.4030 - val_accuracy: 0.8245 - val_loss: 0.3889\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8197 - loss: 0.3983 - val_accuracy: 0.8282 - val_loss: 0.3748\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8177 - loss: 0.3982 - val_accuracy: 0.8290 - val_loss: 0.3744\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8157 - loss: 0.4027 - val_accuracy: 0.8278 - val_loss: 0.3722\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8207 - loss: 0.3993 - val_accuracy: 0.8269 - val_loss: 0.3790\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8204 - loss: 0.4004 - val_accuracy: 0.8307 - val_loss: 0.3693\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8203 - loss: 0.4012 - val_accuracy: 0.8307 - val_loss: 0.3723\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8170 - loss: 0.4023 - val_accuracy: 0.8301 - val_loss: 0.3722\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8216 - loss: 0.3960 - val_accuracy: 0.8347 - val_loss: 0.3696\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.3697\n",
            "Test Loss: 0.3678\n",
            "Test Accuracy: 0.8337\n",
            "Confusion Matrix:\n",
            "[[6470 1468]\n",
            " [1308 7444]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.82      7938\n",
            "           1       0.84      0.85      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8337\n",
            "Precision: 0.8353\n",
            "Recall: 0.8505\n",
            "F1 Score: 0.8428\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf3E5Uyr4fjb"
      },
      "source": [
        "improved cnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4ufGMug4fjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a3177f-3ad1-43fa-d8f9-a706bc232c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6810 - loss: 0.5871 - val_accuracy: 0.7940 - val_loss: 0.4569\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7701 - loss: 0.4892 - val_accuracy: 0.8016 - val_loss: 0.4377\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7826 - loss: 0.4698 - val_accuracy: 0.7953 - val_loss: 0.4333\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7834 - loss: 0.4666 - val_accuracy: 0.8046 - val_loss: 0.4274\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7882 - loss: 0.4563 - val_accuracy: 0.8120 - val_loss: 0.4146\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7924 - loss: 0.4548 - val_accuracy: 0.8134 - val_loss: 0.4124\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7961 - loss: 0.4429 - val_accuracy: 0.8074 - val_loss: 0.4252\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7983 - loss: 0.4417 - val_accuracy: 0.8047 - val_loss: 0.4253\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7973 - loss: 0.4424 - val_accuracy: 0.8135 - val_loss: 0.4062\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8021 - loss: 0.4361 - val_accuracy: 0.8144 - val_loss: 0.4072\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8030 - loss: 0.4331 - val_accuracy: 0.8198 - val_loss: 0.4007\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8050 - loss: 0.4301 - val_accuracy: 0.8203 - val_loss: 0.3995\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8071 - loss: 0.4280 - val_accuracy: 0.8207 - val_loss: 0.3959\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8067 - loss: 0.4257 - val_accuracy: 0.8203 - val_loss: 0.3972\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8053 - loss: 0.4258 - val_accuracy: 0.8219 - val_loss: 0.3971\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8056 - loss: 0.4229 - val_accuracy: 0.8206 - val_loss: 0.3932\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8059 - loss: 0.4227 - val_accuracy: 0.8236 - val_loss: 0.3901\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8082 - loss: 0.4202 - val_accuracy: 0.8226 - val_loss: 0.3965\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8107 - loss: 0.4176 - val_accuracy: 0.8209 - val_loss: 0.4005\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8107 - loss: 0.4152 - val_accuracy: 0.8226 - val_loss: 0.3911\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8098 - loss: 0.4196 - val_accuracy: 0.8153 - val_loss: 0.4005\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8083 - loss: 0.4195 - val_accuracy: 0.8140 - val_loss: 0.4093\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8106 - loss: 0.4132 - val_accuracy: 0.8248 - val_loss: 0.3849\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8092 - loss: 0.4193 - val_accuracy: 0.8268 - val_loss: 0.3834\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8121 - loss: 0.4155 - val_accuracy: 0.8214 - val_loss: 0.3968\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8122 - loss: 0.4184 - val_accuracy: 0.8271 - val_loss: 0.3836\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8114 - loss: 0.4129 - val_accuracy: 0.8295 - val_loss: 0.3800\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8153 - loss: 0.4091 - val_accuracy: 0.8294 - val_loss: 0.3780\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8132 - loss: 0.4122 - val_accuracy: 0.8280 - val_loss: 0.3834\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8140 - loss: 0.4098 - val_accuracy: 0.8305 - val_loss: 0.3785\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8142 - loss: 0.4071 - val_accuracy: 0.8332 - val_loss: 0.3768\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8137 - loss: 0.4105 - val_accuracy: 0.8334 - val_loss: 0.3767\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8170 - loss: 0.4061 - val_accuracy: 0.8161 - val_loss: 0.4024\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8140 - loss: 0.4081 - val_accuracy: 0.8297 - val_loss: 0.3784\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8169 - loss: 0.4093 - val_accuracy: 0.8256 - val_loss: 0.3830\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8157 - loss: 0.4069 - val_accuracy: 0.8335 - val_loss: 0.3849\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8166 - loss: 0.4063 - val_accuracy: 0.8322 - val_loss: 0.3759\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8173 - loss: 0.4049 - val_accuracy: 0.8311 - val_loss: 0.3761\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8183 - loss: 0.4037 - val_accuracy: 0.8305 - val_loss: 0.3734\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8162 - loss: 0.4051 - val_accuracy: 0.8349 - val_loss: 0.3712\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8165 - loss: 0.4040 - val_accuracy: 0.8350 - val_loss: 0.3723\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8188 - loss: 0.4016 - val_accuracy: 0.8346 - val_loss: 0.3705\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8181 - loss: 0.4019 - val_accuracy: 0.8303 - val_loss: 0.3791\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8201 - loss: 0.4002 - val_accuracy: 0.8311 - val_loss: 0.3713\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8199 - loss: 0.4006 - val_accuracy: 0.8326 - val_loss: 0.3734\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8201 - loss: 0.3979 - val_accuracy: 0.8180 - val_loss: 0.4008\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8167 - loss: 0.4017 - val_accuracy: 0.8348 - val_loss: 0.3717\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8188 - loss: 0.4016 - val_accuracy: 0.8358 - val_loss: 0.3702\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8189 - loss: 0.4028 - val_accuracy: 0.8337 - val_loss: 0.3708\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8168 - loss: 0.4050 - val_accuracy: 0.8364 - val_loss: 0.3701\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3696\n",
            "Test Loss: 0.3683\n",
            "Test Accuracy: 0.8380\n",
            "Confusion Matrix:\n",
            "[[6568 1370]\n",
            " [1333 7419]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83      7938\n",
            "           1       0.84      0.85      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8380\n",
            "Precision: 0.8441\n",
            "Recall: 0.8477\n",
            "F1 Score: 0.8459\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, GRU, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(GRU(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qyBQEtD4fjc"
      },
      "source": [
        "improved DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGdluOry4fjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f479ec1-a530-4443-9b04-6369151287b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.6671 - loss: 0.6611 - val_accuracy: 0.7883 - val_loss: 0.4542\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7699 - loss: 0.4869 - val_accuracy: 0.8033 - val_loss: 0.4303\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7886 - loss: 0.4602 - val_accuracy: 0.8125 - val_loss: 0.4164\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7967 - loss: 0.4457 - val_accuracy: 0.8160 - val_loss: 0.4147\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8021 - loss: 0.4353 - val_accuracy: 0.8235 - val_loss: 0.4042\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8068 - loss: 0.4281 - val_accuracy: 0.8088 - val_loss: 0.4147\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8109 - loss: 0.4174 - val_accuracy: 0.8236 - val_loss: 0.3931\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8141 - loss: 0.4133 - val_accuracy: 0.8293 - val_loss: 0.3895\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8157 - loss: 0.4081 - val_accuracy: 0.8234 - val_loss: 0.3911\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.4130 - val_accuracy: 0.8275 - val_loss: 0.3868\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.4128 - val_accuracy: 0.8355 - val_loss: 0.3758\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8175 - loss: 0.4058 - val_accuracy: 0.8280 - val_loss: 0.3812\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8171 - loss: 0.4042 - val_accuracy: 0.8357 - val_loss: 0.3732\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.3975 - val_accuracy: 0.8376 - val_loss: 0.3699\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.3931 - val_accuracy: 0.8396 - val_loss: 0.3679\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8241 - loss: 0.3950 - val_accuracy: 0.8399 - val_loss: 0.3686\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8225 - loss: 0.3936 - val_accuracy: 0.8414 - val_loss: 0.3649\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.3993 - val_accuracy: 0.8380 - val_loss: 0.3661\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.3922 - val_accuracy: 0.8412 - val_loss: 0.3653\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.3923 - val_accuracy: 0.8349 - val_loss: 0.3631\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8293 - loss: 0.3870 - val_accuracy: 0.8340 - val_loss: 0.3725\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.3900 - val_accuracy: 0.8414 - val_loss: 0.3619\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.3900 - val_accuracy: 0.8397 - val_loss: 0.3573\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.3870 - val_accuracy: 0.8409 - val_loss: 0.3562\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8266 - loss: 0.3857 - val_accuracy: 0.8451 - val_loss: 0.3539\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.3858 - val_accuracy: 0.8470 - val_loss: 0.3516\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.3791 - val_accuracy: 0.8393 - val_loss: 0.3596\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.3813 - val_accuracy: 0.8450 - val_loss: 0.3569\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.3774 - val_accuracy: 0.8475 - val_loss: 0.3514\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8279 - loss: 0.3808 - val_accuracy: 0.8498 - val_loss: 0.3513\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.3811 - val_accuracy: 0.8447 - val_loss: 0.3517\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.3788 - val_accuracy: 0.8453 - val_loss: 0.3506\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.3796 - val_accuracy: 0.8503 - val_loss: 0.3459\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.3729 - val_accuracy: 0.8518 - val_loss: 0.3444\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.3806 - val_accuracy: 0.8504 - val_loss: 0.3471\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8314 - loss: 0.3756 - val_accuracy: 0.8431 - val_loss: 0.3632\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.3776 - val_accuracy: 0.8469 - val_loss: 0.3498\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8323 - loss: 0.3762 - val_accuracy: 0.8552 - val_loss: 0.3396\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.3722 - val_accuracy: 0.8503 - val_loss: 0.3432\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8315 - loss: 0.3747 - val_accuracy: 0.8427 - val_loss: 0.3500\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.3744 - val_accuracy: 0.8508 - val_loss: 0.3421\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8291 - loss: 0.3778 - val_accuracy: 0.8543 - val_loss: 0.3408\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8347 - loss: 0.3718 - val_accuracy: 0.8500 - val_loss: 0.3461\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3757 - val_accuracy: 0.8534 - val_loss: 0.3411\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.3727 - val_accuracy: 0.8526 - val_loss: 0.3394\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8384 - loss: 0.3671 - val_accuracy: 0.8544 - val_loss: 0.3406\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3710 - val_accuracy: 0.8539 - val_loss: 0.3376\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8361 - loss: 0.3742 - val_accuracy: 0.8529 - val_loss: 0.3382\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.3709 - val_accuracy: 0.8529 - val_loss: 0.3384\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8335 - loss: 0.3735 - val_accuracy: 0.8546 - val_loss: 0.3414\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.3389\n",
            "Test Loss: 0.3386\n",
            "Test Accuracy: 0.8555\n",
            "Confusion Matrix:\n",
            "[[6794 1144]\n",
            " [1267 7485]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85      7938\n",
            "           1       0.87      0.86      0.86      8752\n",
            "\n",
            "    accuracy                           0.86     16690\n",
            "   macro avg       0.86      0.86      0.86     16690\n",
            "weighted avg       0.86      0.86      0.86     16690\n",
            "\n",
            "Accuracy: 0.8555\n",
            "Precision: 0.8674\n",
            "Recall: 0.8552\n",
            "F1 Score: 0.8613\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the DNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input and hidden layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhLm7bb14fjc"
      },
      "source": [
        "improved dnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syZka_d-4fjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4920582-cf7a-4400-d9b1-f89c255180b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6250 - loss: 0.6654 - val_accuracy: 0.6934 - val_loss: 0.5885\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6853 - loss: 0.5972 - val_accuracy: 0.7612 - val_loss: 0.5070\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7506 - loss: 0.5280 - val_accuracy: 0.7746 - val_loss: 0.4813\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7661 - loss: 0.5033 - val_accuracy: 0.7800 - val_loss: 0.4584\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7769 - loss: 0.4876 - val_accuracy: 0.7819 - val_loss: 0.4644\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7836 - loss: 0.4746 - val_accuracy: 0.8010 - val_loss: 0.4368\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7889 - loss: 0.4640 - val_accuracy: 0.8041 - val_loss: 0.4235\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7922 - loss: 0.4597 - val_accuracy: 0.8065 - val_loss: 0.4237\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7962 - loss: 0.4509 - val_accuracy: 0.7960 - val_loss: 0.4386\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7987 - loss: 0.4462 - val_accuracy: 0.8136 - val_loss: 0.4126\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8016 - loss: 0.4417 - val_accuracy: 0.8098 - val_loss: 0.4151\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8027 - loss: 0.4391 - val_accuracy: 0.8136 - val_loss: 0.4140\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8048 - loss: 0.4327 - val_accuracy: 0.8149 - val_loss: 0.4079\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8063 - loss: 0.4338 - val_accuracy: 0.8053 - val_loss: 0.4307\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8046 - loss: 0.4330 - val_accuracy: 0.8167 - val_loss: 0.4102\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8128 - loss: 0.4234 - val_accuracy: 0.8148 - val_loss: 0.4033\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8113 - loss: 0.4248 - val_accuracy: 0.8197 - val_loss: 0.4017\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8151 - loss: 0.4186 - val_accuracy: 0.8204 - val_loss: 0.3998\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8163 - loss: 0.4157 - val_accuracy: 0.8258 - val_loss: 0.3886\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8127 - loss: 0.4210 - val_accuracy: 0.8200 - val_loss: 0.4027\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8175 - loss: 0.4171 - val_accuracy: 0.8127 - val_loss: 0.4250\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8203 - loss: 0.4128 - val_accuracy: 0.8232 - val_loss: 0.3881\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8187 - loss: 0.4102 - val_accuracy: 0.8223 - val_loss: 0.3941\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8184 - loss: 0.4104 - val_accuracy: 0.8228 - val_loss: 0.3925\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8189 - loss: 0.4114 - val_accuracy: 0.8247 - val_loss: 0.3879\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8195 - loss: 0.4074 - val_accuracy: 0.8273 - val_loss: 0.3845\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8199 - loss: 0.4062 - val_accuracy: 0.8256 - val_loss: 0.3863\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8235 - loss: 0.4000 - val_accuracy: 0.8295 - val_loss: 0.3856\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8246 - loss: 0.4016 - val_accuracy: 0.8253 - val_loss: 0.3916\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8220 - loss: 0.4029 - val_accuracy: 0.8301 - val_loss: 0.3794\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8197 - loss: 0.4012 - val_accuracy: 0.8188 - val_loss: 0.3936\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8239 - loss: 0.3992 - val_accuracy: 0.8326 - val_loss: 0.3753\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8226 - loss: 0.4017 - val_accuracy: 0.8304 - val_loss: 0.3804\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8246 - loss: 0.3981 - val_accuracy: 0.8330 - val_loss: 0.3785\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8236 - loss: 0.3972 - val_accuracy: 0.8324 - val_loss: 0.3759\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8252 - loss: 0.3992 - val_accuracy: 0.8354 - val_loss: 0.3762\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8294 - loss: 0.3921 - val_accuracy: 0.8342 - val_loss: 0.3725\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8252 - loss: 0.3961 - val_accuracy: 0.8207 - val_loss: 0.3868\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8282 - loss: 0.3935 - val_accuracy: 0.8370 - val_loss: 0.3709\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8277 - loss: 0.3977 - val_accuracy: 0.8299 - val_loss: 0.3778\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8229 - loss: 0.3954 - val_accuracy: 0.8316 - val_loss: 0.3757\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8292 - loss: 0.3896 - val_accuracy: 0.8343 - val_loss: 0.3717\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8294 - loss: 0.3913 - val_accuracy: 0.8307 - val_loss: 0.3753\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8271 - loss: 0.3876 - val_accuracy: 0.8355 - val_loss: 0.3760\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8268 - loss: 0.3888 - val_accuracy: 0.8325 - val_loss: 0.3692\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8315 - loss: 0.3851 - val_accuracy: 0.8356 - val_loss: 0.3698\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8282 - loss: 0.3884 - val_accuracy: 0.8356 - val_loss: 0.3751\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8296 - loss: 0.3869 - val_accuracy: 0.8368 - val_loss: 0.3669\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8309 - loss: 0.3839 - val_accuracy: 0.8319 - val_loss: 0.3734\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8315 - loss: 0.3834 - val_accuracy: 0.8352 - val_loss: 0.3741\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.3753\n",
            "Test Loss: 0.3720\n",
            "Test Accuracy: 0.8364\n",
            "Confusion Matrix:\n",
            "[[6698 1240]\n",
            " [1491 7261]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      7938\n",
            "           1       0.85      0.83      0.84      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8364\n",
            "Precision: 0.8541\n",
            "Recall: 0.8296\n",
            "F1 Score: 0.8417\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVQ-9Qe-4fjd"
      },
      "source": [
        "improved dnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxRvdJJS4fjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8910597-1a13-4b58-e70d-21eba5510b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - accuracy: 0.5826 - loss: 0.7403 - val_accuracy: 0.6628 - val_loss: 0.6195\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.6691 - loss: 0.6108 - val_accuracy: 0.7370 - val_loss: 0.5367\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.7270 - loss: 0.5485 - val_accuracy: 0.7717 - val_loss: 0.4795\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.7623 - loss: 0.4998 - val_accuracy: 0.7857 - val_loss: 0.4571\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7752 - loss: 0.4783 - val_accuracy: 0.8033 - val_loss: 0.4295\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.7867 - loss: 0.4612 - val_accuracy: 0.7991 - val_loss: 0.4413\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.7902 - loss: 0.4527 - val_accuracy: 0.8132 - val_loss: 0.4185\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.7965 - loss: 0.4482 - val_accuracy: 0.8201 - val_loss: 0.4062\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8020 - loss: 0.4314 - val_accuracy: 0.8179 - val_loss: 0.4007\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8040 - loss: 0.4290 - val_accuracy: 0.8220 - val_loss: 0.3959\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8091 - loss: 0.4214 - val_accuracy: 0.8243 - val_loss: 0.3905\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8083 - loss: 0.4213 - val_accuracy: 0.8256 - val_loss: 0.3898\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8090 - loss: 0.4180 - val_accuracy: 0.8214 - val_loss: 0.3996\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8094 - loss: 0.4167 - val_accuracy: 0.8282 - val_loss: 0.3873\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8130 - loss: 0.4168 - val_accuracy: 0.8242 - val_loss: 0.3907\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8130 - loss: 0.4127 - val_accuracy: 0.8357 - val_loss: 0.3749\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8183 - loss: 0.4052 - val_accuracy: 0.8339 - val_loss: 0.3848\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8152 - loss: 0.4099 - val_accuracy: 0.8366 - val_loss: 0.3717\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8198 - loss: 0.3993 - val_accuracy: 0.8365 - val_loss: 0.3684\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8174 - loss: 0.4036 - val_accuracy: 0.8331 - val_loss: 0.3750\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8234 - loss: 0.3965 - val_accuracy: 0.8378 - val_loss: 0.3721\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8210 - loss: 0.3965 - val_accuracy: 0.8379 - val_loss: 0.3703\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8229 - loss: 0.3929 - val_accuracy: 0.8343 - val_loss: 0.3719\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8211 - loss: 0.3982 - val_accuracy: 0.8384 - val_loss: 0.3711\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8215 - loss: 0.3936 - val_accuracy: 0.8405 - val_loss: 0.3648\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8245 - loss: 0.3910 - val_accuracy: 0.8399 - val_loss: 0.3609\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8261 - loss: 0.3903 - val_accuracy: 0.8427 - val_loss: 0.3619\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8246 - loss: 0.3891 - val_accuracy: 0.8388 - val_loss: 0.3688\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8249 - loss: 0.3923 - val_accuracy: 0.8420 - val_loss: 0.3600\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8278 - loss: 0.3854 - val_accuracy: 0.8302 - val_loss: 0.3840\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8289 - loss: 0.3849 - val_accuracy: 0.8385 - val_loss: 0.3655\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8264 - loss: 0.3854 - val_accuracy: 0.8431 - val_loss: 0.3615\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8324 - loss: 0.3816 - val_accuracy: 0.8374 - val_loss: 0.3704\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - accuracy: 0.8269 - loss: 0.3858 - val_accuracy: 0.8443 - val_loss: 0.3557\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - accuracy: 0.8325 - loss: 0.3768 - val_accuracy: 0.8397 - val_loss: 0.3641\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8303 - loss: 0.3809 - val_accuracy: 0.8456 - val_loss: 0.3573\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8324 - loss: 0.3796 - val_accuracy: 0.8450 - val_loss: 0.3530\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8355 - loss: 0.3707 - val_accuracy: 0.8341 - val_loss: 0.3808\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8312 - loss: 0.3782 - val_accuracy: 0.8444 - val_loss: 0.3546\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8342 - loss: 0.3743 - val_accuracy: 0.8455 - val_loss: 0.3512\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8332 - loss: 0.3724 - val_accuracy: 0.8414 - val_loss: 0.3603\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8347 - loss: 0.3711 - val_accuracy: 0.8301 - val_loss: 0.3742\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8345 - loss: 0.3723 - val_accuracy: 0.8464 - val_loss: 0.3540\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8381 - loss: 0.3708 - val_accuracy: 0.8423 - val_loss: 0.3584\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8358 - loss: 0.3664 - val_accuracy: 0.8469 - val_loss: 0.3563\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8334 - loss: 0.3726 - val_accuracy: 0.8435 - val_loss: 0.3548\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8362 - loss: 0.3705 - val_accuracy: 0.8482 - val_loss: 0.3481\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8372 - loss: 0.3678 - val_accuracy: 0.8396 - val_loss: 0.3618\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8387 - loss: 0.3635 - val_accuracy: 0.8373 - val_loss: 0.3726\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8381 - loss: 0.3683 - val_accuracy: 0.8421 - val_loss: 0.3613\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.3578\n",
            "Test Loss: 0.3530\n",
            "Test Accuracy: 0.8454\n",
            "Confusion Matrix:\n",
            "[[6921 1017]\n",
            " [1563 7189]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84      7938\n",
            "           1       0.88      0.82      0.85      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8454\n",
            "Precision: 0.8761\n",
            "Recall: 0.8214\n",
            "F1 Score: 0.8479\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Reshape output from Dense layers to be suitable for GRU layers\n",
        "model.add(tf.keras.layers.Reshape((X_train_reshaped.shape[1], 32)))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgfsYHnFF8o4"
      },
      "source": [
        "##Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtKdaR54-Kdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "outputId": "16aa154d-13c8-46d0-de67-b93e9c0ce0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "                        Feature  Importance\n",
            "2   Repititive-Words-in-a-Email    0.328655\n",
            "10                Neu-Sentiment    0.193098\n",
            "8                  Spam lexicon    0.173397\n",
            "3       Uinque-Words-in-a-Email    0.070117\n",
            "13                     Polarity    0.051324\n",
            "0               Length-of-Email    0.046473\n",
            "7                Number-of-noun    0.041711\n",
            "9                 Neg-Sentiment    0.033426\n",
            "14                   Subjective    0.022617\n",
            "12               Comp-Sentiment    0.010863\n",
            "11                Pos-Sentiment    0.010829\n",
            "4        Quoted-text-in-a-Email    0.006835\n",
            "5     Question-Marks-in-a-Email    0.006091\n",
            "6   Number of co-occuring words    0.004563\n",
            "1   Number of capitalized words    0.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label','Unnamed: 0'], axis=1)\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the Gradient Boosting Classifier\n",
        "clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = clf.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display feature importances\n",
        "print(\"Feature Importances:\")\n",
        "print(feature_importances)\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
        "plt.title('Feature Importances from Gradient Boosting Classifier')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzshhNk578pY"
      },
      "source": [
        "10-Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQlY2zRe78pZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48343e1d-7568-4379-d4dd-23b1cf5a60c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Repititive-Words-in-a-Email',\n",
              " 'Neu-Sentiment',\n",
              " 'Spam lexicon',\n",
              " 'Uinque-Words-in-a-Email',\n",
              " 'Polarity',\n",
              " 'Length-of-Email',\n",
              " 'Number-of-noun',\n",
              " 'Neg-Sentiment',\n",
              " 'Subjective',\n",
              " 'Comp-Sentiment']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "features=feature_importances.nlargest(n=10, columns='Importance')['Feature'].to_list()\n",
        "features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l05EAxLz78pZ"
      },
      "source": [
        "improved rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oH-k5RH78pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935fe2ac-dd5f-41ad-cd6d-5a7d2ce0a467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7033 - loss: 0.5779 - val_accuracy: 0.7883 - val_loss: 0.4633\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7812 - loss: 0.4722 - val_accuracy: 0.7881 - val_loss: 0.4499\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7917 - loss: 0.4552 - val_accuracy: 0.8109 - val_loss: 0.4181\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.4498 - val_accuracy: 0.8048 - val_loss: 0.4185\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7945 - loss: 0.4440 - val_accuracy: 0.7954 - val_loss: 0.4409\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7995 - loss: 0.4414 - val_accuracy: 0.8095 - val_loss: 0.4327\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8007 - loss: 0.4367 - val_accuracy: 0.8110 - val_loss: 0.4091\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.4300 - val_accuracy: 0.8101 - val_loss: 0.4321\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4247 - val_accuracy: 0.8143 - val_loss: 0.4121\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8105 - loss: 0.4228 - val_accuracy: 0.8215 - val_loss: 0.3975\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.4226 - val_accuracy: 0.8223 - val_loss: 0.4014\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4217 - val_accuracy: 0.8250 - val_loss: 0.3977\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.4186 - val_accuracy: 0.8246 - val_loss: 0.4088\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8146 - loss: 0.4138 - val_accuracy: 0.8088 - val_loss: 0.4162\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8177 - loss: 0.4098 - val_accuracy: 0.8207 - val_loss: 0.4023\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8238 - loss: 0.4048 - val_accuracy: 0.8241 - val_loss: 0.3985\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8208 - loss: 0.4042 - val_accuracy: 0.8283 - val_loss: 0.3905\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8193 - loss: 0.4076 - val_accuracy: 0.8198 - val_loss: 0.3987\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8234 - loss: 0.4015 - val_accuracy: 0.8270 - val_loss: 0.3893\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.4016 - val_accuracy: 0.8161 - val_loss: 0.3953\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8269 - loss: 0.3954 - val_accuracy: 0.8298 - val_loss: 0.3860\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8293 - loss: 0.3952 - val_accuracy: 0.8312 - val_loss: 0.3859\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.3957 - val_accuracy: 0.8305 - val_loss: 0.3792\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8242 - loss: 0.3983 - val_accuracy: 0.8338 - val_loss: 0.3815\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8289 - loss: 0.3933 - val_accuracy: 0.8308 - val_loss: 0.3828\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8268 - loss: 0.3918 - val_accuracy: 0.8274 - val_loss: 0.3843\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8313 - loss: 0.3839 - val_accuracy: 0.8346 - val_loss: 0.3793\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8306 - loss: 0.3916 - val_accuracy: 0.8358 - val_loss: 0.3785\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.3828 - val_accuracy: 0.8340 - val_loss: 0.3728\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8315 - loss: 0.3865 - val_accuracy: 0.8359 - val_loss: 0.3730\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8340 - loss: 0.3811 - val_accuracy: 0.8362 - val_loss: 0.3744\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8329 - loss: 0.3851 - val_accuracy: 0.8390 - val_loss: 0.3674\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.3844 - val_accuracy: 0.8361 - val_loss: 0.3649\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8318 - loss: 0.3822 - val_accuracy: 0.8281 - val_loss: 0.3766\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 0.3773 - val_accuracy: 0.8370 - val_loss: 0.3658\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8367 - loss: 0.3762 - val_accuracy: 0.8360 - val_loss: 0.3664\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 0.3774 - val_accuracy: 0.8417 - val_loss: 0.3652\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 0.3712 - val_accuracy: 0.8415 - val_loss: 0.3617\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.3730 - val_accuracy: 0.8373 - val_loss: 0.3683\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8382 - loss: 0.3708 - val_accuracy: 0.8402 - val_loss: 0.3663\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 0.3736 - val_accuracy: 0.8344 - val_loss: 0.3652\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 0.3729 - val_accuracy: 0.8422 - val_loss: 0.3693\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 0.3677 - val_accuracy: 0.8406 - val_loss: 0.3609\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.3716 - val_accuracy: 0.8396 - val_loss: 0.3619\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 0.3654 - val_accuracy: 0.8383 - val_loss: 0.3661\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.3680 - val_accuracy: 0.8405 - val_loss: 0.3618\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8406 - loss: 0.3675 - val_accuracy: 0.8447 - val_loss: 0.3554\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8426 - loss: 0.3629 - val_accuracy: 0.8363 - val_loss: 0.3645\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8425 - loss: 0.3632 - val_accuracy: 0.8428 - val_loss: 0.3566\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8394 - loss: 0.3649 - val_accuracy: 0.8431 - val_loss: 0.3563\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8404 - loss: 0.3631\n",
            "Test Loss: 0.3568\n",
            "Test Accuracy: 0.8434\n",
            "Confusion Matrix:\n",
            "[[6688 1250]\n",
            " [1364 7388]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.84      7938\n",
            "           1       0.86      0.84      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8434\n",
            "Precision: 0.8553\n",
            "Recall: 0.8441\n",
            "F1 Score: 0.8497\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# RNN layers\n",
        "model.add(SimpleRNN(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(SimpleRNN(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br_Mzvl178pa"
      },
      "source": [
        "improved rnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-07r11PK78pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a5f0a8-5b53-4645-8a4d-2b92648325ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.6362 - loss: 0.6536 - val_accuracy: 0.7421 - val_loss: 0.5235\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7317 - loss: 0.5448 - val_accuracy: 0.7686 - val_loss: 0.4889\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.7587 - loss: 0.5098 - val_accuracy: 0.7871 - val_loss: 0.4688\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.7780 - loss: 0.4806 - val_accuracy: 0.7874 - val_loss: 0.4558\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7800 - loss: 0.4712 - val_accuracy: 0.8038 - val_loss: 0.4337\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.7876 - loss: 0.4586 - val_accuracy: 0.7913 - val_loss: 0.4519\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.7932 - loss: 0.4523 - val_accuracy: 0.8096 - val_loss: 0.4247\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.7937 - loss: 0.4499 - val_accuracy: 0.7937 - val_loss: 0.4704\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8004 - loss: 0.4442 - val_accuracy: 0.7909 - val_loss: 0.4704\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8031 - loss: 0.4375 - val_accuracy: 0.8169 - val_loss: 0.4133\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8071 - loss: 0.4323 - val_accuracy: 0.8173 - val_loss: 0.4111\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8035 - loss: 0.4322 - val_accuracy: 0.8062 - val_loss: 0.4231\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8039 - loss: 0.4334 - val_accuracy: 0.8173 - val_loss: 0.4070\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8105 - loss: 0.4248 - val_accuracy: 0.8140 - val_loss: 0.4185\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8094 - loss: 0.4272 - val_accuracy: 0.8133 - val_loss: 0.4133\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8081 - loss: 0.4261 - val_accuracy: 0.8128 - val_loss: 0.4131\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8138 - loss: 0.4177 - val_accuracy: 0.8172 - val_loss: 0.4054\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8158 - loss: 0.4179 - val_accuracy: 0.8137 - val_loss: 0.4128\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.8130 - loss: 0.4178 - val_accuracy: 0.8139 - val_loss: 0.4160\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8163 - loss: 0.4154 - val_accuracy: 0.8143 - val_loss: 0.4306\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8161 - loss: 0.4138 - val_accuracy: 0.8239 - val_loss: 0.3958\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8189 - loss: 0.4100 - val_accuracy: 0.8189 - val_loss: 0.4030\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8176 - loss: 0.4103 - val_accuracy: 0.8041 - val_loss: 0.4163\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8193 - loss: 0.4066 - val_accuracy: 0.7989 - val_loss: 0.4181\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8188 - loss: 0.4103 - val_accuracy: 0.8272 - val_loss: 0.3909\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8194 - loss: 0.4096 - val_accuracy: 0.8268 - val_loss: 0.3926\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8180 - loss: 0.4049 - val_accuracy: 0.8294 - val_loss: 0.3880\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8167 - loss: 0.4116 - val_accuracy: 0.8174 - val_loss: 0.3945\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8244 - loss: 0.3989 - val_accuracy: 0.8311 - val_loss: 0.3867\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8214 - loss: 0.4028 - val_accuracy: 0.8301 - val_loss: 0.3840\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8238 - loss: 0.4004 - val_accuracy: 0.8265 - val_loss: 0.3947\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8281 - loss: 0.3960 - val_accuracy: 0.8255 - val_loss: 0.3885\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8244 - loss: 0.3958 - val_accuracy: 0.8286 - val_loss: 0.3884\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8251 - loss: 0.3927 - val_accuracy: 0.8239 - val_loss: 0.4031\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8233 - loss: 0.3991 - val_accuracy: 0.8322 - val_loss: 0.3780\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8265 - loss: 0.3945 - val_accuracy: 0.8331 - val_loss: 0.3783\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8286 - loss: 0.3910 - val_accuracy: 0.8257 - val_loss: 0.3863\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8274 - loss: 0.3895 - val_accuracy: 0.8328 - val_loss: 0.3818\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8282 - loss: 0.3885 - val_accuracy: 0.8309 - val_loss: 0.3805\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8279 - loss: 0.3912 - val_accuracy: 0.8307 - val_loss: 0.3810\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8289 - loss: 0.3887 - val_accuracy: 0.8344 - val_loss: 0.3776\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8320 - loss: 0.3839 - val_accuracy: 0.8307 - val_loss: 0.3792\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8297 - loss: 0.3851 - val_accuracy: 0.8341 - val_loss: 0.3743\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8329 - loss: 0.3838 - val_accuracy: 0.8364 - val_loss: 0.3761\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8311 - loss: 0.3844 - val_accuracy: 0.8368 - val_loss: 0.3729\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8310 - loss: 0.3865 - val_accuracy: 0.8343 - val_loss: 0.3727\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8282 - loss: 0.3895 - val_accuracy: 0.8370 - val_loss: 0.3673\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8317 - loss: 0.3806 - val_accuracy: 0.8367 - val_loss: 0.3681\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8326 - loss: 0.3829 - val_accuracy: 0.8361 - val_loss: 0.3672\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8317 - loss: 0.3828 - val_accuracy: 0.8385 - val_loss: 0.3687\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8307 - loss: 0.3742\n",
            "Test Loss: 0.3702\n",
            "Test Accuracy: 0.8339\n",
            "Confusion Matrix:\n",
            "[[6720 1218]\n",
            " [1554 7198]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.85      0.83      7938\n",
            "           1       0.86      0.82      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8339\n",
            "Precision: 0.8553\n",
            "Recall: 0.8224\n",
            "F1 Score: 0.8385\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7-dPn2T78pb"
      },
      "source": [
        "improved rnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYN5vrJl78pb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac057ada-137b-4968-fe7c-ba280afaf0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5986 - loss: 0.6859 - val_accuracy: 0.6751 - val_loss: 0.6201\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7409 - loss: 0.5364 - val_accuracy: 0.5874 - val_loss: 0.8004\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.7775 - loss: 0.4795 - val_accuracy: 0.7745 - val_loss: 0.4747\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.7832 - loss: 0.4689 - val_accuracy: 0.7850 - val_loss: 0.4635\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.7933 - loss: 0.4551 - val_accuracy: 0.7927 - val_loss: 0.4461\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.7943 - loss: 0.4478 - val_accuracy: 0.8082 - val_loss: 0.4249\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8001 - loss: 0.4431 - val_accuracy: 0.8053 - val_loss: 0.4315\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7987 - loss: 0.4428 - val_accuracy: 0.8143 - val_loss: 0.4158\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8031 - loss: 0.4354 - val_accuracy: 0.8106 - val_loss: 0.4183\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8030 - loss: 0.4354 - val_accuracy: 0.8054 - val_loss: 0.4170\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8064 - loss: 0.4298 - val_accuracy: 0.8214 - val_loss: 0.4074\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8076 - loss: 0.4264 - val_accuracy: 0.8232 - val_loss: 0.4073\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8111 - loss: 0.4259 - val_accuracy: 0.7890 - val_loss: 0.4373\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8070 - loss: 0.4271 - val_accuracy: 0.8217 - val_loss: 0.4022\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8087 - loss: 0.4227 - val_accuracy: 0.8211 - val_loss: 0.4042\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8118 - loss: 0.4205 - val_accuracy: 0.8197 - val_loss: 0.4006\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8147 - loss: 0.4129 - val_accuracy: 0.8116 - val_loss: 0.4124\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8172 - loss: 0.4142 - val_accuracy: 0.8191 - val_loss: 0.4008\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8155 - loss: 0.4122 - val_accuracy: 0.8245 - val_loss: 0.3960\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8172 - loss: 0.4125 - val_accuracy: 0.8092 - val_loss: 0.4104\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8197 - loss: 0.4069 - val_accuracy: 0.8298 - val_loss: 0.3908\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8194 - loss: 0.4080 - val_accuracy: 0.8279 - val_loss: 0.3898\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8211 - loss: 0.4035 - val_accuracy: 0.8223 - val_loss: 0.3992\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8186 - loss: 0.4065 - val_accuracy: 0.8290 - val_loss: 0.3868\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8216 - loss: 0.4027 - val_accuracy: 0.8246 - val_loss: 0.3886\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8227 - loss: 0.4066 - val_accuracy: 0.8295 - val_loss: 0.3842\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8211 - loss: 0.4045 - val_accuracy: 0.8295 - val_loss: 0.3864\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8198 - loss: 0.3989 - val_accuracy: 0.8245 - val_loss: 0.3913\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8254 - loss: 0.3975 - val_accuracy: 0.8272 - val_loss: 0.3848\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8227 - loss: 0.3989 - val_accuracy: 0.8255 - val_loss: 0.3902\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8223 - loss: 0.3979 - val_accuracy: 0.8303 - val_loss: 0.3803\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8211 - loss: 0.3990 - val_accuracy: 0.8260 - val_loss: 0.3921\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8246 - loss: 0.3934 - val_accuracy: 0.8331 - val_loss: 0.3752\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8257 - loss: 0.3967 - val_accuracy: 0.8261 - val_loss: 0.3856\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8267 - loss: 0.3907 - val_accuracy: 0.8326 - val_loss: 0.3780\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8235 - loss: 0.3940 - val_accuracy: 0.8269 - val_loss: 0.3915\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8281 - loss: 0.3930 - val_accuracy: 0.8338 - val_loss: 0.3705\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8260 - loss: 0.3905 - val_accuracy: 0.8168 - val_loss: 0.3905\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8285 - loss: 0.3879 - val_accuracy: 0.8351 - val_loss: 0.3719\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8268 - loss: 0.3869 - val_accuracy: 0.8314 - val_loss: 0.3801\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8319 - loss: 0.3834 - val_accuracy: 0.8331 - val_loss: 0.3735\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8303 - loss: 0.3840 - val_accuracy: 0.8361 - val_loss: 0.3728\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8333 - loss: 0.3800 - val_accuracy: 0.8363 - val_loss: 0.3681\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8296 - loss: 0.3847 - val_accuracy: 0.8368 - val_loss: 0.3703\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8303 - loss: 0.3840 - val_accuracy: 0.8367 - val_loss: 0.3640\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8356 - loss: 0.3755 - val_accuracy: 0.8364 - val_loss: 0.3675\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8342 - loss: 0.3783 - val_accuracy: 0.8319 - val_loss: 0.3686\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8357 - loss: 0.3753 - val_accuracy: 0.8331 - val_loss: 0.3735\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8325 - loss: 0.3806 - val_accuracy: 0.8197 - val_loss: 0.3850\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8339 - loss: 0.3777 - val_accuracy: 0.8358 - val_loss: 0.3676\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.3689\n",
            "Test Loss: 0.3660\n",
            "Test Accuracy: 0.8357\n",
            "Confusion Matrix:\n",
            "[[6667 1271]\n",
            " [1472 7280]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      7938\n",
            "           1       0.85      0.83      0.84      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8357\n",
            "Precision: 0.8514\n",
            "Recall: 0.8318\n",
            "F1 Score: 0.8415\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWoExpcJ78pb"
      },
      "source": [
        "improved cnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XACoWPuS78pb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b2d314-4f63-4edc-ee34-1c57fa9e3613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.6576 - loss: 0.6739 - val_accuracy: 0.7754 - val_loss: 0.4821\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.5107 - val_accuracy: 0.7877 - val_loss: 0.4624\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7710 - loss: 0.4855 - val_accuracy: 0.7964 - val_loss: 0.4434\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.4748 - val_accuracy: 0.7958 - val_loss: 0.4363\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7803 - loss: 0.4705 - val_accuracy: 0.8018 - val_loss: 0.4309\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.4608 - val_accuracy: 0.8008 - val_loss: 0.4274\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7871 - loss: 0.4573 - val_accuracy: 0.8026 - val_loss: 0.4233\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7902 - loss: 0.4514 - val_accuracy: 0.8113 - val_loss: 0.4186\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.4466 - val_accuracy: 0.8101 - val_loss: 0.4201\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7930 - loss: 0.4461 - val_accuracy: 0.8104 - val_loss: 0.4184\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7932 - loss: 0.4478 - val_accuracy: 0.8071 - val_loss: 0.4170\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7936 - loss: 0.4497 - val_accuracy: 0.8116 - val_loss: 0.4135\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.4388 - val_accuracy: 0.8125 - val_loss: 0.4120\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8016 - loss: 0.4365 - val_accuracy: 0.8115 - val_loss: 0.4147\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.4394 - val_accuracy: 0.8118 - val_loss: 0.4090\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.4339 - val_accuracy: 0.8170 - val_loss: 0.4061\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.4364 - val_accuracy: 0.8148 - val_loss: 0.4063\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8010 - loss: 0.4357 - val_accuracy: 0.8144 - val_loss: 0.4055\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.4310 - val_accuracy: 0.8153 - val_loss: 0.4067\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4338 - val_accuracy: 0.8152 - val_loss: 0.4066\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.4308 - val_accuracy: 0.8122 - val_loss: 0.4083\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.4275 - val_accuracy: 0.8183 - val_loss: 0.4013\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.4331 - val_accuracy: 0.8200 - val_loss: 0.3998\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.4294 - val_accuracy: 0.8178 - val_loss: 0.4014\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.4327 - val_accuracy: 0.8170 - val_loss: 0.4031\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.4316 - val_accuracy: 0.8181 - val_loss: 0.3987\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.4322 - val_accuracy: 0.8203 - val_loss: 0.3960\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.4236 - val_accuracy: 0.8155 - val_loss: 0.4019\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.4293 - val_accuracy: 0.8215 - val_loss: 0.3947\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.4265 - val_accuracy: 0.8163 - val_loss: 0.3987\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4261 - val_accuracy: 0.8191 - val_loss: 0.3999\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8063 - loss: 0.4292 - val_accuracy: 0.8229 - val_loss: 0.3943\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8064 - loss: 0.4295 - val_accuracy: 0.8197 - val_loss: 0.3958\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.4285 - val_accuracy: 0.8113 - val_loss: 0.4124\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8036 - loss: 0.4298 - val_accuracy: 0.8209 - val_loss: 0.3935\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8116 - loss: 0.4187 - val_accuracy: 0.8082 - val_loss: 0.4117\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8098 - loss: 0.4198 - val_accuracy: 0.8173 - val_loss: 0.3979\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.4264 - val_accuracy: 0.8155 - val_loss: 0.4018\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4294 - val_accuracy: 0.8000 - val_loss: 0.4312\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8077 - loss: 0.4245 - val_accuracy: 0.8194 - val_loss: 0.3976\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4247 - val_accuracy: 0.8226 - val_loss: 0.3938\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.4226 - val_accuracy: 0.8191 - val_loss: 0.3995\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.4257 - val_accuracy: 0.8229 - val_loss: 0.3926\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.4249 - val_accuracy: 0.8246 - val_loss: 0.3891\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.4218 - val_accuracy: 0.8247 - val_loss: 0.3916\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4218 - val_accuracy: 0.8265 - val_loss: 0.3959\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8078 - loss: 0.4237 - val_accuracy: 0.8008 - val_loss: 0.4257\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8092 - loss: 0.4194 - val_accuracy: 0.8261 - val_loss: 0.3867\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8114 - loss: 0.4166 - val_accuracy: 0.8244 - val_loss: 0.3891\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.4205 - val_accuracy: 0.8259 - val_loss: 0.3909\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.3845\n",
            "Test Loss: 0.3842\n",
            "Test Accuracy: 0.8312\n",
            "Confusion Matrix:\n",
            "[[6447 1491]\n",
            " [1326 7426]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82      7938\n",
            "           1       0.83      0.85      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8312\n",
            "Precision: 0.8328\n",
            "Recall: 0.8485\n",
            "F1 Score: 0.8406\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the optimized CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRJkARJr78pc"
      },
      "source": [
        "improved cnn-lstm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuvdzF1L78pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc66365-6c19-4a1a-80b5-153aa0e07403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6987 - loss: 0.5780 - val_accuracy: 0.7857 - val_loss: 0.4577\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7762 - loss: 0.4792 - val_accuracy: 0.7960 - val_loss: 0.4411\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7815 - loss: 0.4732 - val_accuracy: 0.7988 - val_loss: 0.4376\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7857 - loss: 0.4610 - val_accuracy: 0.8023 - val_loss: 0.4266\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7915 - loss: 0.4559 - val_accuracy: 0.8097 - val_loss: 0.4225\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7928 - loss: 0.4522 - val_accuracy: 0.8084 - val_loss: 0.4183\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7930 - loss: 0.4484 - val_accuracy: 0.8098 - val_loss: 0.4179\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7918 - loss: 0.4468 - val_accuracy: 0.8109 - val_loss: 0.4145\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7950 - loss: 0.4421 - val_accuracy: 0.8092 - val_loss: 0.4191\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7984 - loss: 0.4407 - val_accuracy: 0.8170 - val_loss: 0.4112\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7985 - loss: 0.4401 - val_accuracy: 0.8158 - val_loss: 0.4080\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8015 - loss: 0.4337 - val_accuracy: 0.8149 - val_loss: 0.4073\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8047 - loss: 0.4267 - val_accuracy: 0.8134 - val_loss: 0.4053\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8035 - loss: 0.4317 - val_accuracy: 0.8164 - val_loss: 0.4027\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8006 - loss: 0.4322 - val_accuracy: 0.8186 - val_loss: 0.3989\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8048 - loss: 0.4299 - val_accuracy: 0.8185 - val_loss: 0.4047\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8074 - loss: 0.4264 - val_accuracy: 0.8213 - val_loss: 0.4002\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8003 - loss: 0.4325 - val_accuracy: 0.8189 - val_loss: 0.3970\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8078 - loss: 0.4241 - val_accuracy: 0.8191 - val_loss: 0.4016\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8079 - loss: 0.4267 - val_accuracy: 0.8227 - val_loss: 0.3946\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8044 - loss: 0.4255 - val_accuracy: 0.8203 - val_loss: 0.3949\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8052 - loss: 0.4241 - val_accuracy: 0.8185 - val_loss: 0.4022\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8091 - loss: 0.4227 - val_accuracy: 0.8225 - val_loss: 0.3951\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8124 - loss: 0.4170 - val_accuracy: 0.8262 - val_loss: 0.3904\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8090 - loss: 0.4182 - val_accuracy: 0.8170 - val_loss: 0.4007\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8056 - loss: 0.4199 - val_accuracy: 0.8207 - val_loss: 0.3895\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8057 - loss: 0.4245 - val_accuracy: 0.8229 - val_loss: 0.3910\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8055 - loss: 0.4252 - val_accuracy: 0.8230 - val_loss: 0.3874\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8109 - loss: 0.4180 - val_accuracy: 0.8242 - val_loss: 0.3866\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8119 - loss: 0.4165 - val_accuracy: 0.8244 - val_loss: 0.3887\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8119 - loss: 0.4132 - val_accuracy: 0.8251 - val_loss: 0.3873\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8115 - loss: 0.4143 - val_accuracy: 0.8235 - val_loss: 0.3899\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8098 - loss: 0.4174 - val_accuracy: 0.8238 - val_loss: 0.3884\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8089 - loss: 0.4184 - val_accuracy: 0.8244 - val_loss: 0.3871\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8153 - loss: 0.4096 - val_accuracy: 0.8267 - val_loss: 0.3846\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8131 - loss: 0.4143 - val_accuracy: 0.8255 - val_loss: 0.3833\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8116 - loss: 0.4146 - val_accuracy: 0.8161 - val_loss: 0.4059\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8121 - loss: 0.4132 - val_accuracy: 0.8154 - val_loss: 0.4065\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8099 - loss: 0.4184 - val_accuracy: 0.8263 - val_loss: 0.3851\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8133 - loss: 0.4128 - val_accuracy: 0.8301 - val_loss: 0.3828\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8137 - loss: 0.4096 - val_accuracy: 0.8228 - val_loss: 0.3860\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8104 - loss: 0.4159 - val_accuracy: 0.8272 - val_loss: 0.3821\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8176 - loss: 0.4073 - val_accuracy: 0.8292 - val_loss: 0.3804\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8112 - loss: 0.4127 - val_accuracy: 0.8117 - val_loss: 0.4108\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8119 - loss: 0.4116 - val_accuracy: 0.8310 - val_loss: 0.3836\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8131 - loss: 0.4141 - val_accuracy: 0.8274 - val_loss: 0.3825\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8113 - loss: 0.4152 - val_accuracy: 0.8317 - val_loss: 0.3809\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8154 - loss: 0.4072 - val_accuracy: 0.8265 - val_loss: 0.3813\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8138 - loss: 0.4100 - val_accuracy: 0.8298 - val_loss: 0.3825\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8133 - loss: 0.4105 - val_accuracy: 0.8217 - val_loss: 0.3964\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.3805\n",
            "Test Loss: 0.3795\n",
            "Test Accuracy: 0.8313\n",
            "Confusion Matrix:\n",
            "[[6519 1419]\n",
            " [1396 7356]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82      7938\n",
            "           1       0.84      0.84      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8313\n",
            "Precision: 0.8383\n",
            "Recall: 0.8405\n",
            "F1 Score: 0.8394\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lkrFWfl78pc"
      },
      "source": [
        "improved cnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aidOpUYF78pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea342d03-982d-4f12-a384-774209fc8610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6868 - loss: 0.5820 - val_accuracy: 0.7869 - val_loss: 0.4555\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7692 - loss: 0.4852 - val_accuracy: 0.7941 - val_loss: 0.4463\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7806 - loss: 0.4719 - val_accuracy: 0.8034 - val_loss: 0.4343\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7828 - loss: 0.4684 - val_accuracy: 0.8003 - val_loss: 0.4357\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7847 - loss: 0.4628 - val_accuracy: 0.7978 - val_loss: 0.4399\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7905 - loss: 0.4563 - val_accuracy: 0.8095 - val_loss: 0.4195\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7944 - loss: 0.4476 - val_accuracy: 0.8100 - val_loss: 0.4173\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7913 - loss: 0.4457 - val_accuracy: 0.8131 - val_loss: 0.4130\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7985 - loss: 0.4435 - val_accuracy: 0.8064 - val_loss: 0.4183\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7974 - loss: 0.4395 - val_accuracy: 0.8128 - val_loss: 0.4141\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7965 - loss: 0.4421 - val_accuracy: 0.8158 - val_loss: 0.4045\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8024 - loss: 0.4353 - val_accuracy: 0.8148 - val_loss: 0.4066\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7990 - loss: 0.4360 - val_accuracy: 0.8152 - val_loss: 0.4055\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7981 - loss: 0.4382 - val_accuracy: 0.8200 - val_loss: 0.4044\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7996 - loss: 0.4379 - val_accuracy: 0.8133 - val_loss: 0.4119\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8032 - loss: 0.4297 - val_accuracy: 0.8183 - val_loss: 0.4008\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8040 - loss: 0.4299 - val_accuracy: 0.8200 - val_loss: 0.4000\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8028 - loss: 0.4326 - val_accuracy: 0.8191 - val_loss: 0.3950\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8056 - loss: 0.4250 - val_accuracy: 0.8219 - val_loss: 0.3944\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8051 - loss: 0.4311 - val_accuracy: 0.8162 - val_loss: 0.4028\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8043 - loss: 0.4256 - val_accuracy: 0.8206 - val_loss: 0.3944\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8070 - loss: 0.4262 - val_accuracy: 0.8222 - val_loss: 0.3967\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8037 - loss: 0.4259 - val_accuracy: 0.8185 - val_loss: 0.4033\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8092 - loss: 0.4192 - val_accuracy: 0.8114 - val_loss: 0.4165\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8063 - loss: 0.4264 - val_accuracy: 0.8210 - val_loss: 0.3922\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8076 - loss: 0.4239 - val_accuracy: 0.8206 - val_loss: 0.4005\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8100 - loss: 0.4173 - val_accuracy: 0.8232 - val_loss: 0.3931\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8112 - loss: 0.4166 - val_accuracy: 0.8252 - val_loss: 0.3882\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8106 - loss: 0.4183 - val_accuracy: 0.8143 - val_loss: 0.4143\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8079 - loss: 0.4193 - val_accuracy: 0.8241 - val_loss: 0.3874\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8098 - loss: 0.4159 - val_accuracy: 0.8253 - val_loss: 0.3830\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8119 - loss: 0.4182 - val_accuracy: 0.8271 - val_loss: 0.3858\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8097 - loss: 0.4163 - val_accuracy: 0.8220 - val_loss: 0.3912\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8084 - loss: 0.4173 - val_accuracy: 0.8244 - val_loss: 0.3897\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8108 - loss: 0.4154 - val_accuracy: 0.8282 - val_loss: 0.3836\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8100 - loss: 0.4185 - val_accuracy: 0.8295 - val_loss: 0.3839\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8121 - loss: 0.4140 - val_accuracy: 0.8312 - val_loss: 0.3816\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8100 - loss: 0.4179 - val_accuracy: 0.8258 - val_loss: 0.3846\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8129 - loss: 0.4149 - val_accuracy: 0.8264 - val_loss: 0.3846\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8085 - loss: 0.4156 - val_accuracy: 0.8306 - val_loss: 0.3856\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8102 - loss: 0.4153 - val_accuracy: 0.8271 - val_loss: 0.3820\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8123 - loss: 0.4127 - val_accuracy: 0.8211 - val_loss: 0.3952\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8118 - loss: 0.4133 - val_accuracy: 0.8272 - val_loss: 0.3837\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8132 - loss: 0.4117 - val_accuracy: 0.8269 - val_loss: 0.3854\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8126 - loss: 0.4124 - val_accuracy: 0.8278 - val_loss: 0.3810\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8110 - loss: 0.4126 - val_accuracy: 0.8324 - val_loss: 0.3779\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8140 - loss: 0.4113 - val_accuracy: 0.8244 - val_loss: 0.3886\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8119 - loss: 0.4144 - val_accuracy: 0.8311 - val_loss: 0.3775\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8166 - loss: 0.4053 - val_accuracy: 0.8271 - val_loss: 0.3823\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8137 - loss: 0.4135 - val_accuracy: 0.8289 - val_loss: 0.3808\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8311 - loss: 0.3794\n",
            "Test Loss: 0.3785\n",
            "Test Accuracy: 0.8304\n",
            "Confusion Matrix:\n",
            "[[6365 1573]\n",
            " [1257 7495]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.80      0.82      7938\n",
            "           1       0.83      0.86      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8304\n",
            "Precision: 0.8265\n",
            "Recall: 0.8564\n",
            "F1 Score: 0.8412\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, GRU, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(GRU(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCAaRgya78pd"
      },
      "source": [
        "improved DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTVXepei78pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4444383-05b1-4a79-f5fd-cb403acfaf47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.6807 - loss: 0.6250 - val_accuracy: 0.7881 - val_loss: 0.4472\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.4770 - val_accuracy: 0.8070 - val_loss: 0.4199\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7914 - loss: 0.4513 - val_accuracy: 0.8161 - val_loss: 0.4112\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.4409 - val_accuracy: 0.8213 - val_loss: 0.4070\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8036 - loss: 0.4314 - val_accuracy: 0.8205 - val_loss: 0.4012\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.4272 - val_accuracy: 0.8229 - val_loss: 0.3979\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.4198 - val_accuracy: 0.8250 - val_loss: 0.3926\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.4134 - val_accuracy: 0.8284 - val_loss: 0.3878\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.4101 - val_accuracy: 0.8266 - val_loss: 0.3901\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8105 - loss: 0.4145 - val_accuracy: 0.8349 - val_loss: 0.3797\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.4015 - val_accuracy: 0.8335 - val_loss: 0.3791\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.4088 - val_accuracy: 0.8311 - val_loss: 0.3765\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8168 - loss: 0.4037 - val_accuracy: 0.8370 - val_loss: 0.3709\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.3996 - val_accuracy: 0.8345 - val_loss: 0.3736\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.3968 - val_accuracy: 0.8310 - val_loss: 0.3759\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8221 - loss: 0.3952 - val_accuracy: 0.8294 - val_loss: 0.3923\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.3942 - val_accuracy: 0.8334 - val_loss: 0.3733\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.3960 - val_accuracy: 0.8339 - val_loss: 0.3700\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.3915 - val_accuracy: 0.8353 - val_loss: 0.3669\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8269 - loss: 0.3822 - val_accuracy: 0.8369 - val_loss: 0.3747\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8216 - loss: 0.3954 - val_accuracy: 0.8430 - val_loss: 0.3614\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.3900 - val_accuracy: 0.8430 - val_loss: 0.3631\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.3894 - val_accuracy: 0.8416 - val_loss: 0.3559\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8282 - loss: 0.3851 - val_accuracy: 0.8339 - val_loss: 0.3625\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8237 - loss: 0.3866 - val_accuracy: 0.8421 - val_loss: 0.3569\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.3861 - val_accuracy: 0.8438 - val_loss: 0.3557\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.3818 - val_accuracy: 0.8417 - val_loss: 0.3596\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.3837 - val_accuracy: 0.8436 - val_loss: 0.3557\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8283 - loss: 0.3811 - val_accuracy: 0.8390 - val_loss: 0.3675\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.3775 - val_accuracy: 0.8455 - val_loss: 0.3512\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.3773 - val_accuracy: 0.8411 - val_loss: 0.3626\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8282 - loss: 0.3827 - val_accuracy: 0.8495 - val_loss: 0.3522\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.3817 - val_accuracy: 0.8405 - val_loss: 0.3651\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8291 - loss: 0.3788 - val_accuracy: 0.8442 - val_loss: 0.3530\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.3795 - val_accuracy: 0.8477 - val_loss: 0.3468\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.3764 - val_accuracy: 0.8429 - val_loss: 0.3797\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.3772 - val_accuracy: 0.8432 - val_loss: 0.3649\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.3756 - val_accuracy: 0.8500 - val_loss: 0.3417\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8345 - loss: 0.3742 - val_accuracy: 0.8462 - val_loss: 0.3516\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8352 - loss: 0.3729 - val_accuracy: 0.8474 - val_loss: 0.3466\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8316 - loss: 0.3738 - val_accuracy: 0.8447 - val_loss: 0.3490\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.3786 - val_accuracy: 0.8468 - val_loss: 0.3473\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.3759 - val_accuracy: 0.8465 - val_loss: 0.3509\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3714 - val_accuracy: 0.8501 - val_loss: 0.3443\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.3742 - val_accuracy: 0.8451 - val_loss: 0.3513\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.3759 - val_accuracy: 0.8489 - val_loss: 0.3446\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3744 - val_accuracy: 0.8484 - val_loss: 0.3468\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.3704 - val_accuracy: 0.8522 - val_loss: 0.3448\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8504 - loss: 0.3451\n",
            "Test Loss: 0.3442\n",
            "Test Accuracy: 0.8521\n",
            "Confusion Matrix:\n",
            "[[6774 1164]\n",
            " [1305 7447]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85      7938\n",
            "           1       0.86      0.85      0.86      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8521\n",
            "Precision: 0.8648\n",
            "Recall: 0.8509\n",
            "F1 Score: 0.8578\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the DNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input and hidden layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LhqZmap78pd"
      },
      "source": [
        "improved dnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKM_s82J78pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11604bf0-5c8b-44ad-b095-757bc31a1055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 17ms/step - accuracy: 0.6049 - loss: 0.6853 - val_accuracy: 0.7386 - val_loss: 0.5327\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.7265 - loss: 0.5598 - val_accuracy: 0.6956 - val_loss: 0.5498\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.7527 - loss: 0.5235 - val_accuracy: 0.7800 - val_loss: 0.4679\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7689 - loss: 0.5001 - val_accuracy: 0.7854 - val_loss: 0.4560\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.7784 - loss: 0.4816 - val_accuracy: 0.7594 - val_loss: 0.4890\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7831 - loss: 0.4693 - val_accuracy: 0.7985 - val_loss: 0.4357\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.7873 - loss: 0.4657 - val_accuracy: 0.8001 - val_loss: 0.4423\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7892 - loss: 0.4547 - val_accuracy: 0.8065 - val_loss: 0.4218\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7956 - loss: 0.4514 - val_accuracy: 0.8041 - val_loss: 0.4366\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8023 - loss: 0.4437 - val_accuracy: 0.8054 - val_loss: 0.4263\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 16ms/step - accuracy: 0.8027 - loss: 0.4396 - val_accuracy: 0.8088 - val_loss: 0.4275\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8031 - loss: 0.4411 - val_accuracy: 0.8122 - val_loss: 0.4097\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8044 - loss: 0.4355 - val_accuracy: 0.8111 - val_loss: 0.4184\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8119 - loss: 0.4273 - val_accuracy: 0.8194 - val_loss: 0.4119\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8066 - loss: 0.4330 - val_accuracy: 0.8190 - val_loss: 0.4075\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8092 - loss: 0.4259 - val_accuracy: 0.7943 - val_loss: 0.4392\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8097 - loss: 0.4288 - val_accuracy: 0.8096 - val_loss: 0.4168\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8082 - loss: 0.4224 - val_accuracy: 0.8226 - val_loss: 0.4005\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8122 - loss: 0.4249 - val_accuracy: 0.8083 - val_loss: 0.4194\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8126 - loss: 0.4223 - val_accuracy: 0.8232 - val_loss: 0.3972\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8142 - loss: 0.4181 - val_accuracy: 0.8188 - val_loss: 0.4012\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8113 - loss: 0.4239 - val_accuracy: 0.8160 - val_loss: 0.4045\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8157 - loss: 0.4150 - val_accuracy: 0.8276 - val_loss: 0.3910\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8185 - loss: 0.4137 - val_accuracy: 0.8196 - val_loss: 0.3967\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8222 - loss: 0.4116 - val_accuracy: 0.8194 - val_loss: 0.4005\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.8171 - loss: 0.4119 - val_accuracy: 0.8232 - val_loss: 0.3910\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 16ms/step - accuracy: 0.8200 - loss: 0.4106 - val_accuracy: 0.8265 - val_loss: 0.3901\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8161 - loss: 0.4150 - val_accuracy: 0.8298 - val_loss: 0.3869\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8219 - loss: 0.4057 - val_accuracy: 0.8289 - val_loss: 0.3866\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8185 - loss: 0.4080 - val_accuracy: 0.8252 - val_loss: 0.3851\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8214 - loss: 0.4032 - val_accuracy: 0.8238 - val_loss: 0.3874\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8209 - loss: 0.4048 - val_accuracy: 0.8246 - val_loss: 0.3890\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8225 - loss: 0.4039 - val_accuracy: 0.8310 - val_loss: 0.3837\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8233 - loss: 0.4042 - val_accuracy: 0.8226 - val_loss: 0.3874\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8245 - loss: 0.3993 - val_accuracy: 0.8260 - val_loss: 0.3842\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8198 - loss: 0.4031 - val_accuracy: 0.8158 - val_loss: 0.4015\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8219 - loss: 0.4018 - val_accuracy: 0.8307 - val_loss: 0.3801\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8263 - loss: 0.3959 - val_accuracy: 0.8298 - val_loss: 0.3838\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8256 - loss: 0.4001 - val_accuracy: 0.8251 - val_loss: 0.3864\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8231 - loss: 0.3995 - val_accuracy: 0.8265 - val_loss: 0.3875\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8272 - loss: 0.3932 - val_accuracy: 0.8307 - val_loss: 0.3802\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8236 - loss: 0.3929 - val_accuracy: 0.8334 - val_loss: 0.3782\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8294 - loss: 0.3915 - val_accuracy: 0.8220 - val_loss: 0.3871\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8259 - loss: 0.3941 - val_accuracy: 0.8303 - val_loss: 0.3792\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8280 - loss: 0.3910 - val_accuracy: 0.8292 - val_loss: 0.3814\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8287 - loss: 0.3929 - val_accuracy: 0.8308 - val_loss: 0.3741\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8253 - loss: 0.3926 - val_accuracy: 0.8331 - val_loss: 0.3716\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8306 - loss: 0.3870 - val_accuracy: 0.8334 - val_loss: 0.3725\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8281 - loss: 0.3879 - val_accuracy: 0.8308 - val_loss: 0.3770\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8264 - loss: 0.3913 - val_accuracy: 0.8346 - val_loss: 0.3715\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8345 - loss: 0.3744\n",
            "Test Loss: 0.3738\n",
            "Test Accuracy: 0.8358\n",
            "Confusion Matrix:\n",
            "[[6385 1553]\n",
            " [1187 7565]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.80      0.82      7938\n",
            "           1       0.83      0.86      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.83      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8358\n",
            "Precision: 0.8297\n",
            "Recall: 0.8644\n",
            "F1 Score: 0.8467\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUt5kq3I78pe"
      },
      "source": [
        "improved dnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_K8QeNj78pe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac24d1e-ca24-49b8-85e8-e43d93754b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25ms/step - accuracy: 0.5482 - loss: 0.7828 - val_accuracy: 0.7184 - val_loss: 0.5487\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.7100 - loss: 0.5684 - val_accuracy: 0.7758 - val_loss: 0.4755\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.7567 - loss: 0.5100 - val_accuracy: 0.7879 - val_loss: 0.4577\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.7735 - loss: 0.4847 - val_accuracy: 0.7974 - val_loss: 0.4404\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.7798 - loss: 0.4718 - val_accuracy: 0.8024 - val_loss: 0.4304\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.7819 - loss: 0.4639 - val_accuracy: 0.8044 - val_loss: 0.4230\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.7919 - loss: 0.4514 - val_accuracy: 0.8117 - val_loss: 0.4131\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.7930 - loss: 0.4494 - val_accuracy: 0.8041 - val_loss: 0.4171\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.7954 - loss: 0.4447 - val_accuracy: 0.8158 - val_loss: 0.4038\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8009 - loss: 0.4345 - val_accuracy: 0.8164 - val_loss: 0.4023\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.8025 - loss: 0.4352 - val_accuracy: 0.8149 - val_loss: 0.4077\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.7980 - loss: 0.4353 - val_accuracy: 0.8213 - val_loss: 0.3930\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 26ms/step - accuracy: 0.8045 - loss: 0.4258 - val_accuracy: 0.8208 - val_loss: 0.3958\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8068 - loss: 0.4223 - val_accuracy: 0.8220 - val_loss: 0.3883\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8087 - loss: 0.4213 - val_accuracy: 0.8256 - val_loss: 0.3869\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8087 - loss: 0.4173 - val_accuracy: 0.8263 - val_loss: 0.3863\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8118 - loss: 0.4135 - val_accuracy: 0.8284 - val_loss: 0.3821\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8146 - loss: 0.4129 - val_accuracy: 0.8298 - val_loss: 0.3784\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.8109 - loss: 0.4122 - val_accuracy: 0.8272 - val_loss: 0.3863\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8156 - loss: 0.4087 - val_accuracy: 0.8197 - val_loss: 0.3941\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.8179 - loss: 0.4030 - val_accuracy: 0.8331 - val_loss: 0.3762\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8178 - loss: 0.4036 - val_accuracy: 0.8237 - val_loss: 0.3963\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8201 - loss: 0.4026 - val_accuracy: 0.8346 - val_loss: 0.3711\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8234 - loss: 0.3971 - val_accuracy: 0.8358 - val_loss: 0.3695\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8224 - loss: 0.3988 - val_accuracy: 0.8346 - val_loss: 0.3714\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8230 - loss: 0.3970 - val_accuracy: 0.8319 - val_loss: 0.3746\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.8253 - loss: 0.3932 - val_accuracy: 0.8338 - val_loss: 0.3733\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 25ms/step - accuracy: 0.8230 - loss: 0.3927 - val_accuracy: 0.8370 - val_loss: 0.3667\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8256 - loss: 0.3894 - val_accuracy: 0.8367 - val_loss: 0.3637\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8255 - loss: 0.3899 - val_accuracy: 0.8356 - val_loss: 0.3706\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8260 - loss: 0.3936 - val_accuracy: 0.8244 - val_loss: 0.3885\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8230 - loss: 0.3920 - val_accuracy: 0.8403 - val_loss: 0.3620\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8281 - loss: 0.3858 - val_accuracy: 0.8386 - val_loss: 0.3640\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8249 - loss: 0.3888 - val_accuracy: 0.8404 - val_loss: 0.3612\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8291 - loss: 0.3872 - val_accuracy: 0.8214 - val_loss: 0.3985\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8293 - loss: 0.3814 - val_accuracy: 0.8408 - val_loss: 0.3590\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8287 - loss: 0.3833 - val_accuracy: 0.8396 - val_loss: 0.3655\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 25ms/step - accuracy: 0.8334 - loss: 0.3768 - val_accuracy: 0.8402 - val_loss: 0.3616\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8293 - loss: 0.3833 - val_accuracy: 0.8396 - val_loss: 0.3622\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8287 - loss: 0.3823 - val_accuracy: 0.8431 - val_loss: 0.3563\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8323 - loss: 0.3763 - val_accuracy: 0.8356 - val_loss: 0.3686\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8310 - loss: 0.3816 - val_accuracy: 0.8393 - val_loss: 0.3618\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8341 - loss: 0.3746 - val_accuracy: 0.8382 - val_loss: 0.3659\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.8331 - loss: 0.3766 - val_accuracy: 0.8435 - val_loss: 0.3545\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8356 - loss: 0.3731 - val_accuracy: 0.8433 - val_loss: 0.3579\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26ms/step - accuracy: 0.8353 - loss: 0.3706 - val_accuracy: 0.8355 - val_loss: 0.3708\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8353 - loss: 0.3712 - val_accuracy: 0.8435 - val_loss: 0.3538\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8348 - loss: 0.3726 - val_accuracy: 0.8448 - val_loss: 0.3538\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8355 - loss: 0.3709 - val_accuracy: 0.8434 - val_loss: 0.3571\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.8375 - loss: 0.3690 - val_accuracy: 0.8423 - val_loss: 0.3586\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 0.3602\n",
            "Test Loss: 0.3550\n",
            "Test Accuracy: 0.8458\n",
            "Confusion Matrix:\n",
            "[[6883 1055]\n",
            " [1519 7233]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84      7938\n",
            "           1       0.87      0.83      0.85      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8458\n",
            "Precision: 0.8727\n",
            "Recall: 0.8264\n",
            "F1 Score: 0.8489\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Reshape output from Dense layers to be suitable for GRU layers\n",
        "model.add(tf.keras.layers.Reshape((X_train_reshaped.shape[1], 32)))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJr7aQm-8gGZ"
      },
      "source": [
        "12-features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmR3_nQw8gGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeceb848-2c5f-49f0-b1c2-8c769a7a7739"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Repititive-Words-in-a-Email',\n",
              " 'Neu-Sentiment',\n",
              " 'Spam lexicon',\n",
              " 'Uinque-Words-in-a-Email',\n",
              " 'Polarity',\n",
              " 'Length-of-Email',\n",
              " 'Number-of-noun',\n",
              " 'Neg-Sentiment',\n",
              " 'Subjective',\n",
              " 'Comp-Sentiment',\n",
              " 'Pos-Sentiment',\n",
              " 'Quoted-text-in-a-Email']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "features=feature_importances.nlargest(n=12, columns='Importance')['Feature'].to_list()\n",
        "features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJwqLxJF8gGa"
      },
      "source": [
        "improved rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHEM019j8gGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a27fe23-36ef-48ce-87de-ace2bb6b1457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.6939 - loss: 0.5916 - val_accuracy: 0.7908 - val_loss: 0.4469\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7830 - loss: 0.4720 - val_accuracy: 0.7931 - val_loss: 0.4380\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.7919 - loss: 0.4605 - val_accuracy: 0.7976 - val_loss: 0.4467\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8003 - loss: 0.4470 - val_accuracy: 0.8120 - val_loss: 0.4158\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8041 - loss: 0.4366 - val_accuracy: 0.7976 - val_loss: 0.4230\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8037 - loss: 0.4361 - val_accuracy: 0.8134 - val_loss: 0.4043\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8099 - loss: 0.4244 - val_accuracy: 0.8077 - val_loss: 0.4269\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8108 - loss: 0.4178 - val_accuracy: 0.7998 - val_loss: 0.4343\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8095 - loss: 0.4241 - val_accuracy: 0.8053 - val_loss: 0.4280\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8101 - loss: 0.4218 - val_accuracy: 0.8162 - val_loss: 0.4033\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8144 - loss: 0.4181 - val_accuracy: 0.8193 - val_loss: 0.3994\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8143 - loss: 0.4125 - val_accuracy: 0.8116 - val_loss: 0.4300\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8192 - loss: 0.4088 - val_accuracy: 0.8160 - val_loss: 0.4111\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8178 - loss: 0.4109 - val_accuracy: 0.8223 - val_loss: 0.3955\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8228 - loss: 0.4039 - val_accuracy: 0.8274 - val_loss: 0.3943\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8200 - loss: 0.4062 - val_accuracy: 0.8294 - val_loss: 0.3958\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8239 - loss: 0.3959 - val_accuracy: 0.8314 - val_loss: 0.3829\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8232 - loss: 0.3983 - val_accuracy: 0.8263 - val_loss: 0.3909\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8242 - loss: 0.3973 - val_accuracy: 0.8265 - val_loss: 0.3838\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8230 - loss: 0.3956 - val_accuracy: 0.8262 - val_loss: 0.3867\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8252 - loss: 0.3937 - val_accuracy: 0.8197 - val_loss: 0.4085\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8269 - loss: 0.3899 - val_accuracy: 0.8290 - val_loss: 0.3857\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8279 - loss: 0.3890 - val_accuracy: 0.8341 - val_loss: 0.3833\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8269 - loss: 0.3908 - val_accuracy: 0.8312 - val_loss: 0.3833\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8302 - loss: 0.3834 - val_accuracy: 0.8341 - val_loss: 0.3754\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8319 - loss: 0.3840 - val_accuracy: 0.8229 - val_loss: 0.3936\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8281 - loss: 0.3870 - val_accuracy: 0.8213 - val_loss: 0.3855\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 12ms/step - accuracy: 0.8289 - loss: 0.3887 - val_accuracy: 0.8339 - val_loss: 0.3761\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8323 - loss: 0.3799 - val_accuracy: 0.8306 - val_loss: 0.3763\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8316 - loss: 0.3794 - val_accuracy: 0.8249 - val_loss: 0.3887\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8319 - loss: 0.3807 - val_accuracy: 0.8361 - val_loss: 0.3703\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 12ms/step - accuracy: 0.8306 - loss: 0.3837 - val_accuracy: 0.8340 - val_loss: 0.3803\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8349 - loss: 0.3743 - val_accuracy: 0.8400 - val_loss: 0.3670\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8354 - loss: 0.3771 - val_accuracy: 0.8304 - val_loss: 0.3757\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8386 - loss: 0.3743 - val_accuracy: 0.8198 - val_loss: 0.4060\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8384 - loss: 0.3686 - val_accuracy: 0.8286 - val_loss: 0.3877\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.8377 - loss: 0.3687 - val_accuracy: 0.8359 - val_loss: 0.3734\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8377 - loss: 0.3688 - val_accuracy: 0.8373 - val_loss: 0.3672\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8366 - loss: 0.3737 - val_accuracy: 0.8417 - val_loss: 0.3625\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8428 - loss: 0.3618 - val_accuracy: 0.8347 - val_loss: 0.3683\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8417 - loss: 0.3647 - val_accuracy: 0.8385 - val_loss: 0.3677\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8422 - loss: 0.3623 - val_accuracy: 0.8346 - val_loss: 0.3682\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8410 - loss: 0.3648 - val_accuracy: 0.8399 - val_loss: 0.3659\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8411 - loss: 0.3653 - val_accuracy: 0.8417 - val_loss: 0.3593\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8413 - loss: 0.3607 - val_accuracy: 0.8388 - val_loss: 0.3643\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8442 - loss: 0.3606 - val_accuracy: 0.8336 - val_loss: 0.3700\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8422 - loss: 0.3618 - val_accuracy: 0.8406 - val_loss: 0.3647\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8460 - loss: 0.3555 - val_accuracy: 0.8372 - val_loss: 0.3633\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8432 - loss: 0.3584 - val_accuracy: 0.8414 - val_loss: 0.3605\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8431 - loss: 0.3609 - val_accuracy: 0.8389 - val_loss: 0.3703\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3619\n",
            "Test Loss: 0.3594\n",
            "Test Accuracy: 0.8412\n",
            "Confusion Matrix:\n",
            "[[6641 1297]\n",
            " [1354 7398]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.83      7938\n",
            "           1       0.85      0.85      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8412\n",
            "Precision: 0.8508\n",
            "Recall: 0.8453\n",
            "F1 Score: 0.8481\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# RNN layers\n",
        "model.add(SimpleRNN(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(SimpleRNN(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0vpfSAG8gGa"
      },
      "source": [
        "improved rnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8apIwcQi8gGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd3cc6d-f80a-4f68-ce51-ff74d3d5fc4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.6244 - loss: 0.6696 - val_accuracy: 0.5646 - val_loss: 0.7045\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 22ms/step - accuracy: 0.7267 - loss: 0.5513 - val_accuracy: 0.7646 - val_loss: 0.4974\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 17ms/step - accuracy: 0.7531 - loss: 0.5143 - val_accuracy: 0.7176 - val_loss: 0.5472\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7712 - loss: 0.4841 - val_accuracy: 0.7951 - val_loss: 0.4486\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7794 - loss: 0.4749 - val_accuracy: 0.6849 - val_loss: 0.6030\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7836 - loss: 0.4661 - val_accuracy: 0.7997 - val_loss: 0.4333\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.7889 - loss: 0.4587 - val_accuracy: 0.7728 - val_loss: 0.4846\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7960 - loss: 0.4466 - val_accuracy: 0.8031 - val_loss: 0.4356\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.7998 - loss: 0.4435 - val_accuracy: 0.7963 - val_loss: 0.4442\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7990 - loss: 0.4418 - val_accuracy: 0.8076 - val_loss: 0.4383\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.7987 - loss: 0.4422 - val_accuracy: 0.8156 - val_loss: 0.4114\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8030 - loss: 0.4306 - val_accuracy: 0.7857 - val_loss: 0.4580\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8022 - loss: 0.4339 - val_accuracy: 0.8147 - val_loss: 0.4174\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8064 - loss: 0.4312 - val_accuracy: 0.8205 - val_loss: 0.4106\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8108 - loss: 0.4228 - val_accuracy: 0.8074 - val_loss: 0.4193\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8036 - loss: 0.4292 - val_accuracy: 0.8203 - val_loss: 0.4037\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8081 - loss: 0.4224 - val_accuracy: 0.8091 - val_loss: 0.4229\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8130 - loss: 0.4209 - val_accuracy: 0.8245 - val_loss: 0.4046\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8117 - loss: 0.4183 - val_accuracy: 0.8226 - val_loss: 0.4018\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8107 - loss: 0.4158 - val_accuracy: 0.8119 - val_loss: 0.4145\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8114 - loss: 0.4203 - val_accuracy: 0.8186 - val_loss: 0.4106\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8183 - loss: 0.4125 - val_accuracy: 0.8117 - val_loss: 0.4140\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8158 - loss: 0.4126 - val_accuracy: 0.8163 - val_loss: 0.4005\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8169 - loss: 0.4131 - val_accuracy: 0.8214 - val_loss: 0.4008\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8157 - loss: 0.4075 - val_accuracy: 0.8230 - val_loss: 0.3964\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8211 - loss: 0.4066 - val_accuracy: 0.8043 - val_loss: 0.4154\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8178 - loss: 0.4104 - val_accuracy: 0.8242 - val_loss: 0.3991\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8210 - loss: 0.4049 - val_accuracy: 0.8291 - val_loss: 0.3917\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8191 - loss: 0.4058 - val_accuracy: 0.8219 - val_loss: 0.3963\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8187 - loss: 0.4012 - val_accuracy: 0.8235 - val_loss: 0.3884\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8223 - loss: 0.4011 - val_accuracy: 0.8145 - val_loss: 0.4077\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8203 - loss: 0.4042 - val_accuracy: 0.8287 - val_loss: 0.3870\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8248 - loss: 0.3980 - val_accuracy: 0.8213 - val_loss: 0.3982\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8212 - loss: 0.4004 - val_accuracy: 0.8264 - val_loss: 0.3848\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8274 - loss: 0.3943 - val_accuracy: 0.8273 - val_loss: 0.3838\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8258 - loss: 0.3952 - val_accuracy: 0.8283 - val_loss: 0.3864\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8241 - loss: 0.3953 - val_accuracy: 0.8304 - val_loss: 0.3835\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8250 - loss: 0.3935 - val_accuracy: 0.8281 - val_loss: 0.3840\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8246 - loss: 0.3910 - val_accuracy: 0.8264 - val_loss: 0.3833\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8242 - loss: 0.3967 - val_accuracy: 0.8286 - val_loss: 0.3872\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8270 - loss: 0.3909 - val_accuracy: 0.8257 - val_loss: 0.3865\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8228 - loss: 0.3952 - val_accuracy: 0.8262 - val_loss: 0.3987\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8263 - loss: 0.3912 - val_accuracy: 0.8238 - val_loss: 0.3917\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8304 - loss: 0.3861 - val_accuracy: 0.8283 - val_loss: 0.3780\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8266 - loss: 0.3884 - val_accuracy: 0.8330 - val_loss: 0.3772\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8280 - loss: 0.3843 - val_accuracy: 0.8318 - val_loss: 0.3744\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8280 - loss: 0.3874 - val_accuracy: 0.8313 - val_loss: 0.3739\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8280 - loss: 0.3870 - val_accuracy: 0.8302 - val_loss: 0.3745\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8290 - loss: 0.3864 - val_accuracy: 0.8272 - val_loss: 0.3870\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8246 - loss: 0.3883 - val_accuracy: 0.8256 - val_loss: 0.3904\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8359 - loss: 0.3785\n",
            "Test Loss: 0.3768\n",
            "Test Accuracy: 0.8367\n",
            "Confusion Matrix:\n",
            "[[6385 1553]\n",
            " [1173 7579]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.80      0.82      7938\n",
            "           1       0.83      0.87      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8367\n",
            "Precision: 0.8299\n",
            "Recall: 0.8660\n",
            "F1 Score: 0.8476\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO3dO8OD8gGb"
      },
      "source": [
        "improved rnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyMlgvF28gGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62022c7-1903-449d-b3ee-d0c479914ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.5871 - loss: 0.6952 - val_accuracy: 0.7003 - val_loss: 0.5682\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - accuracy: 0.7339 - loss: 0.5458 - val_accuracy: 0.7161 - val_loss: 0.5473\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 20ms/step - accuracy: 0.7712 - loss: 0.4899 - val_accuracy: 0.7951 - val_loss: 0.4472\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 19ms/step - accuracy: 0.7843 - loss: 0.4678 - val_accuracy: 0.7315 - val_loss: 0.5449\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.7846 - loss: 0.4630 - val_accuracy: 0.7816 - val_loss: 0.4701\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - accuracy: 0.7905 - loss: 0.4540 - val_accuracy: 0.7959 - val_loss: 0.4409\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.7938 - loss: 0.4529 - val_accuracy: 0.7737 - val_loss: 0.4753\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.7965 - loss: 0.4453 - val_accuracy: 0.7798 - val_loss: 0.4589\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - accuracy: 0.7977 - loss: 0.4382 - val_accuracy: 0.8087 - val_loss: 0.4248\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 20ms/step - accuracy: 0.8034 - loss: 0.4349 - val_accuracy: 0.8101 - val_loss: 0.4242\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - accuracy: 0.8013 - loss: 0.4358 - val_accuracy: 0.8137 - val_loss: 0.4118\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8056 - loss: 0.4346 - val_accuracy: 0.8148 - val_loss: 0.4174\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8087 - loss: 0.4263 - val_accuracy: 0.8004 - val_loss: 0.4270\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - accuracy: 0.8077 - loss: 0.4245 - val_accuracy: 0.8188 - val_loss: 0.4048\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.8063 - loss: 0.4266 - val_accuracy: 0.8194 - val_loss: 0.4092\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8071 - loss: 0.4248 - val_accuracy: 0.8146 - val_loss: 0.4099\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8093 - loss: 0.4213 - val_accuracy: 0.8105 - val_loss: 0.4125\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8134 - loss: 0.4181 - val_accuracy: 0.8234 - val_loss: 0.3975\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8154 - loss: 0.4128 - val_accuracy: 0.8122 - val_loss: 0.4150\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.8127 - loss: 0.4189 - val_accuracy: 0.8207 - val_loss: 0.3971\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8168 - loss: 0.4117 - val_accuracy: 0.8228 - val_loss: 0.4097\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 22ms/step - accuracy: 0.8156 - loss: 0.4105 - val_accuracy: 0.8159 - val_loss: 0.4019\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 30ms/step - accuracy: 0.8183 - loss: 0.4072 - val_accuracy: 0.8288 - val_loss: 0.3878\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 20ms/step - accuracy: 0.8195 - loss: 0.4021 - val_accuracy: 0.8246 - val_loss: 0.3866\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - accuracy: 0.8191 - loss: 0.4045 - val_accuracy: 0.8250 - val_loss: 0.3886\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.8235 - loss: 0.3995 - val_accuracy: 0.8266 - val_loss: 0.3937\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 20ms/step - accuracy: 0.8177 - loss: 0.4023 - val_accuracy: 0.8295 - val_loss: 0.3810\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - accuracy: 0.8229 - loss: 0.3997 - val_accuracy: 0.8276 - val_loss: 0.3843\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - accuracy: 0.8195 - loss: 0.3991 - val_accuracy: 0.8225 - val_loss: 0.3854\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.8230 - loss: 0.4033 - val_accuracy: 0.8313 - val_loss: 0.3757\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.8256 - loss: 0.3938 - val_accuracy: 0.8344 - val_loss: 0.3804\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 20ms/step - accuracy: 0.8274 - loss: 0.3909 - val_accuracy: 0.8307 - val_loss: 0.3786\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8238 - loss: 0.3941 - val_accuracy: 0.8290 - val_loss: 0.3810\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8258 - loss: 0.3905 - val_accuracy: 0.8340 - val_loss: 0.3736\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8254 - loss: 0.3872 - val_accuracy: 0.8357 - val_loss: 0.3700\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8286 - loss: 0.3860 - val_accuracy: 0.8331 - val_loss: 0.3689\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8272 - loss: 0.3872 - val_accuracy: 0.8361 - val_loss: 0.3676\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.8294 - loss: 0.3883 - val_accuracy: 0.8376 - val_loss: 0.3648\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.8296 - loss: 0.3829 - val_accuracy: 0.8340 - val_loss: 0.3709\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 20ms/step - accuracy: 0.8313 - loss: 0.3821 - val_accuracy: 0.8307 - val_loss: 0.3741\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8290 - loss: 0.3837 - val_accuracy: 0.8388 - val_loss: 0.3685\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8324 - loss: 0.3785 - val_accuracy: 0.8373 - val_loss: 0.3694\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8336 - loss: 0.3756 - val_accuracy: 0.8283 - val_loss: 0.3728\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8326 - loss: 0.3767 - val_accuracy: 0.8352 - val_loss: 0.3676\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - accuracy: 0.8293 - loss: 0.3812 - val_accuracy: 0.8370 - val_loss: 0.3642\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 20ms/step - accuracy: 0.8319 - loss: 0.3762 - val_accuracy: 0.8363 - val_loss: 0.3636\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.8376 - loss: 0.3675 - val_accuracy: 0.8404 - val_loss: 0.3588\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.8332 - loss: 0.3732 - val_accuracy: 0.8277 - val_loss: 0.3717\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8358 - loss: 0.3734 - val_accuracy: 0.8418 - val_loss: 0.3626\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.8339 - loss: 0.3793 - val_accuracy: 0.8167 - val_loss: 0.3856\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8385 - loss: 0.3644\n",
            "Test Loss: 0.3614\n",
            "Test Accuracy: 0.8419\n",
            "Confusion Matrix:\n",
            "[[6765 1173]\n",
            " [1465 7287]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.85      0.84      7938\n",
            "           1       0.86      0.83      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8419\n",
            "Precision: 0.8613\n",
            "Recall: 0.8326\n",
            "F1 Score: 0.8467\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6O91lGV8gGb"
      },
      "source": [
        "improved cnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGzistwz8gGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e653a787-61e4-4eba-ab99-31ac97abc535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.6538 - loss: 0.6762 - val_accuracy: 0.7737 - val_loss: 0.4878\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7467 - loss: 0.5188 - val_accuracy: 0.7880 - val_loss: 0.4658\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7720 - loss: 0.4862 - val_accuracy: 0.7913 - val_loss: 0.4497\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7738 - loss: 0.4781 - val_accuracy: 0.8028 - val_loss: 0.4376\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7830 - loss: 0.4662 - val_accuracy: 0.8033 - val_loss: 0.4284\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7859 - loss: 0.4593 - val_accuracy: 0.8077 - val_loss: 0.4250\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 0.4545 - val_accuracy: 0.8074 - val_loss: 0.4180\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7933 - loss: 0.4524 - val_accuracy: 0.8129 - val_loss: 0.4148\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7965 - loss: 0.4479 - val_accuracy: 0.8107 - val_loss: 0.4131\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.7969 - loss: 0.4446 - val_accuracy: 0.8071 - val_loss: 0.4212\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7989 - loss: 0.4420 - val_accuracy: 0.8125 - val_loss: 0.4121\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.4423 - val_accuracy: 0.8051 - val_loss: 0.4176\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7976 - loss: 0.4407 - val_accuracy: 0.8167 - val_loss: 0.4014\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7982 - loss: 0.4361 - val_accuracy: 0.8083 - val_loss: 0.4140\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8013 - loss: 0.4322 - val_accuracy: 0.8128 - val_loss: 0.4107\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8038 - loss: 0.4298 - val_accuracy: 0.8132 - val_loss: 0.4020\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7996 - loss: 0.4362 - val_accuracy: 0.8176 - val_loss: 0.3988\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.4292 - val_accuracy: 0.8162 - val_loss: 0.4028\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8017 - loss: 0.4324 - val_accuracy: 0.8197 - val_loss: 0.3975\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8049 - loss: 0.4284 - val_accuracy: 0.8195 - val_loss: 0.3987\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8066 - loss: 0.4270 - val_accuracy: 0.8214 - val_loss: 0.3988\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8037 - loss: 0.4293 - val_accuracy: 0.8167 - val_loss: 0.4025\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8073 - loss: 0.4284 - val_accuracy: 0.8174 - val_loss: 0.3951\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4258 - val_accuracy: 0.8152 - val_loss: 0.3990\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8070 - loss: 0.4252 - val_accuracy: 0.8225 - val_loss: 0.3916\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.4217 - val_accuracy: 0.8203 - val_loss: 0.3961\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.4239 - val_accuracy: 0.8188 - val_loss: 0.3979\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.4246 - val_accuracy: 0.8220 - val_loss: 0.3948\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8068 - loss: 0.4226 - val_accuracy: 0.8217 - val_loss: 0.3917\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4221 - val_accuracy: 0.8203 - val_loss: 0.3929\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4215 - val_accuracy: 0.8241 - val_loss: 0.3910\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8092 - loss: 0.4213 - val_accuracy: 0.8197 - val_loss: 0.3910\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8105 - loss: 0.4187 - val_accuracy: 0.8220 - val_loss: 0.3891\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.4198 - val_accuracy: 0.8223 - val_loss: 0.3951\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.4202 - val_accuracy: 0.8148 - val_loss: 0.4019\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8074 - loss: 0.4229 - val_accuracy: 0.8186 - val_loss: 0.3991\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8050 - loss: 0.4255 - val_accuracy: 0.8235 - val_loss: 0.3873\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8072 - loss: 0.4195 - val_accuracy: 0.8193 - val_loss: 0.3898\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8103 - loss: 0.4175 - val_accuracy: 0.8188 - val_loss: 0.3919\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.4209 - val_accuracy: 0.8226 - val_loss: 0.3889\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8080 - loss: 0.4180 - val_accuracy: 0.8214 - val_loss: 0.3913\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.4181 - val_accuracy: 0.8205 - val_loss: 0.3937\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4166 - val_accuracy: 0.8194 - val_loss: 0.3936\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4180 - val_accuracy: 0.8219 - val_loss: 0.3869\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8090 - loss: 0.4188 - val_accuracy: 0.8213 - val_loss: 0.3880\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8081 - loss: 0.4173 - val_accuracy: 0.8226 - val_loss: 0.3874\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8090 - loss: 0.4170 - val_accuracy: 0.8227 - val_loss: 0.3880\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.4143 - val_accuracy: 0.8174 - val_loss: 0.3976\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8134 - loss: 0.4156 - val_accuracy: 0.8222 - val_loss: 0.3945\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8101 - loss: 0.4148 - val_accuracy: 0.8185 - val_loss: 0.3960\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8284 - loss: 0.3851\n",
            "Test Loss: 0.3846\n",
            "Test Accuracy: 0.8285\n",
            "Confusion Matrix:\n",
            "[[6310 1628]\n",
            " [1235 7517]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.79      0.82      7938\n",
            "           1       0.82      0.86      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8285\n",
            "Precision: 0.8220\n",
            "Recall: 0.8589\n",
            "F1 Score: 0.8400\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the optimized CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXVeSC7S8gGc"
      },
      "source": [
        "improved cnn-lstm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psvlaBkn8gGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f58d14e-e430-4133-8929-6cc89f287542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - accuracy: 0.6877 - loss: 0.5818 - val_accuracy: 0.7880 - val_loss: 0.4565\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7732 - loss: 0.4859 - val_accuracy: 0.7958 - val_loss: 0.4447\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7838 - loss: 0.4656 - val_accuracy: 0.8003 - val_loss: 0.4310\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.7857 - loss: 0.4630 - val_accuracy: 0.8027 - val_loss: 0.4290\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7880 - loss: 0.4557 - val_accuracy: 0.8000 - val_loss: 0.4298\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7956 - loss: 0.4463 - val_accuracy: 0.8062 - val_loss: 0.4239\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7959 - loss: 0.4449 - val_accuracy: 0.8126 - val_loss: 0.4123\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8007 - loss: 0.4403 - val_accuracy: 0.8002 - val_loss: 0.4352\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7968 - loss: 0.4421 - val_accuracy: 0.8125 - val_loss: 0.4065\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7986 - loss: 0.4387 - val_accuracy: 0.8132 - val_loss: 0.4080\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8004 - loss: 0.4379 - val_accuracy: 0.8025 - val_loss: 0.4228\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8041 - loss: 0.4304 - val_accuracy: 0.8179 - val_loss: 0.4044\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8036 - loss: 0.4305 - val_accuracy: 0.8101 - val_loss: 0.4113\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8054 - loss: 0.4292 - val_accuracy: 0.8173 - val_loss: 0.4010\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8046 - loss: 0.4273 - val_accuracy: 0.8205 - val_loss: 0.3948\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8057 - loss: 0.4269 - val_accuracy: 0.8218 - val_loss: 0.3928\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8063 - loss: 0.4228 - val_accuracy: 0.8200 - val_loss: 0.3988\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8029 - loss: 0.4286 - val_accuracy: 0.8206 - val_loss: 0.3926\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8051 - loss: 0.4238 - val_accuracy: 0.8219 - val_loss: 0.3909\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8066 - loss: 0.4216 - val_accuracy: 0.8192 - val_loss: 0.3952\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8062 - loss: 0.4218 - val_accuracy: 0.8204 - val_loss: 0.3934\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8078 - loss: 0.4169 - val_accuracy: 0.8209 - val_loss: 0.3901\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8081 - loss: 0.4203 - val_accuracy: 0.8211 - val_loss: 0.3912\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8077 - loss: 0.4181 - val_accuracy: 0.8244 - val_loss: 0.3882\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8086 - loss: 0.4156 - val_accuracy: 0.8208 - val_loss: 0.3896\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8100 - loss: 0.4155 - val_accuracy: 0.8206 - val_loss: 0.3912\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8137 - loss: 0.4090 - val_accuracy: 0.8262 - val_loss: 0.3818\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8107 - loss: 0.4149 - val_accuracy: 0.8246 - val_loss: 0.3831\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8113 - loss: 0.4162 - val_accuracy: 0.8256 - val_loss: 0.3849\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8126 - loss: 0.4099 - val_accuracy: 0.8251 - val_loss: 0.3830\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8130 - loss: 0.4085 - val_accuracy: 0.8270 - val_loss: 0.3791\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8130 - loss: 0.4138 - val_accuracy: 0.8209 - val_loss: 0.3971\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8144 - loss: 0.4088 - val_accuracy: 0.8265 - val_loss: 0.3820\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8140 - loss: 0.4130 - val_accuracy: 0.8316 - val_loss: 0.3782\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8136 - loss: 0.4066 - val_accuracy: 0.8304 - val_loss: 0.3774\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8124 - loss: 0.4098 - val_accuracy: 0.8280 - val_loss: 0.3774\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8142 - loss: 0.4055 - val_accuracy: 0.8286 - val_loss: 0.3807\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8161 - loss: 0.4045 - val_accuracy: 0.8322 - val_loss: 0.3784\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8144 - loss: 0.4081 - val_accuracy: 0.8306 - val_loss: 0.3759\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8131 - loss: 0.4092 - val_accuracy: 0.8313 - val_loss: 0.3758\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8151 - loss: 0.4059 - val_accuracy: 0.8307 - val_loss: 0.3777\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8147 - loss: 0.4084 - val_accuracy: 0.8288 - val_loss: 0.3767\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8169 - loss: 0.4078 - val_accuracy: 0.8293 - val_loss: 0.3741\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8186 - loss: 0.4021 - val_accuracy: 0.8277 - val_loss: 0.3777\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8185 - loss: 0.4032 - val_accuracy: 0.8287 - val_loss: 0.3770\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8175 - loss: 0.4015 - val_accuracy: 0.8220 - val_loss: 0.3923\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8170 - loss: 0.4014 - val_accuracy: 0.8285 - val_loss: 0.3774\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8179 - loss: 0.4016 - val_accuracy: 0.8339 - val_loss: 0.3719\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8178 - loss: 0.4014 - val_accuracy: 0.8247 - val_loss: 0.3838\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8174 - loss: 0.4008 - val_accuracy: 0.8325 - val_loss: 0.3754\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8342 - loss: 0.3734\n",
            "Test Loss: 0.3721\n",
            "Test Accuracy: 0.8346\n",
            "Confusion Matrix:\n",
            "[[6493 1445]\n",
            " [1316 7436]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.82      7938\n",
            "           1       0.84      0.85      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8346\n",
            "Precision: 0.8373\n",
            "Recall: 0.8496\n",
            "F1 Score: 0.8434\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFhmTzYy8gGc"
      },
      "source": [
        "improved cnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxpcisDd8gGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac0bdc1-ce45-4706-93d2-a8c35198ab8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - accuracy: 0.6576 - loss: 0.6086 - val_accuracy: 0.7875 - val_loss: 0.4622\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7664 - loss: 0.4967 - val_accuracy: 0.7907 - val_loss: 0.4499\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7796 - loss: 0.4745 - val_accuracy: 0.8012 - val_loss: 0.4398\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7807 - loss: 0.4712 - val_accuracy: 0.7975 - val_loss: 0.4399\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7889 - loss: 0.4577 - val_accuracy: 0.8047 - val_loss: 0.4273\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7903 - loss: 0.4556 - val_accuracy: 0.8056 - val_loss: 0.4220\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7960 - loss: 0.4447 - val_accuracy: 0.8092 - val_loss: 0.4220\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.8013 - loss: 0.4384 - val_accuracy: 0.8123 - val_loss: 0.4161\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8030 - loss: 0.4383 - val_accuracy: 0.8174 - val_loss: 0.4072\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7997 - loss: 0.4380 - val_accuracy: 0.8140 - val_loss: 0.4147\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7994 - loss: 0.4371 - val_accuracy: 0.8155 - val_loss: 0.4088\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8055 - loss: 0.4300 - val_accuracy: 0.8170 - val_loss: 0.4005\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8024 - loss: 0.4346 - val_accuracy: 0.8178 - val_loss: 0.4000\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8054 - loss: 0.4291 - val_accuracy: 0.8187 - val_loss: 0.3976\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8031 - loss: 0.4255 - val_accuracy: 0.8185 - val_loss: 0.3959\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.8064 - loss: 0.4257 - val_accuracy: 0.8212 - val_loss: 0.3973\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8002 - loss: 0.4343 - val_accuracy: 0.8212 - val_loss: 0.3980\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8053 - loss: 0.4238 - val_accuracy: 0.8167 - val_loss: 0.4013\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8043 - loss: 0.4281 - val_accuracy: 0.8215 - val_loss: 0.3922\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8129 - loss: 0.4168 - val_accuracy: 0.8217 - val_loss: 0.3950\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8091 - loss: 0.4201 - val_accuracy: 0.8242 - val_loss: 0.3905\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8055 - loss: 0.4226 - val_accuracy: 0.8265 - val_loss: 0.3881\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8090 - loss: 0.4198 - val_accuracy: 0.8237 - val_loss: 0.3876\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8083 - loss: 0.4187 - val_accuracy: 0.8235 - val_loss: 0.3870\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8111 - loss: 0.4156 - val_accuracy: 0.8246 - val_loss: 0.3846\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8094 - loss: 0.4174 - val_accuracy: 0.8267 - val_loss: 0.3820\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8127 - loss: 0.4118 - val_accuracy: 0.8289 - val_loss: 0.3838\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8087 - loss: 0.4175 - val_accuracy: 0.8248 - val_loss: 0.3807\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8128 - loss: 0.4142 - val_accuracy: 0.8235 - val_loss: 0.3804\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8126 - loss: 0.4141 - val_accuracy: 0.8259 - val_loss: 0.3835\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8099 - loss: 0.4176 - val_accuracy: 0.8265 - val_loss: 0.3856\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8131 - loss: 0.4098 - val_accuracy: 0.8301 - val_loss: 0.3776\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8125 - loss: 0.4113 - val_accuracy: 0.8108 - val_loss: 0.4075\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8117 - loss: 0.4114 - val_accuracy: 0.8263 - val_loss: 0.3814\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8141 - loss: 0.4092 - val_accuracy: 0.8318 - val_loss: 0.3756\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8172 - loss: 0.4040 - val_accuracy: 0.8250 - val_loss: 0.3889\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8143 - loss: 0.4086 - val_accuracy: 0.8272 - val_loss: 0.3781\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8138 - loss: 0.4084 - val_accuracy: 0.8274 - val_loss: 0.3817\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8162 - loss: 0.4089 - val_accuracy: 0.8265 - val_loss: 0.3767\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8164 - loss: 0.4064 - val_accuracy: 0.8274 - val_loss: 0.3759\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8131 - loss: 0.4075 - val_accuracy: 0.8267 - val_loss: 0.3803\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8169 - loss: 0.4046 - val_accuracy: 0.8308 - val_loss: 0.3751\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.8158 - loss: 0.4049 - val_accuracy: 0.8269 - val_loss: 0.3766\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8185 - loss: 0.4053 - val_accuracy: 0.8314 - val_loss: 0.3746\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8170 - loss: 0.4028 - val_accuracy: 0.8235 - val_loss: 0.3917\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8145 - loss: 0.4088 - val_accuracy: 0.8305 - val_loss: 0.3731\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8160 - loss: 0.4047 - val_accuracy: 0.8308 - val_loss: 0.3719\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8156 - loss: 0.4094 - val_accuracy: 0.8294 - val_loss: 0.3729\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8160 - loss: 0.4079 - val_accuracy: 0.8299 - val_loss: 0.3753\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8156 - loss: 0.4046 - val_accuracy: 0.8244 - val_loss: 0.3825\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8304 - loss: 0.3752\n",
            "Test Loss: 0.3729\n",
            "Test Accuracy: 0.8327\n",
            "Confusion Matrix:\n",
            "[[6393 1545]\n",
            " [1248 7504]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.81      0.82      7938\n",
            "           1       0.83      0.86      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8327\n",
            "Precision: 0.8293\n",
            "Recall: 0.8574\n",
            "F1 Score: 0.8431\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, GRU, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(GRU(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNhDkhlN8gGc"
      },
      "source": [
        "improved DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBnQpWhV8gGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4a0a9a-05e1-4676-ddc8-d3efb5658b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6771 - loss: 0.6270 - val_accuracy: 0.7943 - val_loss: 0.4460\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.4782 - val_accuracy: 0.7997 - val_loss: 0.4416\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7954 - loss: 0.4497 - val_accuracy: 0.8137 - val_loss: 0.4223\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.7982 - loss: 0.4408 - val_accuracy: 0.8180 - val_loss: 0.4160\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8040 - loss: 0.4312 - val_accuracy: 0.7998 - val_loss: 0.4270\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8037 - loss: 0.4246 - val_accuracy: 0.8248 - val_loss: 0.3988\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8096 - loss: 0.4221 - val_accuracy: 0.8085 - val_loss: 0.4162\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.4206 - val_accuracy: 0.8246 - val_loss: 0.3962\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8162 - loss: 0.4091 - val_accuracy: 0.8275 - val_loss: 0.3950\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8156 - loss: 0.4096 - val_accuracy: 0.8237 - val_loss: 0.3927\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8146 - loss: 0.4111 - val_accuracy: 0.8331 - val_loss: 0.3866\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.4097 - val_accuracy: 0.8354 - val_loss: 0.3787\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8165 - loss: 0.4050 - val_accuracy: 0.8343 - val_loss: 0.3801\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.3968 - val_accuracy: 0.8262 - val_loss: 0.3803\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.3973 - val_accuracy: 0.8343 - val_loss: 0.3757\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8217 - loss: 0.3943 - val_accuracy: 0.8398 - val_loss: 0.3718\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8201 - loss: 0.3968 - val_accuracy: 0.8341 - val_loss: 0.3712\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8244 - loss: 0.3921 - val_accuracy: 0.8302 - val_loss: 0.3738\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.3887 - val_accuracy: 0.8373 - val_loss: 0.3696\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8233 - loss: 0.3916 - val_accuracy: 0.8393 - val_loss: 0.3648\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.3940 - val_accuracy: 0.8395 - val_loss: 0.3657\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.3901 - val_accuracy: 0.8399 - val_loss: 0.3638\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8265 - loss: 0.3892 - val_accuracy: 0.8379 - val_loss: 0.3684\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.3905 - val_accuracy: 0.8415 - val_loss: 0.3635\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8255 - loss: 0.3831 - val_accuracy: 0.8271 - val_loss: 0.3961\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8244 - loss: 0.3851 - val_accuracy: 0.8459 - val_loss: 0.3592\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.3888 - val_accuracy: 0.8429 - val_loss: 0.3601\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 0.3850 - val_accuracy: 0.8421 - val_loss: 0.3679\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.3839 - val_accuracy: 0.8447 - val_loss: 0.3555\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.3817 - val_accuracy: 0.8453 - val_loss: 0.3590\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8280 - loss: 0.3841 - val_accuracy: 0.8453 - val_loss: 0.3580\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8292 - loss: 0.3821 - val_accuracy: 0.8466 - val_loss: 0.3552\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8304 - loss: 0.3818 - val_accuracy: 0.8467 - val_loss: 0.3557\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.3815 - val_accuracy: 0.8468 - val_loss: 0.3564\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3790 - val_accuracy: 0.8444 - val_loss: 0.3683\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.3794 - val_accuracy: 0.8462 - val_loss: 0.3523\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8272 - loss: 0.3814 - val_accuracy: 0.8441 - val_loss: 0.3525\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.3749 - val_accuracy: 0.8399 - val_loss: 0.3719\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8320 - loss: 0.3777 - val_accuracy: 0.8470 - val_loss: 0.3505\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8330 - loss: 0.3774 - val_accuracy: 0.8469 - val_loss: 0.3570\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.3806 - val_accuracy: 0.8373 - val_loss: 0.3594\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.3727 - val_accuracy: 0.8418 - val_loss: 0.3593\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.3773 - val_accuracy: 0.8480 - val_loss: 0.3501\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.3752 - val_accuracy: 0.8479 - val_loss: 0.3464\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.3732 - val_accuracy: 0.8437 - val_loss: 0.3510\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.3780 - val_accuracy: 0.8489 - val_loss: 0.3467\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.3776 - val_accuracy: 0.8444 - val_loss: 0.3508\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.3802 - val_accuracy: 0.8462 - val_loss: 0.3594\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.3732 - val_accuracy: 0.8480 - val_loss: 0.3451\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.3724 - val_accuracy: 0.8501 - val_loss: 0.3550\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8496 - loss: 0.3476\n",
            "Test Loss: 0.3473\n",
            "Test Accuracy: 0.8491\n",
            "Confusion Matrix:\n",
            "[[6813 1125]\n",
            " [1393 7359]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84      7938\n",
            "           1       0.87      0.84      0.85      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8491\n",
            "Precision: 0.8674\n",
            "Recall: 0.8408\n",
            "F1 Score: 0.8539\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the DNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input and hidden layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OkYQDHh8gGd"
      },
      "source": [
        "improved dnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfkPZG3O8gGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06dd9665-95f1-4923-faa6-cfa9c1578446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 18ms/step - accuracy: 0.6104 - loss: 0.6683 - val_accuracy: 0.7084 - val_loss: 0.5664\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.7291 - loss: 0.5617 - val_accuracy: 0.7546 - val_loss: 0.5139\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7507 - loss: 0.5291 - val_accuracy: 0.7648 - val_loss: 0.4920\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7704 - loss: 0.4981 - val_accuracy: 0.7750 - val_loss: 0.4748\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.7740 - loss: 0.4884 - val_accuracy: 0.7749 - val_loss: 0.4881\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7830 - loss: 0.4765 - val_accuracy: 0.7988 - val_loss: 0.4455\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7903 - loss: 0.4643 - val_accuracy: 0.7742 - val_loss: 0.4887\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.7908 - loss: 0.4620 - val_accuracy: 0.8044 - val_loss: 0.4289\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.7911 - loss: 0.4572 - val_accuracy: 0.8037 - val_loss: 0.4343\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.7960 - loss: 0.4503 - val_accuracy: 0.8038 - val_loss: 0.4277\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8010 - loss: 0.4439 - val_accuracy: 0.7994 - val_loss: 0.4287\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8031 - loss: 0.4429 - val_accuracy: 0.8089 - val_loss: 0.4221\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8016 - loss: 0.4388 - val_accuracy: 0.7996 - val_loss: 0.4458\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8048 - loss: 0.4350 - val_accuracy: 0.8153 - val_loss: 0.4109\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8086 - loss: 0.4337 - val_accuracy: 0.7959 - val_loss: 0.4397\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8080 - loss: 0.4263 - val_accuracy: 0.8164 - val_loss: 0.4105\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8090 - loss: 0.4297 - val_accuracy: 0.8185 - val_loss: 0.4067\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8129 - loss: 0.4226 - val_accuracy: 0.8093 - val_loss: 0.4225\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8115 - loss: 0.4240 - val_accuracy: 0.8182 - val_loss: 0.4124\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8117 - loss: 0.4216 - val_accuracy: 0.8184 - val_loss: 0.4032\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8126 - loss: 0.4217 - val_accuracy: 0.8210 - val_loss: 0.4001\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8119 - loss: 0.4223 - val_accuracy: 0.8223 - val_loss: 0.3971\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8157 - loss: 0.4170 - val_accuracy: 0.8256 - val_loss: 0.3961\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8157 - loss: 0.4179 - val_accuracy: 0.8270 - val_loss: 0.3945\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8200 - loss: 0.4098 - val_accuracy: 0.8232 - val_loss: 0.3953\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8166 - loss: 0.4151 - val_accuracy: 0.8194 - val_loss: 0.4030\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8164 - loss: 0.4114 - val_accuracy: 0.8190 - val_loss: 0.4107\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8189 - loss: 0.4095 - val_accuracy: 0.8126 - val_loss: 0.4044\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8212 - loss: 0.4068 - val_accuracy: 0.8230 - val_loss: 0.3962\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8208 - loss: 0.4069 - val_accuracy: 0.8261 - val_loss: 0.3912\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8179 - loss: 0.4115 - val_accuracy: 0.8244 - val_loss: 0.3925\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8213 - loss: 0.4089 - val_accuracy: 0.8303 - val_loss: 0.3881\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8236 - loss: 0.4018 - val_accuracy: 0.8272 - val_loss: 0.3901\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8186 - loss: 0.4073 - val_accuracy: 0.8164 - val_loss: 0.4093\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8222 - loss: 0.4011 - val_accuracy: 0.8238 - val_loss: 0.3908\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8227 - loss: 0.4016 - val_accuracy: 0.8309 - val_loss: 0.3823\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8268 - loss: 0.4002 - val_accuracy: 0.8247 - val_loss: 0.3915\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8259 - loss: 0.4019 - val_accuracy: 0.8259 - val_loss: 0.3905\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8256 - loss: 0.4022 - val_accuracy: 0.8312 - val_loss: 0.3837\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8271 - loss: 0.3908 - val_accuracy: 0.8227 - val_loss: 0.3916\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.8250 - loss: 0.3939 - val_accuracy: 0.8193 - val_loss: 0.3975\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8261 - loss: 0.3973 - val_accuracy: 0.8274 - val_loss: 0.3913\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8297 - loss: 0.3905 - val_accuracy: 0.8260 - val_loss: 0.3862\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8287 - loss: 0.3907 - val_accuracy: 0.8325 - val_loss: 0.3758\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8298 - loss: 0.3910 - val_accuracy: 0.8297 - val_loss: 0.3861\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8294 - loss: 0.3916 - val_accuracy: 0.8322 - val_loss: 0.3782\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8315 - loss: 0.3863 - val_accuracy: 0.8322 - val_loss: 0.3761\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8287 - loss: 0.3906 - val_accuracy: 0.8298 - val_loss: 0.3838\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8287 - loss: 0.3873 - val_accuracy: 0.8306 - val_loss: 0.3772\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8273 - loss: 0.3909 - val_accuracy: 0.8356 - val_loss: 0.3721\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8356 - loss: 0.3736\n",
            "Test Loss: 0.3707\n",
            "Test Accuracy: 0.8370\n",
            "Confusion Matrix:\n",
            "[[6421 1517]\n",
            " [1204 7548]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.81      0.83      7938\n",
            "           1       0.83      0.86      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8370\n",
            "Precision: 0.8327\n",
            "Recall: 0.8624\n",
            "F1 Score: 0.8473\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR3XF0Z68gGd"
      },
      "source": [
        "improved dnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXCvxy688gGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4739173c-781d-4450-9bf5-bb34989cf6cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - accuracy: 0.5651 - loss: 0.7594 - val_accuracy: 0.6381 - val_loss: 0.6342\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.6656 - loss: 0.6137 - val_accuracy: 0.7766 - val_loss: 0.4827\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.7519 - loss: 0.5123 - val_accuracy: 0.7774 - val_loss: 0.4660\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.7687 - loss: 0.4877 - val_accuracy: 0.8020 - val_loss: 0.4357\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.7810 - loss: 0.4686 - val_accuracy: 0.8060 - val_loss: 0.4243\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.7893 - loss: 0.4552 - val_accuracy: 0.8107 - val_loss: 0.4195\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26ms/step - accuracy: 0.7910 - loss: 0.4545 - val_accuracy: 0.8100 - val_loss: 0.4159\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.7897 - loss: 0.4578 - val_accuracy: 0.8110 - val_loss: 0.4170\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.7988 - loss: 0.4409 - val_accuracy: 0.8161 - val_loss: 0.4029\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.7993 - loss: 0.4368 - val_accuracy: 0.8155 - val_loss: 0.4112\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.8027 - loss: 0.4323 - val_accuracy: 0.8212 - val_loss: 0.3996\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8035 - loss: 0.4313 - val_accuracy: 0.8226 - val_loss: 0.3942\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.8030 - loss: 0.4282 - val_accuracy: 0.8253 - val_loss: 0.3944\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8065 - loss: 0.4219 - val_accuracy: 0.8282 - val_loss: 0.3873\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25ms/step - accuracy: 0.8102 - loss: 0.4177 - val_accuracy: 0.8245 - val_loss: 0.3902\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8078 - loss: 0.4194 - val_accuracy: 0.8291 - val_loss: 0.3824\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 27ms/step - accuracy: 0.8086 - loss: 0.4196 - val_accuracy: 0.8282 - val_loss: 0.3866\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 26ms/step - accuracy: 0.8152 - loss: 0.4090 - val_accuracy: 0.8227 - val_loss: 0.3951\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8102 - loss: 0.4171 - val_accuracy: 0.8301 - val_loss: 0.3801\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8107 - loss: 0.4115 - val_accuracy: 0.8310 - val_loss: 0.3747\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.8125 - loss: 0.4107 - val_accuracy: 0.8288 - val_loss: 0.3791\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8135 - loss: 0.4078 - val_accuracy: 0.8294 - val_loss: 0.3808\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.8196 - loss: 0.4027 - val_accuracy: 0.8340 - val_loss: 0.3737\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.8193 - loss: 0.3987 - val_accuracy: 0.8349 - val_loss: 0.3705\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8174 - loss: 0.4021 - val_accuracy: 0.8352 - val_loss: 0.3727\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8191 - loss: 0.3990 - val_accuracy: 0.8303 - val_loss: 0.3764\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.8192 - loss: 0.3989 - val_accuracy: 0.8394 - val_loss: 0.3675\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8241 - loss: 0.3922 - val_accuracy: 0.8304 - val_loss: 0.3735\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8251 - loss: 0.3908 - val_accuracy: 0.8274 - val_loss: 0.3782\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8240 - loss: 0.3918 - val_accuracy: 0.8370 - val_loss: 0.3657\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8265 - loss: 0.3891 - val_accuracy: 0.8411 - val_loss: 0.3651\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8293 - loss: 0.3870 - val_accuracy: 0.8363 - val_loss: 0.3644\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8232 - loss: 0.3919 - val_accuracy: 0.8282 - val_loss: 0.3822\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 27ms/step - accuracy: 0.8252 - loss: 0.3880 - val_accuracy: 0.8377 - val_loss: 0.3622\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8274 - loss: 0.3882 - val_accuracy: 0.8398 - val_loss: 0.3619\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8241 - loss: 0.3925 - val_accuracy: 0.8409 - val_loss: 0.3635\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.8254 - loss: 0.3895 - val_accuracy: 0.8411 - val_loss: 0.3587\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8312 - loss: 0.3793 - val_accuracy: 0.8407 - val_loss: 0.3564\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8304 - loss: 0.3801 - val_accuracy: 0.8404 - val_loss: 0.3610\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - accuracy: 0.8319 - loss: 0.3796 - val_accuracy: 0.8392 - val_loss: 0.3681\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.8317 - loss: 0.3772 - val_accuracy: 0.8413 - val_loss: 0.3545\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8287 - loss: 0.3825 - val_accuracy: 0.8389 - val_loss: 0.3638\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8317 - loss: 0.3760 - val_accuracy: 0.8423 - val_loss: 0.3548\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.8315 - loss: 0.3786 - val_accuracy: 0.8393 - val_loss: 0.3624\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.8314 - loss: 0.3782 - val_accuracy: 0.8339 - val_loss: 0.3705\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8333 - loss: 0.3793 - val_accuracy: 0.8425 - val_loss: 0.3543\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8304 - loss: 0.3778 - val_accuracy: 0.8433 - val_loss: 0.3499\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8342 - loss: 0.3737 - val_accuracy: 0.8432 - val_loss: 0.3525\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8342 - loss: 0.3721 - val_accuracy: 0.8464 - val_loss: 0.3511\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.8358 - loss: 0.3683 - val_accuracy: 0.8419 - val_loss: 0.3566\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8444 - loss: 0.3560\n",
            "Test Loss: 0.3559\n",
            "Test Accuracy: 0.8432\n",
            "Confusion Matrix:\n",
            "[[6502 1436]\n",
            " [1181 7571]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.82      0.83      7938\n",
            "           1       0.84      0.87      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8432\n",
            "Precision: 0.8406\n",
            "Recall: 0.8651\n",
            "F1 Score: 0.8526\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Reshape output from Dense layers to be suitable for GRU layers\n",
        "model.add(tf.keras.layers.Reshape((X_train_reshaped.shape[1], 32)))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df= pd.read_csv('/content/finalFeatures.csv')\n",
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "KPk6qanvoDOl",
        "outputId": "ffca67ef-4849-443f-e1eb-09fa7d6bf7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Length-of-Email  Number of capitalized words  \\\n",
              "0           0         0.000246                          0.0   \n",
              "\n",
              "   Repititive-Words-in-a-Email  Uinque-Words-in-a-Email  \\\n",
              "0                          0.0                 0.003667   \n",
              "\n",
              "   Quoted-text-in-a-Email  Question-Marks-in-a-Email  \\\n",
              "0                     0.0                        0.0   \n",
              "\n",
              "   Number of co-occuring words  Number-of-noun  Spam lexicon  label  \\\n",
              "0                     0.000186        0.000234           0.0      1   \n",
              "\n",
              "   Neg-Sentiment  Neu-Sentiment  Pos-Sentiment  Comp-Sentiment  Polarity  \\\n",
              "0          0.108          0.892            0.0         -0.3182      -0.6   \n",
              "\n",
              "   Subjective  \n",
              "0         1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42c9d34a-5ec4-4ea4-9e00-d00a1e63e062\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Length-of-Email</th>\n",
              "      <th>Number of capitalized words</th>\n",
              "      <th>Repititive-Words-in-a-Email</th>\n",
              "      <th>Uinque-Words-in-a-Email</th>\n",
              "      <th>Quoted-text-in-a-Email</th>\n",
              "      <th>Question-Marks-in-a-Email</th>\n",
              "      <th>Number of co-occuring words</th>\n",
              "      <th>Number-of-noun</th>\n",
              "      <th>Spam lexicon</th>\n",
              "      <th>label</th>\n",
              "      <th>Neg-Sentiment</th>\n",
              "      <th>Neu-Sentiment</th>\n",
              "      <th>Pos-Sentiment</th>\n",
              "      <th>Comp-Sentiment</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000246</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000186</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42c9d34a-5ec4-4ea4-9e00-d00a1e63e062')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42c9d34a-5ec4-4ea4-9e00-d00a1e63e062 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42c9d34a-5ec4-4ea4-9e00-d00a1e63e062');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 83448,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24089,\n        \"min\": 0,\n        \"max\": 83447,\n        \"num_unique_values\": 83448,\n        \"samples\": [\n          67681,\n          61385,\n          41829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length-of-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0069793722241669135,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 7956,\n        \"samples\": [\n          0.0172906812047355,\n          0.007997274112082,\n          0.0002939683048718\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of capitalized words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004469001600244551,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.3333333333333333,\n          0.6666666666666666,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repititive-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022305691466995316,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 614,\n        \"samples\": [\n          0.0874766355140186,\n          0.3536448598130841,\n          0.0549532710280373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Uinque-Words-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02815831639889422,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1184,\n        \"samples\": [\n          0.0650453580389886,\n          0.2646207295888824,\n          0.187222543910442\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quoted-text-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014785310265820185,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          0.0828402366863905,\n          0.3224852071005917,\n          0.1568047337278106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question-Marks-in-a-Email\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006316381939540536,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 103,\n        \"samples\": [\n          0.0103513174404015,\n          0.3613550815558343,\n          0.1044542032622333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number of co-occuring words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007107244858234746,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2509,\n        \"samples\": [\n          0.0334663620407322,\n          0.000431444456429,\n          0.0097173058254807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number-of-noun\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004615418184700771,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1358,\n        \"samples\": [\n          0.00100625809831,\n          0.0265211038513494,\n          0.0175612714691368\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam lexicon\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013190503304589766,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 169,\n        \"samples\": [\n          0.1642156862745098,\n          0.0208333333333333,\n          0.1311274509803921\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neg-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061534251444246235,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 458,\n        \"samples\": [\n          0.344,\n          0.055\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Neu-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12437377692924996,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 731,\n        \"samples\": [\n          0.39,\n          0.791\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pos-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10917272072015846,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 674,\n        \"samples\": [\n          0.541,\n          0.217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comp-Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5516671967906014,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 5642,\n        \"samples\": [\n          0.4058,\n          0.687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1674412025145324,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 30980,\n        \"samples\": [\n          0.1641666666666666,\n          0.1810064935064934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subjective\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18782995916813944,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 34053,\n        \"samples\": [\n          0.3962745098039215,\n          0.5379629629629631\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUpIYODQGFz1"
      },
      "source": [
        "##Prinicpal Component Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r80nVUMKGIIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08a913fd-956f-49c6-9b63-3e90747c9b2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances based on PCA:\n",
            "                        Feature  Importance (PC1)  Importance (PC2)  \\\n",
            "0               Length-of-Email          0.143662         -0.003176   \n",
            "6   Number of co-occuring words          0.145311         -0.000927   \n",
            "2   Repititive-Words-in-a-Email          0.137547          0.001102   \n",
            "8                  Spam lexicon          0.126001          0.010724   \n",
            "3       Uinque-Words-in-a-Email          0.128352          0.004645   \n",
            "7                Number-of-noun          0.127575         -0.005017   \n",
            "11                Pos-Sentiment         -0.009527          0.099317   \n",
            "10                Neu-Sentiment          0.007039         -0.086974   \n",
            "12               Comp-Sentiment          0.015953          0.069741   \n",
            "13                     Polarity         -0.007686          0.069581   \n",
            "14                   Subjective          0.002174          0.048485   \n",
            "4        Quoted-text-in-a-Email          0.008410          0.002480   \n",
            "5     Question-Marks-in-a-Email          0.006821         -0.001691   \n",
            "9                 Neg-Sentiment          0.003187         -0.000652   \n",
            "1   Number of capitalized words          0.000194         -0.001051   \n",
            "\n",
            "    Total Importance  \n",
            "0           0.146837  \n",
            "6           0.146238  \n",
            "2           0.138650  \n",
            "8           0.136725  \n",
            "3           0.132997  \n",
            "7           0.132591  \n",
            "11          0.108844  \n",
            "10          0.094013  \n",
            "12          0.085694  \n",
            "13          0.077267  \n",
            "14          0.050659  \n",
            "4           0.010890  \n",
            "5           0.008512  \n",
            "9           0.003839  \n",
            "1           0.001245  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data.drop(['label','Unnamed: 0'], axis=1)  # Assuming 'label' is the target variable\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=None)  # Retain all components\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Get the explained variance ratio for each principal component\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Get the loadings (contributions of each original feature to the principal components)\n",
        "loadings = pca.components_.T\n",
        "\n",
        "# Create a DataFrame to display feature contributions to the principal components\n",
        "pca_importances = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance (PC1)': loadings[:, 0] * explained_variance_ratio[0],\n",
        "    'Importance (PC2)': loadings[:, 1] * explained_variance_ratio[1],\n",
        "    # Add more columns for additional principal components if needed\n",
        "})\n",
        "\n",
        "# Summarize importance by taking the absolute value of the loadings weighted by the explained variance\n",
        "pca_importances['Total Importance'] = pca_importances.iloc[:, 1:].abs().sum(axis=1)\n",
        "\n",
        "# Sort by total importance\n",
        "pca_importances = pca_importances.sort_values(by='Total Importance', ascending=False)\n",
        "\n",
        "# Display the feature importances\n",
        "print(\"Feature Importances based on PCA:\")\n",
        "print(pca_importances)\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Total Importance', y='Feature', data=pca_importances)\n",
        "plt.title('Feature Importances from PCA')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca_importances"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "tV_ha91cJt86",
        "outputId": "a514c519-5ba9-44a0-90d2-bb3bc4985b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Feature  Importance (PC1)  Importance (PC2)  \\\n",
              "0               Length-of-Email          0.143662         -0.003176   \n",
              "6   Number of co-occuring words          0.145311         -0.000927   \n",
              "2   Repititive-Words-in-a-Email          0.137547          0.001102   \n",
              "8                  Spam lexicon          0.126001          0.010724   \n",
              "3       Uinque-Words-in-a-Email          0.128352          0.004645   \n",
              "7                Number-of-noun          0.127575         -0.005017   \n",
              "11                Pos-Sentiment         -0.009527          0.099317   \n",
              "10                Neu-Sentiment          0.007039         -0.086974   \n",
              "12               Comp-Sentiment          0.015953          0.069741   \n",
              "13                     Polarity         -0.007686          0.069581   \n",
              "14                   Subjective          0.002174          0.048485   \n",
              "4        Quoted-text-in-a-Email          0.008410          0.002480   \n",
              "5     Question-Marks-in-a-Email          0.006821         -0.001691   \n",
              "9                 Neg-Sentiment          0.003187         -0.000652   \n",
              "1   Number of capitalized words          0.000194         -0.001051   \n",
              "\n",
              "    Total Importance  \n",
              "0           0.146837  \n",
              "6           0.146238  \n",
              "2           0.138650  \n",
              "8           0.136725  \n",
              "3           0.132997  \n",
              "7           0.132591  \n",
              "11          0.108844  \n",
              "10          0.094013  \n",
              "12          0.085694  \n",
              "13          0.077267  \n",
              "14          0.050659  \n",
              "4           0.010890  \n",
              "5           0.008512  \n",
              "9           0.003839  \n",
              "1           0.001245  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-034f818a-b418-4a66-a562-6ab89dcfda10\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Importance (PC1)</th>\n",
              "      <th>Importance (PC2)</th>\n",
              "      <th>Total Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Length-of-Email</td>\n",
              "      <td>0.143662</td>\n",
              "      <td>-0.003176</td>\n",
              "      <td>0.146837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Number of co-occuring words</td>\n",
              "      <td>0.145311</td>\n",
              "      <td>-0.000927</td>\n",
              "      <td>0.146238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Repititive-Words-in-a-Email</td>\n",
              "      <td>0.137547</td>\n",
              "      <td>0.001102</td>\n",
              "      <td>0.138650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Spam lexicon</td>\n",
              "      <td>0.126001</td>\n",
              "      <td>0.010724</td>\n",
              "      <td>0.136725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Uinque-Words-in-a-Email</td>\n",
              "      <td>0.128352</td>\n",
              "      <td>0.004645</td>\n",
              "      <td>0.132997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Number-of-noun</td>\n",
              "      <td>0.127575</td>\n",
              "      <td>-0.005017</td>\n",
              "      <td>0.132591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Pos-Sentiment</td>\n",
              "      <td>-0.009527</td>\n",
              "      <td>0.099317</td>\n",
              "      <td>0.108844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Neu-Sentiment</td>\n",
              "      <td>0.007039</td>\n",
              "      <td>-0.086974</td>\n",
              "      <td>0.094013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Comp-Sentiment</td>\n",
              "      <td>0.015953</td>\n",
              "      <td>0.069741</td>\n",
              "      <td>0.085694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Polarity</td>\n",
              "      <td>-0.007686</td>\n",
              "      <td>0.069581</td>\n",
              "      <td>0.077267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Subjective</td>\n",
              "      <td>0.002174</td>\n",
              "      <td>0.048485</td>\n",
              "      <td>0.050659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quoted-text-in-a-Email</td>\n",
              "      <td>0.008410</td>\n",
              "      <td>0.002480</td>\n",
              "      <td>0.010890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Question-Marks-in-a-Email</td>\n",
              "      <td>0.006821</td>\n",
              "      <td>-0.001691</td>\n",
              "      <td>0.008512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Neg-Sentiment</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>-0.000652</td>\n",
              "      <td>0.003839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Number of capitalized words</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>-0.001051</td>\n",
              "      <td>0.001245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-034f818a-b418-4a66-a562-6ab89dcfda10')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-034f818a-b418-4a66-a562-6ab89dcfda10 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-034f818a-b418-4a66-a562-6ab89dcfda10');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7cd3efa7-1b8f-4ad9-b46e-1908573bac93\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7cd3efa7-1b8f-4ad9-b46e-1908573bac93')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7cd3efa7-1b8f-4ad9-b46e-1908573bac93 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f1d332bf-3c95-4fd5-8423-b56fcbdafd05\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pca_importances')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f1d332bf-3c95-4fd5-8423-b56fcbdafd05 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pca_importances');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pca_importances",
              "summary": "{\n  \"name\": \"pca_importances\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Polarity\",\n          \"Quoted-text-in-a-Email\",\n          \"Length-of-Email\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Importance (PC1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0672957322841612,\n        \"min\": -0.009526577786922917,\n        \"max\": 0.1453114393863396,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.007686487854753183,\n          0.008410247136030743,\n          0.14366150547969966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Importance (PC2)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04377184933258852,\n        \"min\": -0.08697392457257218,\n        \"max\": 0.09931716431231537,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.06958060594714023,\n          0.002480100119310113,\n          -0.0031759148925207567\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.056398211984218266,\n        \"min\": 0.0012446496234894586,\n        \"max\": 0.14683742037222042,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.07726709380189341,\n          0.010890347255340856,\n          0.14683742037222042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSC-ebHd82EA"
      },
      "source": [
        "10-features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PJZ98nb82ES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e58937a-7e4d-4b04-d9bd-d4bdacb68f1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Length-of-Email',\n",
              " 'Number of co-occuring words',\n",
              " 'Repititive-Words-in-a-Email',\n",
              " 'Spam lexicon',\n",
              " 'Uinque-Words-in-a-Email',\n",
              " 'Number-of-noun',\n",
              " 'Pos-Sentiment',\n",
              " 'Neu-Sentiment',\n",
              " 'Comp-Sentiment',\n",
              " 'Polarity']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "features=pca_importances.nlargest(n=10, columns='Total Importance')['Feature'].to_list()\n",
        "features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd_VepEF82ES"
      },
      "source": [
        "improved rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L34P3VbZ82ES",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14fe6811-e4b6-4481-c90d-4ff014236ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 16ms/step - accuracy: 0.7067 - loss: 0.5811 - val_accuracy: 0.8028 - val_loss: 0.4320\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7934 - loss: 0.4593 - val_accuracy: 0.8086 - val_loss: 0.4206\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8028 - loss: 0.4378 - val_accuracy: 0.8161 - val_loss: 0.4068\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8084 - loss: 0.4293 - val_accuracy: 0.8014 - val_loss: 0.4245\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8118 - loss: 0.4206 - val_accuracy: 0.8175 - val_loss: 0.3996\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8130 - loss: 0.4178 - val_accuracy: 0.8230 - val_loss: 0.3976\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8178 - loss: 0.4085 - val_accuracy: 0.8161 - val_loss: 0.4082\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8242 - loss: 0.4032 - val_accuracy: 0.8243 - val_loss: 0.3953\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8225 - loss: 0.4072 - val_accuracy: 0.8329 - val_loss: 0.3757\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8229 - loss: 0.3983 - val_accuracy: 0.8281 - val_loss: 0.3884\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8255 - loss: 0.3928 - val_accuracy: 0.8315 - val_loss: 0.3805\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8260 - loss: 0.3935 - val_accuracy: 0.8265 - val_loss: 0.3902\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8260 - loss: 0.3982 - val_accuracy: 0.8376 - val_loss: 0.3755\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8285 - loss: 0.3936 - val_accuracy: 0.8328 - val_loss: 0.3714\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8304 - loss: 0.3905 - val_accuracy: 0.8355 - val_loss: 0.3698\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 10ms/step - accuracy: 0.8297 - loss: 0.3858 - val_accuracy: 0.8310 - val_loss: 0.3756\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8342 - loss: 0.3789 - val_accuracy: 0.8403 - val_loss: 0.3578\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8312 - loss: 0.3829 - val_accuracy: 0.8298 - val_loss: 0.3852\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8326 - loss: 0.3782 - val_accuracy: 0.8346 - val_loss: 0.3680\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8369 - loss: 0.3757 - val_accuracy: 0.8405 - val_loss: 0.3595\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8355 - loss: 0.3809 - val_accuracy: 0.8382 - val_loss: 0.3602\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8395 - loss: 0.3667 - val_accuracy: 0.8387 - val_loss: 0.3599\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8359 - loss: 0.3744 - val_accuracy: 0.8402 - val_loss: 0.3635\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8385 - loss: 0.3706 - val_accuracy: 0.8442 - val_loss: 0.3492\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8384 - loss: 0.3693 - val_accuracy: 0.8445 - val_loss: 0.3493\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8379 - loss: 0.3699 - val_accuracy: 0.8458 - val_loss: 0.3496\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8399 - loss: 0.3668 - val_accuracy: 0.8432 - val_loss: 0.3509\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8363 - loss: 0.3705 - val_accuracy: 0.8432 - val_loss: 0.3487\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8387 - loss: 0.3674 - val_accuracy: 0.8468 - val_loss: 0.3443\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8398 - loss: 0.3669 - val_accuracy: 0.8400 - val_loss: 0.3532\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8409 - loss: 0.3642 - val_accuracy: 0.8399 - val_loss: 0.3611\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8412 - loss: 0.3641 - val_accuracy: 0.8424 - val_loss: 0.3491\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8438 - loss: 0.3613 - val_accuracy: 0.8445 - val_loss: 0.3488\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8432 - loss: 0.3615 - val_accuracy: 0.8441 - val_loss: 0.3425\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8446 - loss: 0.3569 - val_accuracy: 0.8442 - val_loss: 0.3464\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8468 - loss: 0.3526 - val_accuracy: 0.8431 - val_loss: 0.3508\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8476 - loss: 0.3561 - val_accuracy: 0.8507 - val_loss: 0.3391\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8448 - loss: 0.3535 - val_accuracy: 0.8536 - val_loss: 0.3364\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8460 - loss: 0.3549 - val_accuracy: 0.8472 - val_loss: 0.3441\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8469 - loss: 0.3514 - val_accuracy: 0.8467 - val_loss: 0.3425\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8465 - loss: 0.3480 - val_accuracy: 0.8499 - val_loss: 0.3401\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8492 - loss: 0.3511 - val_accuracy: 0.8459 - val_loss: 0.3461\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8461 - loss: 0.3519 - val_accuracy: 0.8522 - val_loss: 0.3350\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8472 - loss: 0.3494 - val_accuracy: 0.8502 - val_loss: 0.3357\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8479 - loss: 0.3468 - val_accuracy: 0.8527 - val_loss: 0.3332\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8505 - loss: 0.3459 - val_accuracy: 0.8468 - val_loss: 0.3435\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8487 - loss: 0.3508 - val_accuracy: 0.8560 - val_loss: 0.3313\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8508 - loss: 0.3451 - val_accuracy: 0.8485 - val_loss: 0.3466\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8501 - loss: 0.3494 - val_accuracy: 0.8543 - val_loss: 0.3339\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - accuracy: 0.8509 - loss: 0.3442 - val_accuracy: 0.8517 - val_loss: 0.3341\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8546 - loss: 0.3298\n",
            "Test Loss: 0.3318\n",
            "Test Accuracy: 0.8541\n",
            "Confusion Matrix:\n",
            "[[6886 1052]\n",
            " [1383 7369]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      7938\n",
            "           1       0.88      0.84      0.86      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8541\n",
            "Precision: 0.8751\n",
            "Recall: 0.8420\n",
            "F1 Score: 0.8582\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# RNN layers\n",
        "model.add(SimpleRNN(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(SimpleRNN(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt3WSicM82ES"
      },
      "source": [
        "improved rnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCu_ZS5782ET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f1744b-b506-40b0-8025-2dc61d4a8c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 15ms/step - accuracy: 0.5727 - loss: 0.7063 - val_accuracy: 0.6690 - val_loss: 0.6122\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13ms/step - accuracy: 0.6675 - loss: 0.6095 - val_accuracy: 0.7469 - val_loss: 0.5097\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.7495 - loss: 0.5132 - val_accuracy: 0.7577 - val_loss: 0.4815\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.7815 - loss: 0.4703 - val_accuracy: 0.7973 - val_loss: 0.4357\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.7940 - loss: 0.4525 - val_accuracy: 0.7746 - val_loss: 0.4506\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.7977 - loss: 0.4469 - val_accuracy: 0.8011 - val_loss: 0.4297\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8032 - loss: 0.4346 - val_accuracy: 0.8107 - val_loss: 0.4119\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8022 - loss: 0.4347 - val_accuracy: 0.8128 - val_loss: 0.4088\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8078 - loss: 0.4248 - val_accuracy: 0.8098 - val_loss: 0.4112\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8041 - loss: 0.4237 - val_accuracy: 0.8140 - val_loss: 0.4044\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8118 - loss: 0.4187 - val_accuracy: 0.8106 - val_loss: 0.4021\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8088 - loss: 0.4195 - val_accuracy: 0.8173 - val_loss: 0.4008\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8091 - loss: 0.4177 - val_accuracy: 0.7981 - val_loss: 0.4165\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8116 - loss: 0.4160 - val_accuracy: 0.8161 - val_loss: 0.4112\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.4106 - val_accuracy: 0.8181 - val_loss: 0.3951\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8174 - loss: 0.4068 - val_accuracy: 0.8207 - val_loss: 0.3927\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8181 - loss: 0.4058 - val_accuracy: 0.8210 - val_loss: 0.3889\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8144 - loss: 0.4085 - val_accuracy: 0.8285 - val_loss: 0.3881\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8167 - loss: 0.4039 - val_accuracy: 0.8295 - val_loss: 0.3818\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8206 - loss: 0.3965 - val_accuracy: 0.8229 - val_loss: 0.3881\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.8205 - loss: 0.4022 - val_accuracy: 0.8265 - val_loss: 0.3796\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 14ms/step - accuracy: 0.8195 - loss: 0.4007 - val_accuracy: 0.8305 - val_loss: 0.3804\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8286 - loss: 0.3869 - val_accuracy: 0.8293 - val_loss: 0.3793\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8209 - loss: 0.3962 - val_accuracy: 0.8314 - val_loss: 0.3809\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8271 - loss: 0.3907 - val_accuracy: 0.8361 - val_loss: 0.3740\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8264 - loss: 0.3912 - val_accuracy: 0.8334 - val_loss: 0.3726\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8240 - loss: 0.3896 - val_accuracy: 0.8336 - val_loss: 0.3712\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8262 - loss: 0.3854 - val_accuracy: 0.8342 - val_loss: 0.3729\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8277 - loss: 0.3874 - val_accuracy: 0.8363 - val_loss: 0.3678\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8249 - loss: 0.3878 - val_accuracy: 0.8343 - val_loss: 0.3720\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8289 - loss: 0.3854 - val_accuracy: 0.8378 - val_loss: 0.3674\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8312 - loss: 0.3840 - val_accuracy: 0.8321 - val_loss: 0.3677\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8303 - loss: 0.3816 - val_accuracy: 0.8297 - val_loss: 0.3739\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8293 - loss: 0.3820 - val_accuracy: 0.8387 - val_loss: 0.3631\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8338 - loss: 0.3781 - val_accuracy: 0.8354 - val_loss: 0.3629\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8329 - loss: 0.3767 - val_accuracy: 0.8382 - val_loss: 0.3597\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8315 - loss: 0.3775 - val_accuracy: 0.8421 - val_loss: 0.3555\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8317 - loss: 0.3767 - val_accuracy: 0.8403 - val_loss: 0.3601\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8378 - loss: 0.3666 - val_accuracy: 0.8408 - val_loss: 0.3609\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8347 - loss: 0.3764 - val_accuracy: 0.8416 - val_loss: 0.3560\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8310 - loss: 0.3730 - val_accuracy: 0.8417 - val_loss: 0.3646\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step - accuracy: 0.8351 - loss: 0.3730 - val_accuracy: 0.8403 - val_loss: 0.3610\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8376 - loss: 0.3697 - val_accuracy: 0.8420 - val_loss: 0.3536\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8349 - loss: 0.3676 - val_accuracy: 0.8405 - val_loss: 0.3589\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8354 - loss: 0.3673 - val_accuracy: 0.8354 - val_loss: 0.3600\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8385 - loss: 0.3623 - val_accuracy: 0.8393 - val_loss: 0.3530\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8371 - loss: 0.3651 - val_accuracy: 0.8414 - val_loss: 0.3548\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8383 - loss: 0.3646 - val_accuracy: 0.8432 - val_loss: 0.3513\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - accuracy: 0.8412 - loss: 0.3608 - val_accuracy: 0.8469 - val_loss: 0.3446\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8412 - loss: 0.3648 - val_accuracy: 0.8406 - val_loss: 0.3577\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8483 - loss: 0.3414\n",
            "Test Loss: 0.3426\n",
            "Test Accuracy: 0.8487\n",
            "Confusion Matrix:\n",
            "[[6729 1209]\n",
            " [1316 7436]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84      7938\n",
            "           1       0.86      0.85      0.85      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8487\n",
            "Precision: 0.8602\n",
            "Recall: 0.8496\n",
            "F1 Score: 0.8549\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klicrAUQ82ET"
      },
      "source": [
        "improved rnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPCRAS5y82ET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6e00a4-b5fc-422e-9612-2ada551a8100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 16ms/step - accuracy: 0.5961 - loss: 0.6893 - val_accuracy: 0.6635 - val_loss: 0.6068\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.6626 - loss: 0.6138 - val_accuracy: 0.7733 - val_loss: 0.4716\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.7695 - loss: 0.4915 - val_accuracy: 0.7602 - val_loss: 0.4932\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7832 - loss: 0.4630 - val_accuracy: 0.7837 - val_loss: 0.4566\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.7929 - loss: 0.4485 - val_accuracy: 0.8050 - val_loss: 0.4216\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.7968 - loss: 0.4422 - val_accuracy: 0.8077 - val_loss: 0.4187\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8039 - loss: 0.4322 - val_accuracy: 0.7974 - val_loss: 0.4374\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.8090 - loss: 0.4223 - val_accuracy: 0.8127 - val_loss: 0.4167\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8086 - loss: 0.4209 - val_accuracy: 0.8172 - val_loss: 0.4062\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8129 - loss: 0.4170 - val_accuracy: 0.8179 - val_loss: 0.4058\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8131 - loss: 0.4150 - val_accuracy: 0.8199 - val_loss: 0.3936\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8109 - loss: 0.4148 - val_accuracy: 0.8218 - val_loss: 0.3925\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8149 - loss: 0.4068 - val_accuracy: 0.8191 - val_loss: 0.4014\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8169 - loss: 0.4070 - val_accuracy: 0.8208 - val_loss: 0.3900\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8187 - loss: 0.4052 - val_accuracy: 0.8265 - val_loss: 0.3954\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8190 - loss: 0.4014 - val_accuracy: 0.8270 - val_loss: 0.3941\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8223 - loss: 0.3969 - val_accuracy: 0.8284 - val_loss: 0.3795\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.8228 - loss: 0.3987 - val_accuracy: 0.8301 - val_loss: 0.3798\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8220 - loss: 0.3952 - val_accuracy: 0.8331 - val_loss: 0.3804\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8240 - loss: 0.3917 - val_accuracy: 0.8325 - val_loss: 0.3759\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.8258 - loss: 0.3914 - val_accuracy: 0.8298 - val_loss: 0.3810\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8283 - loss: 0.3873 - val_accuracy: 0.8298 - val_loss: 0.3895\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8248 - loss: 0.3920 - val_accuracy: 0.8306 - val_loss: 0.3748\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8283 - loss: 0.3852 - val_accuracy: 0.8283 - val_loss: 0.3891\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8265 - loss: 0.3844 - val_accuracy: 0.8316 - val_loss: 0.3766\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8292 - loss: 0.3829 - val_accuracy: 0.8325 - val_loss: 0.3813\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8313 - loss: 0.3783 - val_accuracy: 0.8314 - val_loss: 0.3731\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8358 - loss: 0.3727 - val_accuracy: 0.8324 - val_loss: 0.3691\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8325 - loss: 0.3734 - val_accuracy: 0.8349 - val_loss: 0.3700\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8353 - loss: 0.3690 - val_accuracy: 0.8374 - val_loss: 0.3632\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 16ms/step - accuracy: 0.8369 - loss: 0.3690 - val_accuracy: 0.8382 - val_loss: 0.3650\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.8345 - loss: 0.3710 - val_accuracy: 0.8419 - val_loss: 0.3627\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8379 - loss: 0.3691 - val_accuracy: 0.8412 - val_loss: 0.3566\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8387 - loss: 0.3691 - val_accuracy: 0.8429 - val_loss: 0.3532\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.8352 - loss: 0.3690 - val_accuracy: 0.8388 - val_loss: 0.3582\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8401 - loss: 0.3644 - val_accuracy: 0.8409 - val_loss: 0.3597\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8404 - loss: 0.3628 - val_accuracy: 0.8423 - val_loss: 0.3538\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8375 - loss: 0.3665 - val_accuracy: 0.8450 - val_loss: 0.3499\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8425 - loss: 0.3610 - val_accuracy: 0.8441 - val_loss: 0.3495\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8437 - loss: 0.3566 - val_accuracy: 0.8420 - val_loss: 0.3474\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8424 - loss: 0.3583 - val_accuracy: 0.8462 - val_loss: 0.3504\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8429 - loss: 0.3590 - val_accuracy: 0.8377 - val_loss: 0.3544\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8441 - loss: 0.3538 - val_accuracy: 0.8462 - val_loss: 0.3481\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.8431 - loss: 0.3564 - val_accuracy: 0.8457 - val_loss: 0.3459\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8483 - loss: 0.3482 - val_accuracy: 0.8445 - val_loss: 0.3529\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8440 - loss: 0.3557 - val_accuracy: 0.8502 - val_loss: 0.3412\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.8427 - loss: 0.3493 - val_accuracy: 0.8446 - val_loss: 0.3435\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8463 - loss: 0.3497 - val_accuracy: 0.8486 - val_loss: 0.3408\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8494 - loss: 0.3451 - val_accuracy: 0.8496 - val_loss: 0.3367\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8506 - loss: 0.3437 - val_accuracy: 0.8509 - val_loss: 0.3400\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.3368\n",
            "Test Loss: 0.3355\n",
            "Test Accuracy: 0.8541\n",
            "Confusion Matrix:\n",
            "[[6685 1253]\n",
            " [1182 7570]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.85      7938\n",
            "           1       0.86      0.86      0.86      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8541\n",
            "Precision: 0.8580\n",
            "Recall: 0.8649\n",
            "F1 Score: 0.8615\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSC1vL9A82ET"
      },
      "source": [
        "improved cnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3rv4n5K82ET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d404dbe-427a-4b1c-cd41-a2b724d1ec34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6679 - loss: 0.6470 - val_accuracy: 0.7916 - val_loss: 0.4522\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7696 - loss: 0.4884 - val_accuracy: 0.7971 - val_loss: 0.4358\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7843 - loss: 0.4621 - val_accuracy: 0.8037 - val_loss: 0.4236\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7934 - loss: 0.4502 - val_accuracy: 0.8051 - val_loss: 0.4173\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7959 - loss: 0.4472 - val_accuracy: 0.8164 - val_loss: 0.4116\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8024 - loss: 0.4337 - val_accuracy: 0.8133 - val_loss: 0.4135\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7985 - loss: 0.4364 - val_accuracy: 0.8169 - val_loss: 0.4048\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8045 - loss: 0.4313 - val_accuracy: 0.8185 - val_loss: 0.4008\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4239 - val_accuracy: 0.8101 - val_loss: 0.4066\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4237 - val_accuracy: 0.8214 - val_loss: 0.3978\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.4244 - val_accuracy: 0.8200 - val_loss: 0.3958\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.4208 - val_accuracy: 0.8119 - val_loss: 0.4137\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4165 - val_accuracy: 0.8149 - val_loss: 0.4147\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8079 - loss: 0.4219 - val_accuracy: 0.8204 - val_loss: 0.3937\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8085 - loss: 0.4233 - val_accuracy: 0.8220 - val_loss: 0.3912\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.4162 - val_accuracy: 0.8196 - val_loss: 0.3956\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.4128 - val_accuracy: 0.8204 - val_loss: 0.3914\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8097 - loss: 0.4158 - val_accuracy: 0.8249 - val_loss: 0.3910\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8159 - loss: 0.4086 - val_accuracy: 0.8220 - val_loss: 0.3913\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4139 - val_accuracy: 0.8229 - val_loss: 0.3915\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8128 - loss: 0.4121 - val_accuracy: 0.8212 - val_loss: 0.3967\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8156 - loss: 0.4072 - val_accuracy: 0.8239 - val_loss: 0.3870\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8175 - loss: 0.4073 - val_accuracy: 0.8244 - val_loss: 0.3864\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.4159 - val_accuracy: 0.8263 - val_loss: 0.3849\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8150 - loss: 0.4099 - val_accuracy: 0.8262 - val_loss: 0.3866\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.4074 - val_accuracy: 0.8280 - val_loss: 0.3865\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8155 - loss: 0.4105 - val_accuracy: 0.8240 - val_loss: 0.3872\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.4061 - val_accuracy: 0.8270 - val_loss: 0.3844\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8176 - loss: 0.4056 - val_accuracy: 0.8265 - val_loss: 0.3861\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8153 - loss: 0.4094 - val_accuracy: 0.8292 - val_loss: 0.3835\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8166 - loss: 0.4062 - val_accuracy: 0.8180 - val_loss: 0.3970\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.4097 - val_accuracy: 0.8233 - val_loss: 0.3921\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.4080 - val_accuracy: 0.8266 - val_loss: 0.3891\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8166 - loss: 0.4057 - val_accuracy: 0.8319 - val_loss: 0.3820\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8158 - loss: 0.4048 - val_accuracy: 0.8288 - val_loss: 0.3817\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8205 - loss: 0.4028 - val_accuracy: 0.8180 - val_loss: 0.3985\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8162 - loss: 0.4100 - val_accuracy: 0.8282 - val_loss: 0.3847\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8183 - loss: 0.4009 - val_accuracy: 0.8305 - val_loss: 0.3807\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8182 - loss: 0.4021 - val_accuracy: 0.8283 - val_loss: 0.3808\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8171 - loss: 0.4057 - val_accuracy: 0.8281 - val_loss: 0.3827\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 0.4078 - val_accuracy: 0.8306 - val_loss: 0.3787\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8209 - loss: 0.4001 - val_accuracy: 0.8308 - val_loss: 0.3798\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8165 - loss: 0.4042 - val_accuracy: 0.8183 - val_loss: 0.4054\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.3993 - val_accuracy: 0.8346 - val_loss: 0.3781\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8177 - loss: 0.4053 - val_accuracy: 0.8286 - val_loss: 0.3832\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8223 - loss: 0.3969 - val_accuracy: 0.8302 - val_loss: 0.3786\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.4009 - val_accuracy: 0.8291 - val_loss: 0.3779\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8225 - loss: 0.3949 - val_accuracy: 0.8295 - val_loss: 0.3783\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.4054 - val_accuracy: 0.8330 - val_loss: 0.3776\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.3971 - val_accuracy: 0.8320 - val_loss: 0.3774\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8310 - loss: 0.3782\n",
            "Test Loss: 0.3766\n",
            "Test Accuracy: 0.8343\n",
            "Confusion Matrix:\n",
            "[[6653 1285]\n",
            " [1481 7271]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      7938\n",
            "           1       0.85      0.83      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8343\n",
            "Precision: 0.8498\n",
            "Recall: 0.8308\n",
            "F1 Score: 0.8402\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the optimized CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcna2V4-82ET"
      },
      "source": [
        "improved cnn-lstm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE4rjXyB82ET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459e0f9f-42a0-4b3e-8fa5-1268c1b04aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6983 - loss: 0.5708 - val_accuracy: 0.7930 - val_loss: 0.4531\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7846 - loss: 0.4657 - val_accuracy: 0.7995 - val_loss: 0.4283\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 10ms/step - accuracy: 0.7984 - loss: 0.4465 - val_accuracy: 0.8065 - val_loss: 0.4187\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.7971 - loss: 0.4402 - val_accuracy: 0.8104 - val_loss: 0.4103\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8023 - loss: 0.4334 - val_accuracy: 0.8092 - val_loss: 0.4107\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8008 - loss: 0.4351 - val_accuracy: 0.8143 - val_loss: 0.4066\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8081 - loss: 0.4262 - val_accuracy: 0.8101 - val_loss: 0.4161\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8083 - loss: 0.4250 - val_accuracy: 0.8164 - val_loss: 0.4084\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8071 - loss: 0.4211 - val_accuracy: 0.8152 - val_loss: 0.3991\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8089 - loss: 0.4236 - val_accuracy: 0.8182 - val_loss: 0.3992\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8053 - loss: 0.4206 - val_accuracy: 0.8206 - val_loss: 0.3962\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8071 - loss: 0.4176 - val_accuracy: 0.8205 - val_loss: 0.3939\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8113 - loss: 0.4152 - val_accuracy: 0.8197 - val_loss: 0.3996\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8125 - loss: 0.4134 - val_accuracy: 0.8221 - val_loss: 0.3921\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8118 - loss: 0.4119 - val_accuracy: 0.8220 - val_loss: 0.3980\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8138 - loss: 0.4110 - val_accuracy: 0.8209 - val_loss: 0.3940\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8156 - loss: 0.4077 - val_accuracy: 0.8249 - val_loss: 0.3889\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8154 - loss: 0.4074 - val_accuracy: 0.8216 - val_loss: 0.3883\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8109 - loss: 0.4113 - val_accuracy: 0.8250 - val_loss: 0.3882\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8177 - loss: 0.4037 - val_accuracy: 0.8240 - val_loss: 0.3861\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8132 - loss: 0.4061 - val_accuracy: 0.8220 - val_loss: 0.3897\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8152 - loss: 0.4051 - val_accuracy: 0.8180 - val_loss: 0.3975\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8145 - loss: 0.4095 - val_accuracy: 0.8268 - val_loss: 0.3842\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8191 - loss: 0.4055 - val_accuracy: 0.8077 - val_loss: 0.4218\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8144 - loss: 0.4075 - val_accuracy: 0.8278 - val_loss: 0.3857\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8175 - loss: 0.4034 - val_accuracy: 0.8296 - val_loss: 0.3802\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8210 - loss: 0.3980 - val_accuracy: 0.8290 - val_loss: 0.3813\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8197 - loss: 0.4007 - val_accuracy: 0.8305 - val_loss: 0.3805\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8148 - loss: 0.4050 - val_accuracy: 0.8297 - val_loss: 0.3814\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8178 - loss: 0.3999 - val_accuracy: 0.8247 - val_loss: 0.3932\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8168 - loss: 0.4006 - val_accuracy: 0.8324 - val_loss: 0.3776\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.8185 - loss: 0.3988 - val_accuracy: 0.8337 - val_loss: 0.3765\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8213 - loss: 0.3965 - val_accuracy: 0.8319 - val_loss: 0.3780\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8210 - loss: 0.3980 - val_accuracy: 0.8343 - val_loss: 0.3758\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8201 - loss: 0.3984 - val_accuracy: 0.8137 - val_loss: 0.4226\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8181 - loss: 0.4023 - val_accuracy: 0.8306 - val_loss: 0.3765\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8208 - loss: 0.3951 - val_accuracy: 0.8354 - val_loss: 0.3739\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8189 - loss: 0.3985 - val_accuracy: 0.8305 - val_loss: 0.3760\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8200 - loss: 0.3985 - val_accuracy: 0.8356 - val_loss: 0.3729\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8208 - loss: 0.3978 - val_accuracy: 0.8337 - val_loss: 0.3761\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8232 - loss: 0.3924 - val_accuracy: 0.8336 - val_loss: 0.3745\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8217 - loss: 0.3957 - val_accuracy: 0.8322 - val_loss: 0.3906\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8234 - loss: 0.3940 - val_accuracy: 0.8328 - val_loss: 0.3728\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8228 - loss: 0.3941 - val_accuracy: 0.8343 - val_loss: 0.3748\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8243 - loss: 0.3940 - val_accuracy: 0.8337 - val_loss: 0.3784\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8164 - loss: 0.3987 - val_accuracy: 0.8361 - val_loss: 0.3725\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8250 - loss: 0.3882 - val_accuracy: 0.8334 - val_loss: 0.3750\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8211 - loss: 0.3961 - val_accuracy: 0.8355 - val_loss: 0.3724\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8222 - loss: 0.3917 - val_accuracy: 0.8328 - val_loss: 0.3708\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8217 - loss: 0.3901 - val_accuracy: 0.8328 - val_loss: 0.3739\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8317 - loss: 0.3710\n",
            "Test Loss: 0.3687\n",
            "Test Accuracy: 0.8342\n",
            "Confusion Matrix:\n",
            "[[6495 1443]\n",
            " [1325 7427]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.82      0.82      7938\n",
            "           1       0.84      0.85      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8342\n",
            "Precision: 0.8373\n",
            "Recall: 0.8486\n",
            "F1 Score: 0.8429\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5EAyvnm82ET"
      },
      "source": [
        "improved cnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQCDiqK782ET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249dfa33-d553-4874-8eb7-64993cf75379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.6767 - loss: 0.5894 - val_accuracy: 0.7925 - val_loss: 0.4497\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.7819 - loss: 0.4713 - val_accuracy: 0.7997 - val_loss: 0.4262\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.7899 - loss: 0.4548 - val_accuracy: 0.8062 - val_loss: 0.4268\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.7946 - loss: 0.4457 - val_accuracy: 0.8135 - val_loss: 0.4113\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8007 - loss: 0.4401 - val_accuracy: 0.8117 - val_loss: 0.4084\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8011 - loss: 0.4323 - val_accuracy: 0.8136 - val_loss: 0.4126\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8011 - loss: 0.4324 - val_accuracy: 0.8152 - val_loss: 0.4049\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8056 - loss: 0.4273 - val_accuracy: 0.8163 - val_loss: 0.4043\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8070 - loss: 0.4259 - val_accuracy: 0.8122 - val_loss: 0.4059\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8092 - loss: 0.4197 - val_accuracy: 0.8200 - val_loss: 0.4005\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8120 - loss: 0.4187 - val_accuracy: 0.8104 - val_loss: 0.4210\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8104 - loss: 0.4125 - val_accuracy: 0.8247 - val_loss: 0.3912\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.8094 - loss: 0.4182 - val_accuracy: 0.8061 - val_loss: 0.4347\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8077 - loss: 0.4200 - val_accuracy: 0.8264 - val_loss: 0.3899\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8104 - loss: 0.4142 - val_accuracy: 0.8244 - val_loss: 0.3883\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8135 - loss: 0.4113 - val_accuracy: 0.8209 - val_loss: 0.3964\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8147 - loss: 0.4111 - val_accuracy: 0.8241 - val_loss: 0.3946\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8159 - loss: 0.4070 - val_accuracy: 0.8136 - val_loss: 0.4306\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8150 - loss: 0.4078 - val_accuracy: 0.8275 - val_loss: 0.3819\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8119 - loss: 0.4087 - val_accuracy: 0.8274 - val_loss: 0.3852\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8151 - loss: 0.4056 - val_accuracy: 0.8235 - val_loss: 0.3927\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.8162 - loss: 0.4066 - val_accuracy: 0.8224 - val_loss: 0.3881\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8155 - loss: 0.4055 - val_accuracy: 0.8320 - val_loss: 0.3795\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8148 - loss: 0.4098 - val_accuracy: 0.8292 - val_loss: 0.3791\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8156 - loss: 0.4108 - val_accuracy: 0.8286 - val_loss: 0.3792\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8175 - loss: 0.4017 - val_accuracy: 0.8286 - val_loss: 0.3850\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8180 - loss: 0.4040 - val_accuracy: 0.8299 - val_loss: 0.3855\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8216 - loss: 0.3981 - val_accuracy: 0.8321 - val_loss: 0.3777\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8187 - loss: 0.3983 - val_accuracy: 0.8288 - val_loss: 0.3831\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.8187 - loss: 0.3997 - val_accuracy: 0.8316 - val_loss: 0.3782\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8162 - loss: 0.4058 - val_accuracy: 0.8286 - val_loss: 0.3790\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8220 - loss: 0.3994 - val_accuracy: 0.8315 - val_loss: 0.3787\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8195 - loss: 0.3993 - val_accuracy: 0.8336 - val_loss: 0.3752\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8212 - loss: 0.3986 - val_accuracy: 0.8334 - val_loss: 0.3776\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8194 - loss: 0.3999 - val_accuracy: 0.8354 - val_loss: 0.3724\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8201 - loss: 0.3969 - val_accuracy: 0.8307 - val_loss: 0.3779\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8168 - loss: 0.4030 - val_accuracy: 0.8322 - val_loss: 0.3768\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8209 - loss: 0.3998 - val_accuracy: 0.8333 - val_loss: 0.3736\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.8186 - loss: 0.4006 - val_accuracy: 0.8307 - val_loss: 0.3766\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8209 - loss: 0.3960 - val_accuracy: 0.8339 - val_loss: 0.3755\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8231 - loss: 0.3943 - val_accuracy: 0.8310 - val_loss: 0.3781\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8229 - loss: 0.3910 - val_accuracy: 0.8334 - val_loss: 0.3717\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8224 - loss: 0.3962 - val_accuracy: 0.8348 - val_loss: 0.3698\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8235 - loss: 0.3949 - val_accuracy: 0.8346 - val_loss: 0.3746\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8242 - loss: 0.3926 - val_accuracy: 0.8370 - val_loss: 0.3696\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.8238 - loss: 0.3917 - val_accuracy: 0.8327 - val_loss: 0.3783\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8217 - loss: 0.3949 - val_accuracy: 0.8388 - val_loss: 0.3692\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8263 - loss: 0.3891 - val_accuracy: 0.8357 - val_loss: 0.3725\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8259 - loss: 0.3912 - val_accuracy: 0.8337 - val_loss: 0.3756\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8249 - loss: 0.3902 - val_accuracy: 0.8364 - val_loss: 0.3717\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.3694\n",
            "Test Loss: 0.3671\n",
            "Test Accuracy: 0.8368\n",
            "Confusion Matrix:\n",
            "[[6649 1289]\n",
            " [1434 7318]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      7938\n",
            "           1       0.85      0.84      0.84      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8368\n",
            "Precision: 0.8502\n",
            "Recall: 0.8362\n",
            "F1 Score: 0.8431\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, GRU, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(GRU(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olPWrHZw82EU"
      },
      "source": [
        "improved DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R9NX4p382EU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4674001e-8889-4174-e0a4-c43e221643d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.6808 - loss: 0.6296 - val_accuracy: 0.7895 - val_loss: 0.4531\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7779 - loss: 0.4741 - val_accuracy: 0.8037 - val_loss: 0.4289\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.4546 - val_accuracy: 0.8155 - val_loss: 0.4180\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7994 - loss: 0.4390 - val_accuracy: 0.8128 - val_loss: 0.4166\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4340 - val_accuracy: 0.8118 - val_loss: 0.4142\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8040 - loss: 0.4272 - val_accuracy: 0.8208 - val_loss: 0.4036\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8102 - loss: 0.4189 - val_accuracy: 0.8231 - val_loss: 0.3981\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8105 - loss: 0.4204 - val_accuracy: 0.8265 - val_loss: 0.3910\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8161 - loss: 0.4106 - val_accuracy: 0.8289 - val_loss: 0.3859\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.4080 - val_accuracy: 0.8220 - val_loss: 0.3953\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8149 - loss: 0.4078 - val_accuracy: 0.8283 - val_loss: 0.3793\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8203 - loss: 0.4032 - val_accuracy: 0.8331 - val_loss: 0.3903\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.4052 - val_accuracy: 0.8344 - val_loss: 0.3740\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8184 - loss: 0.4030 - val_accuracy: 0.8343 - val_loss: 0.3794\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8198 - loss: 0.3990 - val_accuracy: 0.8405 - val_loss: 0.3714\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.3981 - val_accuracy: 0.8377 - val_loss: 0.3833\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8227 - loss: 0.3975 - val_accuracy: 0.8397 - val_loss: 0.3646\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.3962 - val_accuracy: 0.8375 - val_loss: 0.3707\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.3936 - val_accuracy: 0.8318 - val_loss: 0.3797\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8256 - loss: 0.3908 - val_accuracy: 0.8449 - val_loss: 0.3601\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8209 - loss: 0.3922 - val_accuracy: 0.8393 - val_loss: 0.3679\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8251 - loss: 0.3902 - val_accuracy: 0.8432 - val_loss: 0.3575\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.3893 - val_accuracy: 0.8423 - val_loss: 0.3671\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.3882 - val_accuracy: 0.8420 - val_loss: 0.3662\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8273 - loss: 0.3882 - val_accuracy: 0.8501 - val_loss: 0.3529\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8301 - loss: 0.3823 - val_accuracy: 0.8432 - val_loss: 0.3607\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8330 - loss: 0.3788 - val_accuracy: 0.8472 - val_loss: 0.3531\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.3840 - val_accuracy: 0.8482 - val_loss: 0.3481\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 0.3889 - val_accuracy: 0.8471 - val_loss: 0.3597\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 0.3750 - val_accuracy: 0.8482 - val_loss: 0.3520\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.3810 - val_accuracy: 0.8504 - val_loss: 0.3458\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8325 - loss: 0.3788 - val_accuracy: 0.8525 - val_loss: 0.3472\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8303 - loss: 0.3786 - val_accuracy: 0.8492 - val_loss: 0.3465\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.3771 - val_accuracy: 0.8498 - val_loss: 0.3447\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.3771 - val_accuracy: 0.8454 - val_loss: 0.3650\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8340 - loss: 0.3732 - val_accuracy: 0.8495 - val_loss: 0.3417\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8329 - loss: 0.3729 - val_accuracy: 0.8533 - val_loss: 0.3409\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8323 - loss: 0.3805 - val_accuracy: 0.8492 - val_loss: 0.3594\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8324 - loss: 0.3746 - val_accuracy: 0.8531 - val_loss: 0.3433\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 0.3708 - val_accuracy: 0.8514 - val_loss: 0.3453\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 0.3727 - val_accuracy: 0.8499 - val_loss: 0.3581\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8345 - loss: 0.3758 - val_accuracy: 0.8537 - val_loss: 0.3414\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8343 - loss: 0.3715 - val_accuracy: 0.8555 - val_loss: 0.3397\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8332 - loss: 0.3746 - val_accuracy: 0.8531 - val_loss: 0.3393\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.3689 - val_accuracy: 0.8549 - val_loss: 0.3378\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8393 - loss: 0.3715 - val_accuracy: 0.8545 - val_loss: 0.3409\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.3712 - val_accuracy: 0.8542 - val_loss: 0.3367\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 0.3652 - val_accuracy: 0.8471 - val_loss: 0.3529\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8350 - loss: 0.3711 - val_accuracy: 0.8519 - val_loss: 0.3417\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.3706 - val_accuracy: 0.8572 - val_loss: 0.3343\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8541 - loss: 0.3358\n",
            "Test Loss: 0.3350\n",
            "Test Accuracy: 0.8560\n",
            "Confusion Matrix:\n",
            "[[6758 1180]\n",
            " [1223 7529]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85      7938\n",
            "           1       0.86      0.86      0.86      8752\n",
            "\n",
            "    accuracy                           0.86     16690\n",
            "   macro avg       0.86      0.86      0.86     16690\n",
            "weighted avg       0.86      0.86      0.86     16690\n",
            "\n",
            "Accuracy: 0.8560\n",
            "Precision: 0.8645\n",
            "Recall: 0.8603\n",
            "F1 Score: 0.8624\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the DNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input and hidden layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yijptGAb82EU"
      },
      "source": [
        "improved dnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrY8fFVI82EU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a968c87f-4f86-4baf-c07b-8c37c031fd85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 16ms/step - accuracy: 0.5532 - loss: 0.7020 - val_accuracy: 0.6422 - val_loss: 0.6396\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.6394 - loss: 0.6409 - val_accuracy: 0.7321 - val_loss: 0.5392\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7376 - loss: 0.5361 - val_accuracy: 0.7851 - val_loss: 0.4545\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.7805 - loss: 0.4800 - val_accuracy: 0.7937 - val_loss: 0.4364\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.7916 - loss: 0.4623 - val_accuracy: 0.7991 - val_loss: 0.4297\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7985 - loss: 0.4494 - val_accuracy: 0.8077 - val_loss: 0.4179\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7968 - loss: 0.4437 - val_accuracy: 0.8076 - val_loss: 0.4173\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8057 - loss: 0.4383 - val_accuracy: 0.8058 - val_loss: 0.4200\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step - accuracy: 0.7982 - loss: 0.4375 - val_accuracy: 0.8140 - val_loss: 0.4049\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8038 - loss: 0.4349 - val_accuracy: 0.8182 - val_loss: 0.3995\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step - accuracy: 0.8040 - loss: 0.4328 - val_accuracy: 0.8217 - val_loss: 0.3956\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.8108 - loss: 0.4261 - val_accuracy: 0.8121 - val_loss: 0.4082\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8108 - loss: 0.4181 - val_accuracy: 0.8169 - val_loss: 0.3967\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8106 - loss: 0.4201 - val_accuracy: 0.8198 - val_loss: 0.4015\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8119 - loss: 0.4215 - val_accuracy: 0.8265 - val_loss: 0.3889\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8148 - loss: 0.4113 - val_accuracy: 0.8273 - val_loss: 0.3873\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8155 - loss: 0.4174 - val_accuracy: 0.8271 - val_loss: 0.3820\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8160 - loss: 0.4103 - val_accuracy: 0.8178 - val_loss: 0.3925\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 14ms/step - accuracy: 0.8211 - loss: 0.4040 - val_accuracy: 0.8229 - val_loss: 0.3968\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8204 - loss: 0.4031 - val_accuracy: 0.8299 - val_loss: 0.3781\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8230 - loss: 0.4032 - val_accuracy: 0.8307 - val_loss: 0.3754\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 15ms/step - accuracy: 0.8242 - loss: 0.3961 - val_accuracy: 0.8298 - val_loss: 0.3795\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8236 - loss: 0.4014 - val_accuracy: 0.8128 - val_loss: 0.3976\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8224 - loss: 0.3992 - val_accuracy: 0.8349 - val_loss: 0.3775\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8263 - loss: 0.3962 - val_accuracy: 0.8326 - val_loss: 0.3822\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8264 - loss: 0.3925 - val_accuracy: 0.8322 - val_loss: 0.3698\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8287 - loss: 0.3922 - val_accuracy: 0.8362 - val_loss: 0.3682\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8270 - loss: 0.3911 - val_accuracy: 0.8395 - val_loss: 0.3651\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8296 - loss: 0.3862 - val_accuracy: 0.8369 - val_loss: 0.3681\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.8288 - loss: 0.3860 - val_accuracy: 0.8393 - val_loss: 0.3606\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.8282 - loss: 0.3882 - val_accuracy: 0.8394 - val_loss: 0.3610\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8332 - loss: 0.3843 - val_accuracy: 0.8359 - val_loss: 0.3674\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8307 - loss: 0.3860 - val_accuracy: 0.8264 - val_loss: 0.3861\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8283 - loss: 0.3867 - val_accuracy: 0.8411 - val_loss: 0.3578\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8319 - loss: 0.3859 - val_accuracy: 0.8397 - val_loss: 0.3613\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8310 - loss: 0.3828 - val_accuracy: 0.8387 - val_loss: 0.3606\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8337 - loss: 0.3780 - val_accuracy: 0.8340 - val_loss: 0.3703\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8303 - loss: 0.3797 - val_accuracy: 0.8399 - val_loss: 0.3571\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.8333 - loss: 0.3780 - val_accuracy: 0.8358 - val_loss: 0.3681\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8350 - loss: 0.3757 - val_accuracy: 0.8435 - val_loss: 0.3569\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8387 - loss: 0.3700 - val_accuracy: 0.8431 - val_loss: 0.3596\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8382 - loss: 0.3712 - val_accuracy: 0.8399 - val_loss: 0.3562\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8354 - loss: 0.3715 - val_accuracy: 0.8433 - val_loss: 0.3502\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8377 - loss: 0.3714 - val_accuracy: 0.8436 - val_loss: 0.3554\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8382 - loss: 0.3670 - val_accuracy: 0.8447 - val_loss: 0.3520\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8355 - loss: 0.3748 - val_accuracy: 0.8435 - val_loss: 0.3496\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.8395 - loss: 0.3671 - val_accuracy: 0.8471 - val_loss: 0.3480\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8378 - loss: 0.3693 - val_accuracy: 0.8465 - val_loss: 0.3472\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8372 - loss: 0.3651 - val_accuracy: 0.8445 - val_loss: 0.3486\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.8369 - loss: 0.3670 - val_accuracy: 0.8452 - val_loss: 0.3504\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8486 - loss: 0.3443\n",
            "Test Loss: 0.3447\n",
            "Test Accuracy: 0.8488\n",
            "Confusion Matrix:\n",
            "[[6723 1215]\n",
            " [1309 7443]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84      7938\n",
            "           1       0.86      0.85      0.86      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8488\n",
            "Precision: 0.8597\n",
            "Recall: 0.8504\n",
            "F1 Score: 0.8550\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjs_57Ly82EU"
      },
      "source": [
        "improved dnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1si5ltJ-82EU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab89bf0-fffb-48a3-e84a-6e954d7846fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 23ms/step - accuracy: 0.5686 - loss: 0.7584 - val_accuracy: 0.6624 - val_loss: 0.6121\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.6543 - loss: 0.6238 - val_accuracy: 0.7200 - val_loss: 0.5466\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.7276 - loss: 0.5427 - val_accuracy: 0.7850 - val_loss: 0.4606\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.7666 - loss: 0.4902 - val_accuracy: 0.7785 - val_loss: 0.4755\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.7806 - loss: 0.4715 - val_accuracy: 0.8000 - val_loss: 0.4304\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - accuracy: 0.7860 - loss: 0.4619 - val_accuracy: 0.8038 - val_loss: 0.4266\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.7937 - loss: 0.4472 - val_accuracy: 0.8107 - val_loss: 0.4139\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.7944 - loss: 0.4455 - val_accuracy: 0.8122 - val_loss: 0.4144\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.7978 - loss: 0.4369 - val_accuracy: 0.8146 - val_loss: 0.4052\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8008 - loss: 0.4379 - val_accuracy: 0.8111 - val_loss: 0.4126\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.8040 - loss: 0.4318 - val_accuracy: 0.8165 - val_loss: 0.4024\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.8071 - loss: 0.4250 - val_accuracy: 0.8266 - val_loss: 0.3905\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.8086 - loss: 0.4197 - val_accuracy: 0.8323 - val_loss: 0.3826\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8069 - loss: 0.4211 - val_accuracy: 0.8292 - val_loss: 0.3813\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - accuracy: 0.8088 - loss: 0.4178 - val_accuracy: 0.8242 - val_loss: 0.3978\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.8141 - loss: 0.4118 - val_accuracy: 0.8253 - val_loss: 0.3833\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8144 - loss: 0.4092 - val_accuracy: 0.8346 - val_loss: 0.3731\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8144 - loss: 0.4095 - val_accuracy: 0.8358 - val_loss: 0.3759\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8162 - loss: 0.4052 - val_accuracy: 0.8355 - val_loss: 0.3727\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - accuracy: 0.8145 - loss: 0.4088 - val_accuracy: 0.8214 - val_loss: 0.3909\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.8167 - loss: 0.4018 - val_accuracy: 0.8358 - val_loss: 0.3671\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 23ms/step - accuracy: 0.8173 - loss: 0.4018 - val_accuracy: 0.8370 - val_loss: 0.3686\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - accuracy: 0.8155 - loss: 0.4047 - val_accuracy: 0.8322 - val_loss: 0.3676\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8153 - loss: 0.4039 - val_accuracy: 0.8298 - val_loss: 0.3750\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - accuracy: 0.8188 - loss: 0.4006 - val_accuracy: 0.8313 - val_loss: 0.3823\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.8179 - loss: 0.3989 - val_accuracy: 0.8391 - val_loss: 0.3648\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - accuracy: 0.8215 - loss: 0.3965 - val_accuracy: 0.8415 - val_loss: 0.3619\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.8198 - loss: 0.3954 - val_accuracy: 0.8146 - val_loss: 0.4182\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8202 - loss: 0.3956 - val_accuracy: 0.8359 - val_loss: 0.3612\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8210 - loss: 0.3964 - val_accuracy: 0.8405 - val_loss: 0.3629\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - accuracy: 0.8229 - loss: 0.3928 - val_accuracy: 0.8392 - val_loss: 0.3612\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.8242 - loss: 0.3899 - val_accuracy: 0.8315 - val_loss: 0.3815\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.8233 - loss: 0.3925 - val_accuracy: 0.8383 - val_loss: 0.3614\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 21ms/step - accuracy: 0.8217 - loss: 0.3948 - val_accuracy: 0.8398 - val_loss: 0.3586\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - accuracy: 0.8239 - loss: 0.3878 - val_accuracy: 0.8411 - val_loss: 0.3585\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.8272 - loss: 0.3879 - val_accuracy: 0.8331 - val_loss: 0.3714\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8259 - loss: 0.3854 - val_accuracy: 0.8376 - val_loss: 0.3555\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8270 - loss: 0.3847 - val_accuracy: 0.8393 - val_loss: 0.3623\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8290 - loss: 0.3812 - val_accuracy: 0.8353 - val_loss: 0.3642\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.8249 - loss: 0.3885 - val_accuracy: 0.8391 - val_loss: 0.3561\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.8268 - loss: 0.3857 - val_accuracy: 0.8410 - val_loss: 0.3610\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8279 - loss: 0.3814 - val_accuracy: 0.8172 - val_loss: 0.4022\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 24ms/step - accuracy: 0.8302 - loss: 0.3808 - val_accuracy: 0.8443 - val_loss: 0.3552\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8281 - loss: 0.3834 - val_accuracy: 0.8163 - val_loss: 0.4057\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8297 - loss: 0.3811 - val_accuracy: 0.8428 - val_loss: 0.3505\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8277 - loss: 0.3824 - val_accuracy: 0.8414 - val_loss: 0.3533\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8309 - loss: 0.3788 - val_accuracy: 0.8426 - val_loss: 0.3515\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8314 - loss: 0.3791 - val_accuracy: 0.8383 - val_loss: 0.3573\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8302 - loss: 0.3779 - val_accuracy: 0.8383 - val_loss: 0.3607\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.8311 - loss: 0.3740 - val_accuracy: 0.8442 - val_loss: 0.3515\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8463 - loss: 0.3519\n",
            "Test Loss: 0.3517\n",
            "Test Accuracy: 0.8453\n",
            "Confusion Matrix:\n",
            "[[6698 1240]\n",
            " [1342 7410]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.84      7938\n",
            "           1       0.86      0.85      0.85      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.84      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8453\n",
            "Precision: 0.8566\n",
            "Recall: 0.8467\n",
            "F1 Score: 0.8516\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Reshape output from Dense layers to be suitable for GRU layers\n",
        "model.add(tf.keras.layers.Reshape((X_train_reshaped.shape[1], 32)))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekNfmuJi8ioA"
      },
      "source": [
        "12-features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIKmRYBY8ioB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39a434e-6b46-4bbe-c40c-ffccc8cd2bd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Length-of-Email',\n",
              " 'Number of co-occuring words',\n",
              " 'Repititive-Words-in-a-Email',\n",
              " 'Spam lexicon',\n",
              " 'Uinque-Words-in-a-Email',\n",
              " 'Number-of-noun',\n",
              " 'Pos-Sentiment',\n",
              " 'Neu-Sentiment',\n",
              " 'Comp-Sentiment',\n",
              " 'Polarity',\n",
              " 'Subjective',\n",
              " 'Quoted-text-in-a-Email']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "features=pca_importances.nlargest(n=12, columns='Total Importance')['Feature'].to_list()\n",
        "features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO4UTArq8ioB"
      },
      "source": [
        "improved rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJnQuDoG8ioB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e43c83d-b258-4a5e-ff0b-0744103bb22b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.7032 - loss: 0.5842 - val_accuracy: 0.8053 - val_loss: 0.4314\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8019 - loss: 0.4504 - val_accuracy: 0.8143 - val_loss: 0.4111\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.8089 - loss: 0.4312 - val_accuracy: 0.8214 - val_loss: 0.3995\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8142 - loss: 0.4198 - val_accuracy: 0.8271 - val_loss: 0.3869\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8204 - loss: 0.4065 - val_accuracy: 0.8295 - val_loss: 0.3903\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8208 - loss: 0.4021 - val_accuracy: 0.8253 - val_loss: 0.3988\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8271 - loss: 0.3981 - val_accuracy: 0.8342 - val_loss: 0.3807\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.8283 - loss: 0.3884 - val_accuracy: 0.8232 - val_loss: 0.3862\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8296 - loss: 0.3913 - val_accuracy: 0.8385 - val_loss: 0.3651\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8337 - loss: 0.3854 - val_accuracy: 0.8368 - val_loss: 0.3703\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8327 - loss: 0.3826 - val_accuracy: 0.8449 - val_loss: 0.3615\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8348 - loss: 0.3764 - val_accuracy: 0.8325 - val_loss: 0.3790\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 11ms/step - accuracy: 0.8379 - loss: 0.3758 - val_accuracy: 0.8435 - val_loss: 0.3640\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 16ms/step - accuracy: 0.8363 - loss: 0.3759 - val_accuracy: 0.8415 - val_loss: 0.3706\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.8383 - loss: 0.3720 - val_accuracy: 0.8329 - val_loss: 0.3703\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 19ms/step - accuracy: 0.8383 - loss: 0.3691 - val_accuracy: 0.8388 - val_loss: 0.3586\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.8403 - loss: 0.3680 - val_accuracy: 0.8435 - val_loss: 0.3680\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8414 - loss: 0.3676 - val_accuracy: 0.8501 - val_loss: 0.3470\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - accuracy: 0.8430 - loss: 0.3652 - val_accuracy: 0.8459 - val_loss: 0.3600\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 28ms/step - accuracy: 0.8385 - loss: 0.3627 - val_accuracy: 0.8435 - val_loss: 0.3517\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 22ms/step - accuracy: 0.8446 - loss: 0.3589 - val_accuracy: 0.8393 - val_loss: 0.3664\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 26ms/step - accuracy: 0.8454 - loss: 0.3614 - val_accuracy: 0.8473 - val_loss: 0.3517\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 18ms/step - accuracy: 0.8482 - loss: 0.3560 - val_accuracy: 0.8443 - val_loss: 0.3523\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.8475 - loss: 0.3534 - val_accuracy: 0.8474 - val_loss: 0.3461\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8446 - loss: 0.3577 - val_accuracy: 0.8463 - val_loss: 0.3488\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.8492 - loss: 0.3500 - val_accuracy: 0.8483 - val_loss: 0.3586\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 17ms/step - accuracy: 0.8473 - loss: 0.3535 - val_accuracy: 0.8534 - val_loss: 0.3363\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8470 - loss: 0.3490 - val_accuracy: 0.8387 - val_loss: 0.3603\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.8491 - loss: 0.3468 - val_accuracy: 0.8471 - val_loss: 0.3517\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8475 - loss: 0.3491 - val_accuracy: 0.8488 - val_loss: 0.3441\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 19ms/step - accuracy: 0.8540 - loss: 0.3409 - val_accuracy: 0.8423 - val_loss: 0.3504\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - accuracy: 0.8519 - loss: 0.3442 - val_accuracy: 0.8463 - val_loss: 0.3412\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 11ms/step - accuracy: 0.8525 - loss: 0.3415 - val_accuracy: 0.8525 - val_loss: 0.3408\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8529 - loss: 0.3420 - val_accuracy: 0.8548 - val_loss: 0.3318\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8538 - loss: 0.3375 - val_accuracy: 0.8550 - val_loss: 0.3326\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8557 - loss: 0.3370 - val_accuracy: 0.8486 - val_loss: 0.3408\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8541 - loss: 0.3368 - val_accuracy: 0.8530 - val_loss: 0.3295\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8558 - loss: 0.3331 - val_accuracy: 0.8465 - val_loss: 0.3450\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8528 - loss: 0.3378 - val_accuracy: 0.8515 - val_loss: 0.3333\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8566 - loss: 0.3309 - val_accuracy: 0.8558 - val_loss: 0.3394\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8551 - loss: 0.3337 - val_accuracy: 0.8555 - val_loss: 0.3275\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8576 - loss: 0.3304 - val_accuracy: 0.8501 - val_loss: 0.3411\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8582 - loss: 0.3343 - val_accuracy: 0.8510 - val_loss: 0.3363\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8562 - loss: 0.3341 - val_accuracy: 0.8544 - val_loss: 0.3340\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8552 - loss: 0.3337 - val_accuracy: 0.8417 - val_loss: 0.3570\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.8566 - loss: 0.3330 - val_accuracy: 0.8498 - val_loss: 0.3404\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8579 - loss: 0.3290 - val_accuracy: 0.8587 - val_loss: 0.3314\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.8590 - loss: 0.3285 - val_accuracy: 0.8562 - val_loss: 0.3262\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8614 - loss: 0.3235 - val_accuracy: 0.8571 - val_loss: 0.3239\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8587 - loss: 0.3304 - val_accuracy: 0.8569 - val_loss: 0.3265\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 0.3210\n",
            "Test Loss: 0.3223\n",
            "Test Accuracy: 0.8603\n",
            "Confusion Matrix:\n",
            "[[6785 1153]\n",
            " [1179 7573]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85      7938\n",
            "           1       0.87      0.87      0.87      8752\n",
            "\n",
            "    accuracy                           0.86     16690\n",
            "   macro avg       0.86      0.86      0.86     16690\n",
            "weighted avg       0.86      0.86      0.86     16690\n",
            "\n",
            "Accuracy: 0.8603\n",
            "Precision: 0.8679\n",
            "Recall: 0.8653\n",
            "F1 Score: 0.8666\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# RNN layers\n",
        "model.add(SimpleRNN(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(SimpleRNN(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUuNd9on8ioC"
      },
      "source": [
        "improved rnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXnJnZul8ioC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88b7d09-d095-4ef4-ec26-c3c852425112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 25ms/step - accuracy: 0.5753 - loss: 0.7069 - val_accuracy: 0.6396 - val_loss: 0.6274\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26ms/step - accuracy: 0.6320 - loss: 0.6421 - val_accuracy: 0.6749 - val_loss: 0.6021\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.6781 - loss: 0.6013 - val_accuracy: 0.6997 - val_loss: 0.5617\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 19ms/step - accuracy: 0.7318 - loss: 0.5357 - val_accuracy: 0.7528 - val_loss: 0.4956\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.7606 - loss: 0.4965 - val_accuracy: 0.7812 - val_loss: 0.4536\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.7787 - loss: 0.4686 - val_accuracy: 0.7892 - val_loss: 0.4386\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 18ms/step - accuracy: 0.7909 - loss: 0.4563 - val_accuracy: 0.8085 - val_loss: 0.4152\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8003 - loss: 0.4386 - val_accuracy: 0.8012 - val_loss: 0.4328\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.7999 - loss: 0.4322 - val_accuracy: 0.8053 - val_loss: 0.4119\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8047 - loss: 0.4289 - val_accuracy: 0.8180 - val_loss: 0.3981\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8070 - loss: 0.4270 - val_accuracy: 0.8188 - val_loss: 0.4012\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8082 - loss: 0.4194 - val_accuracy: 0.8130 - val_loss: 0.4012\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.8150 - loss: 0.4102 - val_accuracy: 0.8230 - val_loss: 0.3899\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.8182 - loss: 0.4063 - val_accuracy: 0.8231 - val_loss: 0.3956\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8163 - loss: 0.4082 - val_accuracy: 0.8168 - val_loss: 0.3961\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8178 - loss: 0.4048 - val_accuracy: 0.8296 - val_loss: 0.3837\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8217 - loss: 0.3986 - val_accuracy: 0.8179 - val_loss: 0.3942\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8246 - loss: 0.3924 - val_accuracy: 0.8110 - val_loss: 0.4129\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8206 - loss: 0.3999 - val_accuracy: 0.8289 - val_loss: 0.3803\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8242 - loss: 0.3958 - val_accuracy: 0.8281 - val_loss: 0.3776\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8238 - loss: 0.3959 - val_accuracy: 0.8297 - val_loss: 0.3721\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.8259 - loss: 0.3936 - val_accuracy: 0.8283 - val_loss: 0.3779\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8261 - loss: 0.3843 - val_accuracy: 0.8318 - val_loss: 0.3711\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8301 - loss: 0.3833 - val_accuracy: 0.8323 - val_loss: 0.3734\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 16ms/step - accuracy: 0.8282 - loss: 0.3869 - val_accuracy: 0.8349 - val_loss: 0.3683\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8328 - loss: 0.3777 - val_accuracy: 0.8385 - val_loss: 0.3609\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8312 - loss: 0.3842 - val_accuracy: 0.8071 - val_loss: 0.4107\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8331 - loss: 0.3780 - val_accuracy: 0.8364 - val_loss: 0.3612\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8325 - loss: 0.3800 - val_accuracy: 0.8376 - val_loss: 0.3631\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8329 - loss: 0.3755 - val_accuracy: 0.8336 - val_loss: 0.3631\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8357 - loss: 0.3719 - val_accuracy: 0.8291 - val_loss: 0.3706\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.8353 - loss: 0.3736 - val_accuracy: 0.8414 - val_loss: 0.3578\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8345 - loss: 0.3714 - val_accuracy: 0.8417 - val_loss: 0.3517\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8383 - loss: 0.3691 - val_accuracy: 0.8406 - val_loss: 0.3518\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8339 - loss: 0.3676 - val_accuracy: 0.8416 - val_loss: 0.3539\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.8359 - loss: 0.3683 - val_accuracy: 0.8373 - val_loss: 0.3604\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8401 - loss: 0.3646 - val_accuracy: 0.8370 - val_loss: 0.3603\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8384 - loss: 0.3667 - val_accuracy: 0.8404 - val_loss: 0.3489\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8367 - loss: 0.3724 - val_accuracy: 0.8429 - val_loss: 0.3490\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8396 - loss: 0.3646 - val_accuracy: 0.8402 - val_loss: 0.3514\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8401 - loss: 0.3613 - val_accuracy: 0.8444 - val_loss: 0.3474\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8429 - loss: 0.3569 - val_accuracy: 0.8373 - val_loss: 0.3519\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8401 - loss: 0.3625 - val_accuracy: 0.8411 - val_loss: 0.3441\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8429 - loss: 0.3525 - val_accuracy: 0.8430 - val_loss: 0.3463\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8426 - loss: 0.3575 - val_accuracy: 0.8473 - val_loss: 0.3441\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8427 - loss: 0.3622 - val_accuracy: 0.8444 - val_loss: 0.3450\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 16ms/step - accuracy: 0.8441 - loss: 0.3566 - val_accuracy: 0.8457 - val_loss: 0.3418\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8449 - loss: 0.3471 - val_accuracy: 0.8407 - val_loss: 0.3474\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.8437 - loss: 0.3567 - val_accuracy: 0.8480 - val_loss: 0.3370\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8473 - loss: 0.3510 - val_accuracy: 0.8491 - val_loss: 0.3401\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8494 - loss: 0.3404\n",
            "Test Loss: 0.3406\n",
            "Test Accuracy: 0.8494\n",
            "Confusion Matrix:\n",
            "[[6846 1092]\n",
            " [1421 7331]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84      7938\n",
            "           1       0.87      0.84      0.85      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8494\n",
            "Precision: 0.8704\n",
            "Recall: 0.8376\n",
            "F1 Score: 0.8537\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQiWhsqr8ioD"
      },
      "source": [
        "improved rnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPMq8LMI8ioD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3443426-236d-4204-d1b0-3548123ca3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 20ms/step - accuracy: 0.5604 - loss: 0.7270 - val_accuracy: 0.6472 - val_loss: 0.6289\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 21ms/step - accuracy: 0.6371 - loss: 0.6391 - val_accuracy: 0.6743 - val_loss: 0.6055\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 20ms/step - accuracy: 0.7634 - loss: 0.5014 - val_accuracy: 0.7763 - val_loss: 0.4846\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.7841 - loss: 0.4690 - val_accuracy: 0.8032 - val_loss: 0.4243\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7960 - loss: 0.4503 - val_accuracy: 0.7900 - val_loss: 0.4423\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - accuracy: 0.7983 - loss: 0.4440 - val_accuracy: 0.8099 - val_loss: 0.4155\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.8021 - loss: 0.4361 - val_accuracy: 0.8113 - val_loss: 0.4114\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8058 - loss: 0.4314 - val_accuracy: 0.7994 - val_loss: 0.4239\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8056 - loss: 0.4305 - val_accuracy: 0.8012 - val_loss: 0.4243\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.8100 - loss: 0.4252 - val_accuracy: 0.8182 - val_loss: 0.3975\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8131 - loss: 0.4142 - val_accuracy: 0.8213 - val_loss: 0.3963\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8147 - loss: 0.4162 - val_accuracy: 0.8104 - val_loss: 0.4063\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8163 - loss: 0.4118 - val_accuracy: 0.8254 - val_loss: 0.3875\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.8145 - loss: 0.4107 - val_accuracy: 0.8290 - val_loss: 0.3917\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8133 - loss: 0.4127 - val_accuracy: 0.8203 - val_loss: 0.3880\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8196 - loss: 0.4047 - val_accuracy: 0.8248 - val_loss: 0.3887\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8207 - loss: 0.4026 - val_accuracy: 0.8254 - val_loss: 0.3928\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8229 - loss: 0.3965 - val_accuracy: 0.8318 - val_loss: 0.3747\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 20ms/step - accuracy: 0.8216 - loss: 0.4007 - val_accuracy: 0.8283 - val_loss: 0.3767\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8237 - loss: 0.3960 - val_accuracy: 0.8337 - val_loss: 0.3727\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8207 - loss: 0.3991 - val_accuracy: 0.8316 - val_loss: 0.3795\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8273 - loss: 0.3901 - val_accuracy: 0.8331 - val_loss: 0.3700\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8257 - loss: 0.3889 - val_accuracy: 0.8336 - val_loss: 0.3705\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8267 - loss: 0.3879 - val_accuracy: 0.8334 - val_loss: 0.3714\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8291 - loss: 0.3860 - val_accuracy: 0.8365 - val_loss: 0.3624\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8283 - loss: 0.3863 - val_accuracy: 0.8319 - val_loss: 0.3630\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.8336 - loss: 0.3770 - val_accuracy: 0.8322 - val_loss: 0.3698\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8327 - loss: 0.3747 - val_accuracy: 0.8271 - val_loss: 0.3741\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8333 - loss: 0.3763 - val_accuracy: 0.8299 - val_loss: 0.3699\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8350 - loss: 0.3723 - val_accuracy: 0.8382 - val_loss: 0.3606\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8318 - loss: 0.3766 - val_accuracy: 0.8364 - val_loss: 0.3604\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8337 - loss: 0.3747 - val_accuracy: 0.8408 - val_loss: 0.3534\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8306 - loss: 0.3766 - val_accuracy: 0.8379 - val_loss: 0.3581\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8329 - loss: 0.3745 - val_accuracy: 0.8337 - val_loss: 0.3659\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8331 - loss: 0.3746 - val_accuracy: 0.8404 - val_loss: 0.3609\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8353 - loss: 0.3724 - val_accuracy: 0.8370 - val_loss: 0.3609\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8362 - loss: 0.3700 - val_accuracy: 0.8422 - val_loss: 0.3479\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8360 - loss: 0.3679 - val_accuracy: 0.8402 - val_loss: 0.3535\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8407 - loss: 0.3635 - val_accuracy: 0.8432 - val_loss: 0.3506\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8395 - loss: 0.3635 - val_accuracy: 0.8447 - val_loss: 0.3500\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8410 - loss: 0.3607 - val_accuracy: 0.8453 - val_loss: 0.3466\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8353 - loss: 0.3695 - val_accuracy: 0.8453 - val_loss: 0.3456\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8391 - loss: 0.3655 - val_accuracy: 0.8420 - val_loss: 0.3501\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8412 - loss: 0.3551 - val_accuracy: 0.8423 - val_loss: 0.3489\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8400 - loss: 0.3612 - val_accuracy: 0.8483 - val_loss: 0.3463\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8410 - loss: 0.3558 - val_accuracy: 0.8442 - val_loss: 0.3441\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8428 - loss: 0.3559 - val_accuracy: 0.8491 - val_loss: 0.3448\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8455 - loss: 0.3524 - val_accuracy: 0.8492 - val_loss: 0.3389\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8430 - loss: 0.3513 - val_accuracy: 0.8478 - val_loss: 0.3473\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8475 - loss: 0.3494 - val_accuracy: 0.8531 - val_loss: 0.3345\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8480 - loss: 0.3420\n",
            "Test Loss: 0.3398\n",
            "Test Accuracy: 0.8519\n",
            "Confusion Matrix:\n",
            "[[6816 1122]\n",
            " [1350 7402]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.85      7938\n",
            "           1       0.87      0.85      0.86      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8519\n",
            "Precision: 0.8684\n",
            "Recall: 0.8457\n",
            "F1 Score: 0.8569\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo8gy_0k8ioD"
      },
      "source": [
        "improved cnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXsdUEmo8ioD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439f8789-9acd-498a-a344-0f9a7f0c1678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6538 - loss: 0.6662 - val_accuracy: 0.7922 - val_loss: 0.4531\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7671 - loss: 0.4878 - val_accuracy: 0.8048 - val_loss: 0.4270\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7854 - loss: 0.4629 - val_accuracy: 0.8060 - val_loss: 0.4233\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7916 - loss: 0.4533 - val_accuracy: 0.8096 - val_loss: 0.4125\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7983 - loss: 0.4427 - val_accuracy: 0.8170 - val_loss: 0.4060\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.4381 - val_accuracy: 0.8150 - val_loss: 0.4032\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7999 - loss: 0.4339 - val_accuracy: 0.8147 - val_loss: 0.4014\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8042 - loss: 0.4292 - val_accuracy: 0.8176 - val_loss: 0.3992\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8074 - loss: 0.4240 - val_accuracy: 0.8195 - val_loss: 0.3983\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8100 - loss: 0.4222 - val_accuracy: 0.8253 - val_loss: 0.3944\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4184 - val_accuracy: 0.8263 - val_loss: 0.3884\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4160 - val_accuracy: 0.8198 - val_loss: 0.3898\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8108 - loss: 0.4165 - val_accuracy: 0.8277 - val_loss: 0.3887\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8158 - loss: 0.4146 - val_accuracy: 0.8238 - val_loss: 0.3881\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 0.4100 - val_accuracy: 0.8301 - val_loss: 0.3859\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.4121 - val_accuracy: 0.8307 - val_loss: 0.3842\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8138 - loss: 0.4125 - val_accuracy: 0.8304 - val_loss: 0.3797\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.4123 - val_accuracy: 0.8294 - val_loss: 0.3810\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8180 - loss: 0.4060 - val_accuracy: 0.8279 - val_loss: 0.3853\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.4077 - val_accuracy: 0.8310 - val_loss: 0.3799\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.4070 - val_accuracy: 0.8323 - val_loss: 0.3789\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.4023 - val_accuracy: 0.8337 - val_loss: 0.3764\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8214 - loss: 0.3998 - val_accuracy: 0.8302 - val_loss: 0.3764\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.4022 - val_accuracy: 0.8303 - val_loss: 0.3756\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8204 - loss: 0.4023 - val_accuracy: 0.8352 - val_loss: 0.3725\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.4034 - val_accuracy: 0.8312 - val_loss: 0.3741\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8191 - loss: 0.4044 - val_accuracy: 0.8320 - val_loss: 0.3710\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.3979 - val_accuracy: 0.8346 - val_loss: 0.3782\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 0.3986 - val_accuracy: 0.8341 - val_loss: 0.3719\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.3998 - val_accuracy: 0.8343 - val_loss: 0.3706\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.4019 - val_accuracy: 0.8339 - val_loss: 0.3759\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8188 - loss: 0.3988 - val_accuracy: 0.8346 - val_loss: 0.3709\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8194 - loss: 0.3965 - val_accuracy: 0.8352 - val_loss: 0.3720\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8197 - loss: 0.4023 - val_accuracy: 0.8365 - val_loss: 0.3685\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.3965 - val_accuracy: 0.8360 - val_loss: 0.3690\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8226 - loss: 0.3966 - val_accuracy: 0.8328 - val_loss: 0.3728\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8227 - loss: 0.3965 - val_accuracy: 0.8369 - val_loss: 0.3703\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.3996 - val_accuracy: 0.8326 - val_loss: 0.3760\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8221 - loss: 0.3954 - val_accuracy: 0.8355 - val_loss: 0.3654\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8260 - loss: 0.3924 - val_accuracy: 0.8343 - val_loss: 0.3729\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8247 - loss: 0.3939 - val_accuracy: 0.8328 - val_loss: 0.3749\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.3954 - val_accuracy: 0.8373 - val_loss: 0.3696\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8240 - loss: 0.3922 - val_accuracy: 0.8354 - val_loss: 0.3704\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8238 - loss: 0.3948 - val_accuracy: 0.8380 - val_loss: 0.3667\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 0.3924 - val_accuracy: 0.8363 - val_loss: 0.3689\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8221 - loss: 0.3967 - val_accuracy: 0.8334 - val_loss: 0.3770\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.3945 - val_accuracy: 0.8373 - val_loss: 0.3656\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8233 - loss: 0.3922 - val_accuracy: 0.8372 - val_loss: 0.3638\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 0.3895 - val_accuracy: 0.8376 - val_loss: 0.3632\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8223 - loss: 0.3949 - val_accuracy: 0.8180 - val_loss: 0.4041\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8386 - loss: 0.3708\n",
            "Test Loss: 0.3661\n",
            "Test Accuracy: 0.8407\n",
            "Confusion Matrix:\n",
            "[[6602 1336]\n",
            " [1322 7430]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83      7938\n",
            "           1       0.85      0.85      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8407\n",
            "Precision: 0.8476\n",
            "Recall: 0.8489\n",
            "F1 Score: 0.8483\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the optimized CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG_Yn4_v8ioD"
      },
      "source": [
        "improved cnn-lstm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH5e7ufc8ioE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9e9758-ae56-42ed-894d-7df849978e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.6763 - loss: 0.5865 - val_accuracy: 0.7945 - val_loss: 0.4433\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.7847 - loss: 0.4669 - val_accuracy: 0.8053 - val_loss: 0.4209\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.7928 - loss: 0.4507 - val_accuracy: 0.8093 - val_loss: 0.4154\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8016 - loss: 0.4352 - val_accuracy: 0.8072 - val_loss: 0.4213\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8033 - loss: 0.4298 - val_accuracy: 0.8146 - val_loss: 0.4019\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8018 - loss: 0.4298 - val_accuracy: 0.8210 - val_loss: 0.3972\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8104 - loss: 0.4179 - val_accuracy: 0.8212 - val_loss: 0.3975\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8084 - loss: 0.4191 - val_accuracy: 0.8250 - val_loss: 0.3942\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8113 - loss: 0.4135 - val_accuracy: 0.8221 - val_loss: 0.3944\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8115 - loss: 0.4157 - val_accuracy: 0.8262 - val_loss: 0.3868\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8138 - loss: 0.4080 - val_accuracy: 0.8257 - val_loss: 0.3879\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8155 - loss: 0.4098 - val_accuracy: 0.8266 - val_loss: 0.3844\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8132 - loss: 0.4060 - val_accuracy: 0.8296 - val_loss: 0.3834\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8155 - loss: 0.4060 - val_accuracy: 0.8304 - val_loss: 0.3798\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8161 - loss: 0.4037 - val_accuracy: 0.8236 - val_loss: 0.4063\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8179 - loss: 0.3994 - val_accuracy: 0.8336 - val_loss: 0.3739\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8175 - loss: 0.4005 - val_accuracy: 0.8332 - val_loss: 0.3761\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8206 - loss: 0.3972 - val_accuracy: 0.8340 - val_loss: 0.3714\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.8203 - loss: 0.3965 - val_accuracy: 0.8347 - val_loss: 0.3699\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8201 - loss: 0.3963 - val_accuracy: 0.8345 - val_loss: 0.3696\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8221 - loss: 0.3944 - val_accuracy: 0.8342 - val_loss: 0.3695\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8195 - loss: 0.3963 - val_accuracy: 0.8334 - val_loss: 0.3735\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8181 - loss: 0.4038 - val_accuracy: 0.8327 - val_loss: 0.3697\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8232 - loss: 0.3914 - val_accuracy: 0.8364 - val_loss: 0.3697\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8235 - loss: 0.3906 - val_accuracy: 0.8388 - val_loss: 0.3650\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8251 - loss: 0.3905 - val_accuracy: 0.8275 - val_loss: 0.3895\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.8211 - loss: 0.3936 - val_accuracy: 0.8394 - val_loss: 0.3672\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8257 - loss: 0.3863 - val_accuracy: 0.8370 - val_loss: 0.3633\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.8287 - loss: 0.3834 - val_accuracy: 0.8389 - val_loss: 0.3613\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8198 - loss: 0.3930 - val_accuracy: 0.8382 - val_loss: 0.3618\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8283 - loss: 0.3846 - val_accuracy: 0.8385 - val_loss: 0.3690\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8243 - loss: 0.3887 - val_accuracy: 0.8373 - val_loss: 0.3621\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8255 - loss: 0.3875 - val_accuracy: 0.8413 - val_loss: 0.3615\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8286 - loss: 0.3818 - val_accuracy: 0.8414 - val_loss: 0.3635\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.8248 - loss: 0.3867 - val_accuracy: 0.8403 - val_loss: 0.3589\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.8294 - loss: 0.3827 - val_accuracy: 0.8400 - val_loss: 0.3676\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8276 - loss: 0.3833 - val_accuracy: 0.8353 - val_loss: 0.3723\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8295 - loss: 0.3797 - val_accuracy: 0.8414 - val_loss: 0.3577\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8295 - loss: 0.3798 - val_accuracy: 0.8417 - val_loss: 0.3555\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8301 - loss: 0.3785 - val_accuracy: 0.8428 - val_loss: 0.3537\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8291 - loss: 0.3804 - val_accuracy: 0.8405 - val_loss: 0.3583\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8310 - loss: 0.3774 - val_accuracy: 0.8433 - val_loss: 0.3568\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8293 - loss: 0.3789 - val_accuracy: 0.8445 - val_loss: 0.3539\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8314 - loss: 0.3780 - val_accuracy: 0.8456 - val_loss: 0.3519\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8293 - loss: 0.3766 - val_accuracy: 0.8434 - val_loss: 0.3567\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8296 - loss: 0.3778 - val_accuracy: 0.8448 - val_loss: 0.3520\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8298 - loss: 0.3787 - val_accuracy: 0.8423 - val_loss: 0.3548\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8338 - loss: 0.3754 - val_accuracy: 0.8415 - val_loss: 0.3579\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8314 - loss: 0.3743 - val_accuracy: 0.8467 - val_loss: 0.3494\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8321 - loss: 0.3754 - val_accuracy: 0.8417 - val_loss: 0.3539\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8428 - loss: 0.3555\n",
            "Test Loss: 0.3519\n",
            "Test Accuracy: 0.8450\n",
            "Confusion Matrix:\n",
            "[[6715 1223]\n",
            " [1364 7388]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.85      0.84      7938\n",
            "           1       0.86      0.84      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.85      0.84     16690\n",
            "weighted avg       0.85      0.84      0.85     16690\n",
            "\n",
            "Accuracy: 0.8450\n",
            "Precision: 0.8580\n",
            "Recall: 0.8441\n",
            "F1 Score: 0.8510\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq350RvC8ioE"
      },
      "source": [
        "improved cnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcF2ZB_K8ioE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25eb68ef-c252-418b-84a9-cd2ab39b3f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.6761 - loss: 0.5948 - val_accuracy: 0.7959 - val_loss: 0.4465\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.7816 - loss: 0.4716 - val_accuracy: 0.8027 - val_loss: 0.4242\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7939 - loss: 0.4502 - val_accuracy: 0.8052 - val_loss: 0.4234\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8002 - loss: 0.4419 - val_accuracy: 0.8104 - val_loss: 0.4152\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8038 - loss: 0.4338 - val_accuracy: 0.8148 - val_loss: 0.4043\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8062 - loss: 0.4252 - val_accuracy: 0.8162 - val_loss: 0.4075\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8075 - loss: 0.4271 - val_accuracy: 0.8231 - val_loss: 0.3941\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8099 - loss: 0.4180 - val_accuracy: 0.8247 - val_loss: 0.3900\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8120 - loss: 0.4136 - val_accuracy: 0.8140 - val_loss: 0.4109\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8128 - loss: 0.4109 - val_accuracy: 0.8274 - val_loss: 0.3848\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8158 - loss: 0.4109 - val_accuracy: 0.8232 - val_loss: 0.3960\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8126 - loss: 0.4113 - val_accuracy: 0.8295 - val_loss: 0.3820\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8179 - loss: 0.4058 - val_accuracy: 0.8287 - val_loss: 0.3770\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8165 - loss: 0.4021 - val_accuracy: 0.8309 - val_loss: 0.3777\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 10ms/step - accuracy: 0.8174 - loss: 0.4060 - val_accuracy: 0.8316 - val_loss: 0.3819\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8209 - loss: 0.4019 - val_accuracy: 0.8313 - val_loss: 0.3744\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8194 - loss: 0.4015 - val_accuracy: 0.8331 - val_loss: 0.3774\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8175 - loss: 0.4032 - val_accuracy: 0.8319 - val_loss: 0.3763\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8245 - loss: 0.3943 - val_accuracy: 0.8354 - val_loss: 0.3688\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8227 - loss: 0.3927 - val_accuracy: 0.8373 - val_loss: 0.3673\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8204 - loss: 0.3995 - val_accuracy: 0.8167 - val_loss: 0.3983\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8216 - loss: 0.3964 - val_accuracy: 0.8362 - val_loss: 0.3661\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8231 - loss: 0.3967 - val_accuracy: 0.8363 - val_loss: 0.3684\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8241 - loss: 0.3925 - val_accuracy: 0.8387 - val_loss: 0.3659\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8257 - loss: 0.3887 - val_accuracy: 0.8361 - val_loss: 0.3734\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8230 - loss: 0.3905 - val_accuracy: 0.8370 - val_loss: 0.3678\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8250 - loss: 0.3878 - val_accuracy: 0.8361 - val_loss: 0.3682\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8246 - loss: 0.3929 - val_accuracy: 0.8373 - val_loss: 0.3670\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8258 - loss: 0.3899 - val_accuracy: 0.8381 - val_loss: 0.3636\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8262 - loss: 0.3872 - val_accuracy: 0.8411 - val_loss: 0.3642\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8280 - loss: 0.3846 - val_accuracy: 0.8376 - val_loss: 0.3672\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8261 - loss: 0.3874 - val_accuracy: 0.8370 - val_loss: 0.3619\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8243 - loss: 0.3899 - val_accuracy: 0.8426 - val_loss: 0.3582\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8263 - loss: 0.3865 - val_accuracy: 0.8401 - val_loss: 0.3590\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8285 - loss: 0.3837 - val_accuracy: 0.8366 - val_loss: 0.3664\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8309 - loss: 0.3858 - val_accuracy: 0.8423 - val_loss: 0.3587\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8291 - loss: 0.3826 - val_accuracy: 0.8416 - val_loss: 0.3581\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8257 - loss: 0.3893 - val_accuracy: 0.8416 - val_loss: 0.3583\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8264 - loss: 0.3846 - val_accuracy: 0.8423 - val_loss: 0.3556\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8290 - loss: 0.3830 - val_accuracy: 0.8404 - val_loss: 0.3582\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8272 - loss: 0.3857 - val_accuracy: 0.8396 - val_loss: 0.3552\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8282 - loss: 0.3812 - val_accuracy: 0.8385 - val_loss: 0.3598\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8314 - loss: 0.3765 - val_accuracy: 0.8399 - val_loss: 0.3600\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8290 - loss: 0.3806 - val_accuracy: 0.8396 - val_loss: 0.3612\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8295 - loss: 0.3789 - val_accuracy: 0.8435 - val_loss: 0.3525\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8307 - loss: 0.3820 - val_accuracy: 0.8444 - val_loss: 0.3527\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8288 - loss: 0.3851 - val_accuracy: 0.8425 - val_loss: 0.3562\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8305 - loss: 0.3764 - val_accuracy: 0.8438 - val_loss: 0.3522\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8347 - loss: 0.3741 - val_accuracy: 0.8438 - val_loss: 0.3529\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8299 - loss: 0.3830 - val_accuracy: 0.8432 - val_loss: 0.3514\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8374 - loss: 0.3587\n",
            "Test Loss: 0.3538\n",
            "Test Accuracy: 0.8410\n",
            "Confusion Matrix:\n",
            "[[6656 1282]\n",
            " [1372 7380]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.83      7938\n",
            "           1       0.85      0.84      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8410\n",
            "Precision: 0.8520\n",
            "Recall: 0.8432\n",
            "F1 Score: 0.8476\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, GRU, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(GRU(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu2OWWdu8ioE"
      },
      "source": [
        "improved DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xrPixBs8ioE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc09a6b-6406-49bb-faa7-b6a6d2aea7d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.6719 - loss: 0.6508 - val_accuracy: 0.7957 - val_loss: 0.4461\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 0.4742 - val_accuracy: 0.8031 - val_loss: 0.4350\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7900 - loss: 0.4531 - val_accuracy: 0.8124 - val_loss: 0.4178\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7971 - loss: 0.4434 - val_accuracy: 0.8035 - val_loss: 0.4255\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8022 - loss: 0.4331 - val_accuracy: 0.8207 - val_loss: 0.4005\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4199 - val_accuracy: 0.8228 - val_loss: 0.4030\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.4171 - val_accuracy: 0.8268 - val_loss: 0.3916\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8137 - loss: 0.4149 - val_accuracy: 0.8243 - val_loss: 0.3921\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.4089 - val_accuracy: 0.8111 - val_loss: 0.4169\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8186 - loss: 0.4028 - val_accuracy: 0.8364 - val_loss: 0.3757\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.3997 - val_accuracy: 0.8377 - val_loss: 0.3700\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.3967 - val_accuracy: 0.8350 - val_loss: 0.3715\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.3984 - val_accuracy: 0.8376 - val_loss: 0.3706\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8183 - loss: 0.3939 - val_accuracy: 0.8385 - val_loss: 0.3695\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8239 - loss: 0.3891 - val_accuracy: 0.8271 - val_loss: 0.3831\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.3965 - val_accuracy: 0.8410 - val_loss: 0.3644\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.3955 - val_accuracy: 0.8385 - val_loss: 0.3644\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.3899 - val_accuracy: 0.8403 - val_loss: 0.3610\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.3865 - val_accuracy: 0.8447 - val_loss: 0.3591\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8265 - loss: 0.3854 - val_accuracy: 0.8441 - val_loss: 0.3628\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.3894 - val_accuracy: 0.8456 - val_loss: 0.3550\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8259 - loss: 0.3850 - val_accuracy: 0.8450 - val_loss: 0.3539\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.3797 - val_accuracy: 0.8506 - val_loss: 0.3483\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.3785 - val_accuracy: 0.8466 - val_loss: 0.3553\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.3808 - val_accuracy: 0.8470 - val_loss: 0.3510\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.3783 - val_accuracy: 0.8483 - val_loss: 0.3514\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.3858 - val_accuracy: 0.8531 - val_loss: 0.3484\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.3723 - val_accuracy: 0.8465 - val_loss: 0.3504\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.3796 - val_accuracy: 0.8513 - val_loss: 0.3452\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.3733 - val_accuracy: 0.8385 - val_loss: 0.3721\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.3728 - val_accuracy: 0.8481 - val_loss: 0.3429\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8350 - loss: 0.3746 - val_accuracy: 0.8519 - val_loss: 0.3435\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.3775 - val_accuracy: 0.8557 - val_loss: 0.3367\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8333 - loss: 0.3707 - val_accuracy: 0.8528 - val_loss: 0.3385\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8344 - loss: 0.3746 - val_accuracy: 0.8531 - val_loss: 0.3463\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8366 - loss: 0.3673 - val_accuracy: 0.8506 - val_loss: 0.3411\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.3694 - val_accuracy: 0.8538 - val_loss: 0.3425\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 0.3711 - val_accuracy: 0.8510 - val_loss: 0.3399\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8370 - loss: 0.3706 - val_accuracy: 0.8516 - val_loss: 0.3544\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3688 - val_accuracy: 0.8558 - val_loss: 0.3437\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8341 - loss: 0.3690 - val_accuracy: 0.8537 - val_loss: 0.3402\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3664 - val_accuracy: 0.8525 - val_loss: 0.3478\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.8381 - loss: 0.3665 - val_accuracy: 0.8530 - val_loss: 0.3375\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8558 - loss: 0.3381\n",
            "Test Loss: 0.3384\n",
            "Test Accuracy: 0.8555\n",
            "Confusion Matrix:\n",
            "[[6776 1162]\n",
            " [1250 7502]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85      7938\n",
            "           1       0.87      0.86      0.86      8752\n",
            "\n",
            "    accuracy                           0.86     16690\n",
            "   macro avg       0.86      0.86      0.86     16690\n",
            "weighted avg       0.86      0.86      0.86     16690\n",
            "\n",
            "Accuracy: 0.8555\n",
            "Precision: 0.8659\n",
            "Recall: 0.8572\n",
            "F1 Score: 0.8615\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the DNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input and hidden layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5ThOlgu8ioF"
      },
      "source": [
        "improved dnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3QlRk2p8ioF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8121b182-562d-4f82-9919-1601c5619554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 19ms/step - accuracy: 0.5647 - loss: 0.6967 - val_accuracy: 0.5885 - val_loss: 0.6691\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - accuracy: 0.6189 - loss: 0.6539 - val_accuracy: 0.5988 - val_loss: 0.6703\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.6570 - loss: 0.6218 - val_accuracy: 0.7281 - val_loss: 0.5380\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.7277 - loss: 0.5480 - val_accuracy: 0.7681 - val_loss: 0.4745\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.7580 - loss: 0.5065 - val_accuracy: 0.7773 - val_loss: 0.4722\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.7777 - loss: 0.4806 - val_accuracy: 0.7984 - val_loss: 0.4270\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.7869 - loss: 0.4635 - val_accuracy: 0.8076 - val_loss: 0.4202\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.7945 - loss: 0.4518 - val_accuracy: 0.8008 - val_loss: 0.4323\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.8031 - loss: 0.4427 - val_accuracy: 0.8002 - val_loss: 0.4230\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8029 - loss: 0.4373 - val_accuracy: 0.8152 - val_loss: 0.4014\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8078 - loss: 0.4317 - val_accuracy: 0.8152 - val_loss: 0.3973\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8107 - loss: 0.4223 - val_accuracy: 0.8190 - val_loss: 0.3987\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8079 - loss: 0.4279 - val_accuracy: 0.8200 - val_loss: 0.3972\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.8132 - loss: 0.4143 - val_accuracy: 0.7944 - val_loss: 0.4318\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - accuracy: 0.8138 - loss: 0.4126 - val_accuracy: 0.8263 - val_loss: 0.3865\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8174 - loss: 0.4079 - val_accuracy: 0.8292 - val_loss: 0.3802\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8164 - loss: 0.4084 - val_accuracy: 0.8211 - val_loss: 0.3927\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.8224 - loss: 0.3987 - val_accuracy: 0.8206 - val_loss: 0.3867\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8231 - loss: 0.4010 - val_accuracy: 0.8210 - val_loss: 0.3944\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8252 - loss: 0.4005 - val_accuracy: 0.8301 - val_loss: 0.3715\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8228 - loss: 0.3956 - val_accuracy: 0.8316 - val_loss: 0.3712\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8244 - loss: 0.3945 - val_accuracy: 0.8248 - val_loss: 0.3799\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8249 - loss: 0.3916 - val_accuracy: 0.8241 - val_loss: 0.3808\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8287 - loss: 0.3896 - val_accuracy: 0.8312 - val_loss: 0.3771\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8280 - loss: 0.3849 - val_accuracy: 0.8316 - val_loss: 0.3730\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8315 - loss: 0.3854 - val_accuracy: 0.8382 - val_loss: 0.3609\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8291 - loss: 0.3818 - val_accuracy: 0.8334 - val_loss: 0.3670\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8294 - loss: 0.3847 - val_accuracy: 0.8381 - val_loss: 0.3602\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8273 - loss: 0.3863 - val_accuracy: 0.8319 - val_loss: 0.3717\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8321 - loss: 0.3815 - val_accuracy: 0.8361 - val_loss: 0.3679\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8321 - loss: 0.3777 - val_accuracy: 0.8391 - val_loss: 0.3624\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.8345 - loss: 0.3803 - val_accuracy: 0.8404 - val_loss: 0.3576\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8372 - loss: 0.3752 - val_accuracy: 0.8361 - val_loss: 0.3643\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8343 - loss: 0.3767 - val_accuracy: 0.8423 - val_loss: 0.3572\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8354 - loss: 0.3748 - val_accuracy: 0.8385 - val_loss: 0.3612\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 17ms/step - accuracy: 0.8360 - loss: 0.3725 - val_accuracy: 0.8382 - val_loss: 0.3640\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8388 - loss: 0.3704 - val_accuracy: 0.8363 - val_loss: 0.3601\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8396 - loss: 0.3696 - val_accuracy: 0.8435 - val_loss: 0.3519\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8387 - loss: 0.3659 - val_accuracy: 0.8420 - val_loss: 0.3573\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8336 - loss: 0.3731 - val_accuracy: 0.8432 - val_loss: 0.3528\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8392 - loss: 0.3650 - val_accuracy: 0.8405 - val_loss: 0.3562\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8419 - loss: 0.3615 - val_accuracy: 0.8442 - val_loss: 0.3542\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.8381 - loss: 0.3649 - val_accuracy: 0.8430 - val_loss: 0.3480\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8423 - loss: 0.3587 - val_accuracy: 0.8414 - val_loss: 0.3588\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8382 - loss: 0.3655 - val_accuracy: 0.8473 - val_loss: 0.3446\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8434 - loss: 0.3631 - val_accuracy: 0.8440 - val_loss: 0.3561\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8404 - loss: 0.3652 - val_accuracy: 0.8439 - val_loss: 0.3544\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - accuracy: 0.8377 - loss: 0.3630 - val_accuracy: 0.8462 - val_loss: 0.3457\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8454 - loss: 0.3574 - val_accuracy: 0.8476 - val_loss: 0.3418\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8434 - loss: 0.3590 - val_accuracy: 0.8468 - val_loss: 0.3419\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 0.3435\n",
            "Test Loss: 0.3427\n",
            "Test Accuracy: 0.8475\n",
            "Confusion Matrix:\n",
            "[[6642 1296]\n",
            " [1250 7502]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84      7938\n",
            "           1       0.85      0.86      0.85      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8475\n",
            "Precision: 0.8527\n",
            "Recall: 0.8572\n",
            "F1 Score: 0.8549\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoN1cYYh8ioG"
      },
      "source": [
        "improved dnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq39eSOI8ioG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d254b8df-a797-49fc-c6dd-0646b8973e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.5492 - loss: 0.7621 - val_accuracy: 0.6366 - val_loss: 0.6349\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 25ms/step - accuracy: 0.6269 - loss: 0.6470 - val_accuracy: 0.7000 - val_loss: 0.5777\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.7044 - loss: 0.5719 - val_accuracy: 0.7757 - val_loss: 0.4762\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 24ms/step - accuracy: 0.7655 - loss: 0.4952 - val_accuracy: 0.8038 - val_loss: 0.4289\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.7841 - loss: 0.4699 - val_accuracy: 0.8010 - val_loss: 0.4312\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.7894 - loss: 0.4620 - val_accuracy: 0.8028 - val_loss: 0.4309\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.7954 - loss: 0.4486 - val_accuracy: 0.8146 - val_loss: 0.4046\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.7936 - loss: 0.4492 - val_accuracy: 0.7984 - val_loss: 0.4329\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8039 - loss: 0.4351 - val_accuracy: 0.8158 - val_loss: 0.4039\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.8007 - loss: 0.4313 - val_accuracy: 0.8227 - val_loss: 0.3929\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8048 - loss: 0.4269 - val_accuracy: 0.8257 - val_loss: 0.3870\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8063 - loss: 0.4251 - val_accuracy: 0.8246 - val_loss: 0.3881\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8098 - loss: 0.4187 - val_accuracy: 0.8186 - val_loss: 0.3993\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 25ms/step - accuracy: 0.8063 - loss: 0.4214 - val_accuracy: 0.8295 - val_loss: 0.3823\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8112 - loss: 0.4117 - val_accuracy: 0.8274 - val_loss: 0.3788\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8122 - loss: 0.4101 - val_accuracy: 0.8281 - val_loss: 0.3814\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8186 - loss: 0.4047 - val_accuracy: 0.8174 - val_loss: 0.3959\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.8172 - loss: 0.4072 - val_accuracy: 0.8230 - val_loss: 0.3833\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8162 - loss: 0.4020 - val_accuracy: 0.8380 - val_loss: 0.3743\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.8202 - loss: 0.4030 - val_accuracy: 0.8382 - val_loss: 0.3688\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 23ms/step - accuracy: 0.8207 - loss: 0.3966 - val_accuracy: 0.8341 - val_loss: 0.3759\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8227 - loss: 0.3940 - val_accuracy: 0.8435 - val_loss: 0.3610\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8226 - loss: 0.3937 - val_accuracy: 0.8401 - val_loss: 0.3596\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8246 - loss: 0.3897 - val_accuracy: 0.8373 - val_loss: 0.3671\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.8287 - loss: 0.3849 - val_accuracy: 0.8425 - val_loss: 0.3615\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 24ms/step - accuracy: 0.8226 - loss: 0.3915 - val_accuracy: 0.8407 - val_loss: 0.3666\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8231 - loss: 0.3890 - val_accuracy: 0.8413 - val_loss: 0.3588\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.8286 - loss: 0.3837 - val_accuracy: 0.8414 - val_loss: 0.3663\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8271 - loss: 0.3840 - val_accuracy: 0.8429 - val_loss: 0.3574\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8228 - loss: 0.3875 - val_accuracy: 0.8449 - val_loss: 0.3525\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8262 - loss: 0.3842 - val_accuracy: 0.8326 - val_loss: 0.3758\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8294 - loss: 0.3814 - val_accuracy: 0.8456 - val_loss: 0.3513\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8298 - loss: 0.3828 - val_accuracy: 0.8320 - val_loss: 0.3634\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8301 - loss: 0.3788 - val_accuracy: 0.8435 - val_loss: 0.3499\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8319 - loss: 0.3785 - val_accuracy: 0.8269 - val_loss: 0.3756\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8315 - loss: 0.3765 - val_accuracy: 0.8427 - val_loss: 0.3546\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8313 - loss: 0.3764 - val_accuracy: 0.8259 - val_loss: 0.3881\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8313 - loss: 0.3771 - val_accuracy: 0.8502 - val_loss: 0.3456\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8306 - loss: 0.3746 - val_accuracy: 0.8473 - val_loss: 0.3443\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8320 - loss: 0.3753 - val_accuracy: 0.8412 - val_loss: 0.3552\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8367 - loss: 0.3697 - val_accuracy: 0.8498 - val_loss: 0.3431\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8348 - loss: 0.3729 - val_accuracy: 0.8504 - val_loss: 0.3473\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8347 - loss: 0.3720 - val_accuracy: 0.8492 - val_loss: 0.3454\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.8350 - loss: 0.3747 - val_accuracy: 0.8483 - val_loss: 0.3420\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8346 - loss: 0.3714 - val_accuracy: 0.8466 - val_loss: 0.3502\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8376 - loss: 0.3652 - val_accuracy: 0.8366 - val_loss: 0.3656\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8393 - loss: 0.3635 - val_accuracy: 0.8456 - val_loss: 0.3470\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8367 - loss: 0.3664 - val_accuracy: 0.8462 - val_loss: 0.3477\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.8382 - loss: 0.3623 - val_accuracy: 0.8445 - val_loss: 0.3479\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.8358 - loss: 0.3654 - val_accuracy: 0.8438 - val_loss: 0.3506\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8454 - loss: 0.3503\n",
            "Test Loss: 0.3455\n",
            "Test Accuracy: 0.8488\n",
            "Confusion Matrix:\n",
            "[[6798 1140]\n",
            " [1383 7369]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84      7938\n",
            "           1       0.87      0.84      0.85      8752\n",
            "\n",
            "    accuracy                           0.85     16690\n",
            "   macro avg       0.85      0.85      0.85     16690\n",
            "weighted avg       0.85      0.85      0.85     16690\n",
            "\n",
            "Accuracy: 0.8488\n",
            "Precision: 0.8660\n",
            "Recall: 0.8420\n",
            "F1 Score: 0.8538\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Reshape output from Dense layers to be suitable for GRU layers\n",
        "model.add(tf.keras.layers.Reshape((X_train_reshaped.shape[1], 32)))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqj4oELV_VBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWDIENjEkjUD"
      },
      "source": [
        "Random 10-features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jvfkS6_kjUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8818a033-ae47-4c69-a87b-bfbcb2aa785e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Length-of-Email',\n",
              " 'Number of co-occuring words',\n",
              " 'Repititive-Words-in-a-Email',\n",
              " 'Spam lexicon',\n",
              " 'Uinque-Words-in-a-Email',\n",
              " 'Subjective',\n",
              " 'Quoted-text-in-a-Email',\n",
              " 'Question-Marks-in-a-Email',\n",
              " 'Neg-Sentiment',\n",
              " 'Number of capitalized words']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "features=['Length-of-Email','Number of co-occuring words',\n",
        " 'Repititive-Words-in-a-Email',\n",
        "                  'Spam lexicon',\n",
        "       'Uinque-Words-in-a-Email','Subjective',\n",
        "        'Quoted-text-in-a-Email',\n",
        "     'Question-Marks-in-a-Email',\n",
        "                 'Neg-Sentiment',\n",
        "   'Number of capitalized words' ]\n",
        "features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1OqeChokjUE"
      },
      "source": [
        "improved rnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FIVusYEkjUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838ac220-b4f4-4121-912b-98c2e83dbbce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.7015 - loss: 0.5948 - val_accuracy: 0.7867 - val_loss: 0.4622\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.7744 - loss: 0.4900 - val_accuracy: 0.7944 - val_loss: 0.4513\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.7844 - loss: 0.4721 - val_accuracy: 0.7943 - val_loss: 0.4351\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7949 - loss: 0.4525 - val_accuracy: 0.8011 - val_loss: 0.4341\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8038 - loss: 0.4447 - val_accuracy: 0.8023 - val_loss: 0.4192\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8037 - loss: 0.4418 - val_accuracy: 0.8140 - val_loss: 0.4078\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8054 - loss: 0.4370 - val_accuracy: 0.8124 - val_loss: 0.4086\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8094 - loss: 0.4297 - val_accuracy: 0.8192 - val_loss: 0.3998\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8111 - loss: 0.4242 - val_accuracy: 0.8122 - val_loss: 0.4093\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8114 - loss: 0.4225 - val_accuracy: 0.8107 - val_loss: 0.4079\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8114 - loss: 0.4261 - val_accuracy: 0.8172 - val_loss: 0.4027\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8148 - loss: 0.4198 - val_accuracy: 0.8182 - val_loss: 0.3942\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8145 - loss: 0.4183 - val_accuracy: 0.8197 - val_loss: 0.3957\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8156 - loss: 0.4150 - val_accuracy: 0.8220 - val_loss: 0.3972\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8151 - loss: 0.4125 - val_accuracy: 0.8211 - val_loss: 0.3934\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8204 - loss: 0.4055 - val_accuracy: 0.8197 - val_loss: 0.3909\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8213 - loss: 0.4055 - val_accuracy: 0.8217 - val_loss: 0.3919\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8211 - loss: 0.4084 - val_accuracy: 0.8212 - val_loss: 0.3887\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8232 - loss: 0.4027 - val_accuracy: 0.8055 - val_loss: 0.4081\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8230 - loss: 0.4026 - val_accuracy: 0.8166 - val_loss: 0.3935\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.8222 - loss: 0.4044 - val_accuracy: 0.8283 - val_loss: 0.3835\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.8218 - loss: 0.4013 - val_accuracy: 0.8213 - val_loss: 0.3911\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8218 - loss: 0.4000 - val_accuracy: 0.8253 - val_loss: 0.3850\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8238 - loss: 0.3977 - val_accuracy: 0.8203 - val_loss: 0.3935\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8215 - loss: 0.3976 - val_accuracy: 0.8270 - val_loss: 0.3860\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8238 - loss: 0.3974 - val_accuracy: 0.8301 - val_loss: 0.3804\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8261 - loss: 0.3947 - val_accuracy: 0.8254 - val_loss: 0.3799\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8257 - loss: 0.3945 - val_accuracy: 0.8206 - val_loss: 0.3934\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8239 - loss: 0.3933 - val_accuracy: 0.8329 - val_loss: 0.3739\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8252 - loss: 0.3927 - val_accuracy: 0.8331 - val_loss: 0.3817\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8281 - loss: 0.3911 - val_accuracy: 0.8313 - val_loss: 0.3723\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8275 - loss: 0.3931 - val_accuracy: 0.8314 - val_loss: 0.3802\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8287 - loss: 0.3901 - val_accuracy: 0.8297 - val_loss: 0.3770\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8306 - loss: 0.3887 - val_accuracy: 0.8262 - val_loss: 0.3770\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8295 - loss: 0.3859 - val_accuracy: 0.8321 - val_loss: 0.3684\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8338 - loss: 0.3801 - val_accuracy: 0.8344 - val_loss: 0.3689\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8331 - loss: 0.3837 - val_accuracy: 0.8316 - val_loss: 0.3724\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8293 - loss: 0.3835 - val_accuracy: 0.8292 - val_loss: 0.3760\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8378 - loss: 0.3786 - val_accuracy: 0.8368 - val_loss: 0.3631\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8343 - loss: 0.3790 - val_accuracy: 0.8271 - val_loss: 0.3738\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8342 - loss: 0.3786 - val_accuracy: 0.8234 - val_loss: 0.3774\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8338 - loss: 0.3794 - val_accuracy: 0.8262 - val_loss: 0.3773\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8323 - loss: 0.3807 - val_accuracy: 0.8306 - val_loss: 0.3717\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8337 - loss: 0.3773 - val_accuracy: 0.8289 - val_loss: 0.3780\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8367 - loss: 0.3713 - val_accuracy: 0.8286 - val_loss: 0.3710\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8369 - loss: 0.3745 - val_accuracy: 0.8367 - val_loss: 0.3771\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8373 - loss: 0.3735 - val_accuracy: 0.8306 - val_loss: 0.3709\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8346 - loss: 0.3769 - val_accuracy: 0.8310 - val_loss: 0.3688\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8351 - loss: 0.3758 - val_accuracy: 0.8369 - val_loss: 0.3650\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.3647\n",
            "Test Loss: 0.3684\n",
            "Test Accuracy: 0.8385\n",
            "Confusion Matrix:\n",
            "[[6355 1583]\n",
            " [1113 7639]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.80      0.83      7938\n",
            "           1       0.83      0.87      0.85      8752\n",
            "\n",
            "    accuracy                           0.84     16690\n",
            "   macro avg       0.84      0.84      0.84     16690\n",
            "weighted avg       0.84      0.84      0.84     16690\n",
            "\n",
            "Accuracy: 0.8385\n",
            "Precision: 0.8283\n",
            "Recall: 0.8728\n",
            "F1 Score: 0.8500\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for RNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "\n",
        "# RNN layers\n",
        "model.add(SimpleRNN(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(SimpleRNN(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZIC3T_okjUF"
      },
      "source": [
        "improved rnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVUgYW1DkjUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7338253-e99c-4ec2-da7f-7944f07e7ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - accuracy: 0.5921 - loss: 0.6871 - val_accuracy: 0.6497 - val_loss: 0.6257\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.6433 - loss: 0.6316 - val_accuracy: 0.6809 - val_loss: 0.5922\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6770 - loss: 0.5994 - val_accuracy: 0.7389 - val_loss: 0.5225\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.7508 - loss: 0.5096 - val_accuracy: 0.7585 - val_loss: 0.4822\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.7799 - loss: 0.4810 - val_accuracy: 0.7988 - val_loss: 0.4403\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.7870 - loss: 0.4665 - val_accuracy: 0.8046 - val_loss: 0.4346\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7930 - loss: 0.4580 - val_accuracy: 0.8049 - val_loss: 0.4315\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.7959 - loss: 0.4507 - val_accuracy: 0.8047 - val_loss: 0.4300\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.7992 - loss: 0.4476 - val_accuracy: 0.8065 - val_loss: 0.4256\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7979 - loss: 0.4458 - val_accuracy: 0.8066 - val_loss: 0.4183\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8045 - loss: 0.4380 - val_accuracy: 0.8007 - val_loss: 0.4321\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8028 - loss: 0.4375 - val_accuracy: 0.8116 - val_loss: 0.4124\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8057 - loss: 0.4352 - val_accuracy: 0.8029 - val_loss: 0.4266\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8069 - loss: 0.4285 - val_accuracy: 0.8161 - val_loss: 0.4064\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8040 - loss: 0.4349 - val_accuracy: 0.8152 - val_loss: 0.4030\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8119 - loss: 0.4239 - val_accuracy: 0.8120 - val_loss: 0.4071\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8136 - loss: 0.4214 - val_accuracy: 0.8111 - val_loss: 0.4061\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8125 - loss: 0.4214 - val_accuracy: 0.8131 - val_loss: 0.4013\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8103 - loss: 0.4175 - val_accuracy: 0.8189 - val_loss: 0.3938\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8173 - loss: 0.4167 - val_accuracy: 0.8190 - val_loss: 0.3946\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 16ms/step - accuracy: 0.8155 - loss: 0.4140 - val_accuracy: 0.8195 - val_loss: 0.3952\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8166 - loss: 0.4127 - val_accuracy: 0.8214 - val_loss: 0.3905\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8170 - loss: 0.4113 - val_accuracy: 0.8212 - val_loss: 0.3889\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8153 - loss: 0.4134 - val_accuracy: 0.8154 - val_loss: 0.4014\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8188 - loss: 0.4058 - val_accuracy: 0.8197 - val_loss: 0.3890\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8196 - loss: 0.4065 - val_accuracy: 0.8201 - val_loss: 0.3879\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8190 - loss: 0.4051 - val_accuracy: 0.8238 - val_loss: 0.3837\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.8233 - loss: 0.3995 - val_accuracy: 0.8247 - val_loss: 0.3819\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 15ms/step - accuracy: 0.8224 - loss: 0.4011 - val_accuracy: 0.8254 - val_loss: 0.3805\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8202 - loss: 0.4018 - val_accuracy: 0.8254 - val_loss: 0.3835\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8252 - loss: 0.3964 - val_accuracy: 0.8233 - val_loss: 0.3790\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8228 - loss: 0.3982 - val_accuracy: 0.8227 - val_loss: 0.3858\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8235 - loss: 0.3993 - val_accuracy: 0.8276 - val_loss: 0.3774\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.8243 - loss: 0.3977 - val_accuracy: 0.8295 - val_loss: 0.3784\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8250 - loss: 0.3962 - val_accuracy: 0.8268 - val_loss: 0.3795\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8279 - loss: 0.3929 - val_accuracy: 0.8299 - val_loss: 0.3749\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.8246 - loss: 0.3949 - val_accuracy: 0.8308 - val_loss: 0.3723\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8235 - loss: 0.3920 - val_accuracy: 0.8284 - val_loss: 0.3757\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8286 - loss: 0.3901 - val_accuracy: 0.8282 - val_loss: 0.3771\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8228 - loss: 0.3948 - val_accuracy: 0.8321 - val_loss: 0.3699\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8271 - loss: 0.3895 - val_accuracy: 0.8296 - val_loss: 0.3701\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 17ms/step - accuracy: 0.8263 - loss: 0.3916 - val_accuracy: 0.8277 - val_loss: 0.3778\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.8277 - loss: 0.3896 - val_accuracy: 0.8350 - val_loss: 0.3692\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.8251 - loss: 0.3920 - val_accuracy: 0.8247 - val_loss: 0.3775\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8275 - loss: 0.3871 - val_accuracy: 0.8334 - val_loss: 0.3643\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8290 - loss: 0.3864 - val_accuracy: 0.8222 - val_loss: 0.3793\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8294 - loss: 0.3872 - val_accuracy: 0.8298 - val_loss: 0.3740\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8318 - loss: 0.3818 - val_accuracy: 0.8244 - val_loss: 0.3829\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8294 - loss: 0.3856 - val_accuracy: 0.8294 - val_loss: 0.3749\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8322 - loss: 0.3788 - val_accuracy: 0.8333 - val_loss: 0.3661\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.3745\n",
            "Test Loss: 0.3740\n",
            "Test Accuracy: 0.8323\n",
            "Confusion Matrix:\n",
            "[[6550 1388]\n",
            " [1411 7341]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.83      0.82      7938\n",
            "           1       0.84      0.84      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8323\n",
            "Precision: 0.8410\n",
            "Recall: 0.8388\n",
            "F1 Score: 0.8399\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVxQEJGzkjUF"
      },
      "source": [
        "improved rnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpaWyJVvkjUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32096c3e-b0b7-42ce-f59e-e4fca3a50e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 18ms/step - accuracy: 0.5824 - loss: 0.6988 - val_accuracy: 0.6197 - val_loss: 0.6370\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.6933 - loss: 0.5841 - val_accuracy: 0.7678 - val_loss: 0.4812\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.7726 - loss: 0.4926 - val_accuracy: 0.7836 - val_loss: 0.4682\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.7835 - loss: 0.4780 - val_accuracy: 0.7984 - val_loss: 0.4456\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.7907 - loss: 0.4633 - val_accuracy: 0.7983 - val_loss: 0.4410\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.7892 - loss: 0.4627 - val_accuracy: 0.8009 - val_loss: 0.4330\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.7964 - loss: 0.4542 - val_accuracy: 0.7943 - val_loss: 0.4398\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.7965 - loss: 0.4520 - val_accuracy: 0.7955 - val_loss: 0.4377\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8008 - loss: 0.4466 - val_accuracy: 0.8062 - val_loss: 0.4281\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.7977 - loss: 0.4444 - val_accuracy: 0.8069 - val_loss: 0.4251\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.7998 - loss: 0.4432 - val_accuracy: 0.8069 - val_loss: 0.4327\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 20ms/step - accuracy: 0.7996 - loss: 0.4458 - val_accuracy: 0.8065 - val_loss: 0.4211\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8026 - loss: 0.4408 - val_accuracy: 0.8087 - val_loss: 0.4273\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8032 - loss: 0.4381 - val_accuracy: 0.8047 - val_loss: 0.4261\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8066 - loss: 0.4344 - val_accuracy: 0.8065 - val_loss: 0.4152\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8071 - loss: 0.4313 - val_accuracy: 0.8016 - val_loss: 0.4239\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8074 - loss: 0.4291 - val_accuracy: 0.8128 - val_loss: 0.4123\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 19ms/step - accuracy: 0.8108 - loss: 0.4266 - val_accuracy: 0.8125 - val_loss: 0.4102\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8101 - loss: 0.4243 - val_accuracy: 0.8131 - val_loss: 0.4065\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8107 - loss: 0.4234 - val_accuracy: 0.8149 - val_loss: 0.4043\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8104 - loss: 0.4252 - val_accuracy: 0.8205 - val_loss: 0.3972\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8156 - loss: 0.4168 - val_accuracy: 0.8148 - val_loss: 0.3988\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8104 - loss: 0.4217 - val_accuracy: 0.8167 - val_loss: 0.4009\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8160 - loss: 0.4120 - val_accuracy: 0.8189 - val_loss: 0.3981\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.8160 - loss: 0.4178 - val_accuracy: 0.8194 - val_loss: 0.3941\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8155 - loss: 0.4149 - val_accuracy: 0.8145 - val_loss: 0.3967\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8128 - loss: 0.4183 - val_accuracy: 0.8207 - val_loss: 0.3933\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8130 - loss: 0.4113 - val_accuracy: 0.8208 - val_loss: 0.3888\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8173 - loss: 0.4101 - val_accuracy: 0.8189 - val_loss: 0.3915\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8196 - loss: 0.4084 - val_accuracy: 0.8194 - val_loss: 0.3910\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 19ms/step - accuracy: 0.8192 - loss: 0.4066 - val_accuracy: 0.8232 - val_loss: 0.3847\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8203 - loss: 0.4071 - val_accuracy: 0.8173 - val_loss: 0.3999\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8226 - loss: 0.3981 - val_accuracy: 0.8233 - val_loss: 0.3797\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8227 - loss: 0.3991 - val_accuracy: 0.8233 - val_loss: 0.3814\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8199 - loss: 0.4080 - val_accuracy: 0.8168 - val_loss: 0.3942\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8236 - loss: 0.3973 - val_accuracy: 0.8214 - val_loss: 0.3876\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8238 - loss: 0.3999 - val_accuracy: 0.8253 - val_loss: 0.3793\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8243 - loss: 0.3978 - val_accuracy: 0.8230 - val_loss: 0.3843\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.8254 - loss: 0.3976 - val_accuracy: 0.8121 - val_loss: 0.4075\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8248 - loss: 0.3961 - val_accuracy: 0.8300 - val_loss: 0.3714\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8236 - loss: 0.3935 - val_accuracy: 0.8256 - val_loss: 0.3792\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8258 - loss: 0.3931 - val_accuracy: 0.8293 - val_loss: 0.3711\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8247 - loss: 0.3922 - val_accuracy: 0.8289 - val_loss: 0.3714\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8277 - loss: 0.3931 - val_accuracy: 0.8217 - val_loss: 0.3860\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.8229 - loss: 0.3973 - val_accuracy: 0.8292 - val_loss: 0.3700\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.8240 - loss: 0.3953 - val_accuracy: 0.8323 - val_loss: 0.3665\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8298 - loss: 0.3838 - val_accuracy: 0.8308 - val_loss: 0.3698\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8308 - loss: 0.3865 - val_accuracy: 0.8268 - val_loss: 0.3825\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8301 - loss: 0.3862 - val_accuracy: 0.8292 - val_loss: 0.3702\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.8310 - loss: 0.3871 - val_accuracy: 0.8268 - val_loss: 0.3750\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8311 - loss: 0.3767\n",
            "Test Loss: 0.3760\n",
            "Test Accuracy: 0.8304\n",
            "Confusion Matrix:\n",
            "[[6541 1397]\n",
            " [1434 7318]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82      7938\n",
            "           1       0.84      0.84      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8304\n",
            "Precision: 0.8397\n",
            "Recall: 0.8362\n",
            "F1 Score: 0.8379\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the RNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPANxT0HkjUF"
      },
      "source": [
        "improved cnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsQ6fCRnkjUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bea5fc3-0f81-48bd-dd97-876d1eb97b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6418 - loss: 0.6797 - val_accuracy: 0.7829 - val_loss: 0.4799\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7623 - loss: 0.5031 - val_accuracy: 0.7895 - val_loss: 0.4568\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7769 - loss: 0.4813 - val_accuracy: 0.7974 - val_loss: 0.4525\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7824 - loss: 0.4727 - val_accuracy: 0.7955 - val_loss: 0.4441\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.7865 - loss: 0.4669 - val_accuracy: 0.7982 - val_loss: 0.4397\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7898 - loss: 0.4629 - val_accuracy: 0.7994 - val_loss: 0.4375\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 0.4565 - val_accuracy: 0.7970 - val_loss: 0.4456\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.4523 - val_accuracy: 0.7985 - val_loss: 0.4399\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.7949 - loss: 0.4515 - val_accuracy: 0.8047 - val_loss: 0.4293\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.7916 - loss: 0.4545 - val_accuracy: 0.7935 - val_loss: 0.4367\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.4495 - val_accuracy: 0.7994 - val_loss: 0.4274\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7960 - loss: 0.4474 - val_accuracy: 0.8027 - val_loss: 0.4257\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7983 - loss: 0.4462 - val_accuracy: 0.8053 - val_loss: 0.4265\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7976 - loss: 0.4444 - val_accuracy: 0.7960 - val_loss: 0.4477\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.4398 - val_accuracy: 0.8129 - val_loss: 0.4179\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7997 - loss: 0.4426 - val_accuracy: 0.8068 - val_loss: 0.4150\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7970 - loss: 0.4427 - val_accuracy: 0.8055 - val_loss: 0.4204\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4425 - val_accuracy: 0.8084 - val_loss: 0.4140\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.4379 - val_accuracy: 0.8071 - val_loss: 0.4225\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.7983 - loss: 0.4397 - val_accuracy: 0.8090 - val_loss: 0.4167\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8015 - loss: 0.4376 - val_accuracy: 0.8107 - val_loss: 0.4166\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8016 - loss: 0.4352 - val_accuracy: 0.8032 - val_loss: 0.4278\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8033 - loss: 0.4350 - val_accuracy: 0.8049 - val_loss: 0.4237\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4378 - val_accuracy: 0.8040 - val_loss: 0.4312\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.4323 - val_accuracy: 0.8119 - val_loss: 0.4152\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8065 - loss: 0.4330 - val_accuracy: 0.8118 - val_loss: 0.4167\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8035 - loss: 0.4350 - val_accuracy: 0.8115 - val_loss: 0.4093\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4294 - val_accuracy: 0.7995 - val_loss: 0.4334\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8056 - loss: 0.4313 - val_accuracy: 0.8011 - val_loss: 0.4378\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.4342 - val_accuracy: 0.8123 - val_loss: 0.4091\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8062 - loss: 0.4281 - val_accuracy: 0.8116 - val_loss: 0.4120\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8054 - loss: 0.4324 - val_accuracy: 0.7964 - val_loss: 0.4385\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4318 - val_accuracy: 0.8084 - val_loss: 0.4199\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.4315 - val_accuracy: 0.8102 - val_loss: 0.4179\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.4271 - val_accuracy: 0.8149 - val_loss: 0.4054\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.4268 - val_accuracy: 0.8117 - val_loss: 0.4090\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.4242 - val_accuracy: 0.8105 - val_loss: 0.4101\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8045 - loss: 0.4336 - val_accuracy: 0.8108 - val_loss: 0.4135\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.4268 - val_accuracy: 0.8004 - val_loss: 0.4369\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8103 - loss: 0.4238 - val_accuracy: 0.8161 - val_loss: 0.4060\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 0.4281 - val_accuracy: 0.8038 - val_loss: 0.4305\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.4279 - val_accuracy: 0.8071 - val_loss: 0.4183\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 0.4251 - val_accuracy: 0.7946 - val_loss: 0.4429\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.4233 - val_accuracy: 0.8051 - val_loss: 0.4302\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8075 - loss: 0.4290 - val_accuracy: 0.8134 - val_loss: 0.4021\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4259 - val_accuracy: 0.8015 - val_loss: 0.4362\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.4190 - val_accuracy: 0.8152 - val_loss: 0.4124\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4286 - val_accuracy: 0.8145 - val_loss: 0.4075\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.4239 - val_accuracy: 0.8079 - val_loss: 0.4244\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4300 - val_accuracy: 0.8160 - val_loss: 0.4087\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8148 - loss: 0.4097\n",
            "Test Loss: 0.4065\n",
            "Test Accuracy: 0.8170\n",
            "Confusion Matrix:\n",
            "[[6608 1330]\n",
            " [1724 7028]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.83      0.81      7938\n",
            "           1       0.84      0.80      0.82      8752\n",
            "\n",
            "    accuracy                           0.82     16690\n",
            "   macro avg       0.82      0.82      0.82     16690\n",
            "weighted avg       0.82      0.82      0.82     16690\n",
            "\n",
            "Accuracy: 0.8170\n",
            "Precision: 0.8409\n",
            "Recall: 0.8030\n",
            "F1 Score: 0.8215\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the optimized CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShgQbmL2kjUG"
      },
      "source": [
        "improved cnn-lstm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAythBbXkjUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02dbb06a-d587-4bed-8ed2-536d34859647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.6932 - loss: 0.5788 - val_accuracy: 0.7907 - val_loss: 0.4644\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7780 - loss: 0.4808 - val_accuracy: 0.7931 - val_loss: 0.4521\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.7826 - loss: 0.4703 - val_accuracy: 0.8000 - val_loss: 0.4415\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7864 - loss: 0.4691 - val_accuracy: 0.7989 - val_loss: 0.4423\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.7908 - loss: 0.4605 - val_accuracy: 0.7972 - val_loss: 0.4454\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.7928 - loss: 0.4528 - val_accuracy: 0.8023 - val_loss: 0.4269\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7926 - loss: 0.4512 - val_accuracy: 0.8031 - val_loss: 0.4256\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7974 - loss: 0.4467 - val_accuracy: 0.8022 - val_loss: 0.4312\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.7962 - loss: 0.4460 - val_accuracy: 0.8054 - val_loss: 0.4241\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8002 - loss: 0.4412 - val_accuracy: 0.7968 - val_loss: 0.4320\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.7970 - loss: 0.4428 - val_accuracy: 0.8062 - val_loss: 0.4227\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8034 - loss: 0.4381 - val_accuracy: 0.8099 - val_loss: 0.4188\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8013 - loss: 0.4359 - val_accuracy: 0.8117 - val_loss: 0.4139\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8021 - loss: 0.4354 - val_accuracy: 0.8113 - val_loss: 0.4133\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8044 - loss: 0.4313 - val_accuracy: 0.8102 - val_loss: 0.4140\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8044 - loss: 0.4352 - val_accuracy: 0.8106 - val_loss: 0.4145\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8002 - loss: 0.4335 - val_accuracy: 0.8164 - val_loss: 0.4106\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8054 - loss: 0.4321 - val_accuracy: 0.8122 - val_loss: 0.4147\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8051 - loss: 0.4315 - val_accuracy: 0.8128 - val_loss: 0.4062\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8066 - loss: 0.4265 - val_accuracy: 0.8138 - val_loss: 0.4043\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8059 - loss: 0.4279 - val_accuracy: 0.8142 - val_loss: 0.4038\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8064 - loss: 0.4306 - val_accuracy: 0.8076 - val_loss: 0.4090\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8042 - loss: 0.4284 - val_accuracy: 0.8133 - val_loss: 0.4037\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8086 - loss: 0.4209 - val_accuracy: 0.8181 - val_loss: 0.3979\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8076 - loss: 0.4200 - val_accuracy: 0.8114 - val_loss: 0.4083\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8100 - loss: 0.4230 - val_accuracy: 0.8164 - val_loss: 0.4069\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8087 - loss: 0.4234 - val_accuracy: 0.8059 - val_loss: 0.4165\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8072 - loss: 0.4233 - val_accuracy: 0.8161 - val_loss: 0.4006\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 10ms/step - accuracy: 0.8070 - loss: 0.4244 - val_accuracy: 0.8150 - val_loss: 0.4027\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8092 - loss: 0.4193 - val_accuracy: 0.8140 - val_loss: 0.4038\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8120 - loss: 0.4150 - val_accuracy: 0.8165 - val_loss: 0.3949\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8117 - loss: 0.4194 - val_accuracy: 0.8174 - val_loss: 0.4019\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8114 - loss: 0.4144 - val_accuracy: 0.8132 - val_loss: 0.3942\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8127 - loss: 0.4196 - val_accuracy: 0.8124 - val_loss: 0.4101\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8099 - loss: 0.4182 - val_accuracy: 0.8227 - val_loss: 0.3883\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8126 - loss: 0.4139 - val_accuracy: 0.8131 - val_loss: 0.4061\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8102 - loss: 0.4175 - val_accuracy: 0.8173 - val_loss: 0.4032\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8121 - loss: 0.4132 - val_accuracy: 0.8146 - val_loss: 0.4030\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8123 - loss: 0.4162 - val_accuracy: 0.8212 - val_loss: 0.3866\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8156 - loss: 0.4134 - val_accuracy: 0.8215 - val_loss: 0.3903\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8138 - loss: 0.4126 - val_accuracy: 0.8142 - val_loss: 0.4079\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8139 - loss: 0.4137 - val_accuracy: 0.8186 - val_loss: 0.3920\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8115 - loss: 0.4169 - val_accuracy: 0.8069 - val_loss: 0.4194\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8147 - loss: 0.4074 - val_accuracy: 0.8210 - val_loss: 0.3926\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.4130 - val_accuracy: 0.7985 - val_loss: 0.4318\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8119 - loss: 0.4108 - val_accuracy: 0.8232 - val_loss: 0.3887\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8103 - loss: 0.4152 - val_accuracy: 0.8064 - val_loss: 0.4271\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8129 - loss: 0.4134 - val_accuracy: 0.8243 - val_loss: 0.3850\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8145 - loss: 0.4070 - val_accuracy: 0.8200 - val_loss: 0.3859\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8140 - loss: 0.4102 - val_accuracy: 0.8212 - val_loss: 0.3853\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.3934\n",
            "Test Loss: 0.3922\n",
            "Test Accuracy: 0.8241\n",
            "Confusion Matrix:\n",
            "[[6594 1344]\n",
            " [1592 7160]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.83      0.82      7938\n",
            "           1       0.84      0.82      0.83      8752\n",
            "\n",
            "    accuracy                           0.82     16690\n",
            "   macro avg       0.82      0.82      0.82     16690\n",
            "weighted avg       0.82      0.82      0.82     16690\n",
            "\n",
            "Accuracy: 0.8241\n",
            "Precision: 0.8420\n",
            "Recall: 0.8181\n",
            "F1 Score: 0.8299\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(LSTM(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBs_GC1NkjUG"
      },
      "source": [
        "improved cnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wtFkB5ykjUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19bfa80a-7571-4a38-9178-42b18b6f60de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 10ms/step - accuracy: 0.6728 - loss: 0.5983 - val_accuracy: 0.7794 - val_loss: 0.4753\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7754 - loss: 0.4896 - val_accuracy: 0.7924 - val_loss: 0.4479\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7818 - loss: 0.4743 - val_accuracy: 0.7934 - val_loss: 0.4465\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.7908 - loss: 0.4609 - val_accuracy: 0.7979 - val_loss: 0.4485\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.7856 - loss: 0.4669 - val_accuracy: 0.8036 - val_loss: 0.4380\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.7910 - loss: 0.4589 - val_accuracy: 0.7979 - val_loss: 0.4271\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.7898 - loss: 0.4585 - val_accuracy: 0.8013 - val_loss: 0.4280\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.7899 - loss: 0.4585 - val_accuracy: 0.8070 - val_loss: 0.4277\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.7944 - loss: 0.4503 - val_accuracy: 0.8022 - val_loss: 0.4347\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7943 - loss: 0.4507 - val_accuracy: 0.8077 - val_loss: 0.4186\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7939 - loss: 0.4496 - val_accuracy: 0.8065 - val_loss: 0.4274\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.7977 - loss: 0.4420 - val_accuracy: 0.8056 - val_loss: 0.4286\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8006 - loss: 0.4444 - val_accuracy: 0.8023 - val_loss: 0.4264\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.7963 - loss: 0.4444 - val_accuracy: 0.8061 - val_loss: 0.4269\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8005 - loss: 0.4370 - val_accuracy: 0.8088 - val_loss: 0.4185\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8009 - loss: 0.4405 - val_accuracy: 0.8077 - val_loss: 0.4146\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8029 - loss: 0.4369 - val_accuracy: 0.8090 - val_loss: 0.4151\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - accuracy: 0.7959 - loss: 0.4409 - val_accuracy: 0.8100 - val_loss: 0.4110\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.8059 - loss: 0.4303 - val_accuracy: 0.8068 - val_loss: 0.4179\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8034 - loss: 0.4273 - val_accuracy: 0.8068 - val_loss: 0.4297\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8047 - loss: 0.4279 - val_accuracy: 0.8137 - val_loss: 0.4049\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8064 - loss: 0.4268 - val_accuracy: 0.8133 - val_loss: 0.4077\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8058 - loss: 0.4307 - val_accuracy: 0.8156 - val_loss: 0.4066\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8073 - loss: 0.4274 - val_accuracy: 0.8148 - val_loss: 0.4040\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8057 - loss: 0.4247 - val_accuracy: 0.8133 - val_loss: 0.4119\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8065 - loss: 0.4249 - val_accuracy: 0.8052 - val_loss: 0.4220\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8043 - loss: 0.4298 - val_accuracy: 0.8132 - val_loss: 0.4069\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8048 - loss: 0.4296 - val_accuracy: 0.8131 - val_loss: 0.4068\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8060 - loss: 0.4267 - val_accuracy: 0.8154 - val_loss: 0.4078\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8071 - loss: 0.4265 - val_accuracy: 0.8148 - val_loss: 0.4059\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8086 - loss: 0.4239 - val_accuracy: 0.8139 - val_loss: 0.4010\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8063 - loss: 0.4238 - val_accuracy: 0.8097 - val_loss: 0.4130\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8101 - loss: 0.4196 - val_accuracy: 0.8060 - val_loss: 0.4301\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8092 - loss: 0.4227 - val_accuracy: 0.8194 - val_loss: 0.3979\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8098 - loss: 0.4218 - val_accuracy: 0.8089 - val_loss: 0.4078\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8073 - loss: 0.4244 - val_accuracy: 0.7887 - val_loss: 0.4348\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8081 - loss: 0.4241 - val_accuracy: 0.8190 - val_loss: 0.3956\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8103 - loss: 0.4193 - val_accuracy: 0.8173 - val_loss: 0.3920\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8100 - loss: 0.4178 - val_accuracy: 0.8192 - val_loss: 0.3945\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8095 - loss: 0.4214 - val_accuracy: 0.8147 - val_loss: 0.4052\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8085 - loss: 0.4183 - val_accuracy: 0.8185 - val_loss: 0.3949\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8098 - loss: 0.4174 - val_accuracy: 0.8102 - val_loss: 0.4054\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8112 - loss: 0.4153 - val_accuracy: 0.8137 - val_loss: 0.4024\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8097 - loss: 0.4174 - val_accuracy: 0.8093 - val_loss: 0.4042\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.8099 - loss: 0.4201 - val_accuracy: 0.8219 - val_loss: 0.3906\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8122 - loss: 0.4163 - val_accuracy: 0.8219 - val_loss: 0.3880\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.8141 - loss: 0.4136 - val_accuracy: 0.8195 - val_loss: 0.3940\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.8106 - loss: 0.4159 - val_accuracy: 0.8195 - val_loss: 0.3935\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8105 - loss: 0.4189 - val_accuracy: 0.8168 - val_loss: 0.3905\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.8124 - loss: 0.4159 - val_accuracy: 0.7872 - val_loss: 0.4370\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.3956\n",
            "Test Loss: 0.3948\n",
            "Test Accuracy: 0.8252\n",
            "Confusion Matrix:\n",
            "[[6539 1399]\n",
            " [1519 7233]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.82      7938\n",
            "           1       0.84      0.83      0.83      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.82      0.83      0.82     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8252\n",
            "Precision: 0.8379\n",
            "Recall: 0.8264\n",
            "F1 Score: 0.8321\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, GRU, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for CNN-GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the CNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# CNN layers\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(50, return_sequences=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(GRU(25))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v5lxk2mkjUG"
      },
      "source": [
        "improved DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlP-NObokjUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34287c60-017d-4ba9-85be-0fdffa6a24f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6882 - loss: 0.6353 - val_accuracy: 0.7816 - val_loss: 0.4713\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 0.4948 - val_accuracy: 0.7905 - val_loss: 0.4600\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7794 - loss: 0.4738 - val_accuracy: 0.8010 - val_loss: 0.4442\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.4616 - val_accuracy: 0.8031 - val_loss: 0.4341\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.4559 - val_accuracy: 0.7997 - val_loss: 0.4332\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7890 - loss: 0.4563 - val_accuracy: 0.8078 - val_loss: 0.4240\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7963 - loss: 0.4510 - val_accuracy: 0.8052 - val_loss: 0.4227\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7984 - loss: 0.4424 - val_accuracy: 0.8047 - val_loss: 0.4316\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.4380 - val_accuracy: 0.8169 - val_loss: 0.4144\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4335 - val_accuracy: 0.8104 - val_loss: 0.4367\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.4268 - val_accuracy: 0.8140 - val_loss: 0.4148\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4278 - val_accuracy: 0.8060 - val_loss: 0.4395\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4263 - val_accuracy: 0.8178 - val_loss: 0.4040\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.4252 - val_accuracy: 0.8197 - val_loss: 0.4053\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8101 - loss: 0.4251 - val_accuracy: 0.8153 - val_loss: 0.4100\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.4228 - val_accuracy: 0.8246 - val_loss: 0.4076\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.4178 - val_accuracy: 0.8134 - val_loss: 0.4233\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.4243 - val_accuracy: 0.8004 - val_loss: 0.4500\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.4178 - val_accuracy: 0.8170 - val_loss: 0.4099\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8131 - loss: 0.4182 - val_accuracy: 0.8238 - val_loss: 0.4079\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.4206 - val_accuracy: 0.8223 - val_loss: 0.4064\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8139 - loss: 0.4138 - val_accuracy: 0.8149 - val_loss: 0.4171\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8160 - loss: 0.4118 - val_accuracy: 0.8272 - val_loss: 0.3936\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8153 - loss: 0.4124 - val_accuracy: 0.8205 - val_loss: 0.3951\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.4138 - val_accuracy: 0.8283 - val_loss: 0.3928\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8147 - loss: 0.4129 - val_accuracy: 0.8252 - val_loss: 0.3946\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8150 - loss: 0.4143 - val_accuracy: 0.8278 - val_loss: 0.3895\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.4067 - val_accuracy: 0.8171 - val_loss: 0.4422\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8169 - loss: 0.4077 - val_accuracy: 0.8281 - val_loss: 0.3920\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.4063 - val_accuracy: 0.8299 - val_loss: 0.3905\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.4051 - val_accuracy: 0.8300 - val_loss: 0.3971\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8193 - loss: 0.4096 - val_accuracy: 0.8274 - val_loss: 0.3811\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.4074 - val_accuracy: 0.8294 - val_loss: 0.4000\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.4106 - val_accuracy: 0.8268 - val_loss: 0.3903\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8135 - loss: 0.4119 - val_accuracy: 0.8295 - val_loss: 0.3905\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8177 - loss: 0.4076 - val_accuracy: 0.8143 - val_loss: 0.4209\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.4052 - val_accuracy: 0.8266 - val_loss: 0.3922\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.4134 - val_accuracy: 0.8304 - val_loss: 0.3904\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4032 - val_accuracy: 0.8304 - val_loss: 0.3916\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8179 - loss: 0.4088 - val_accuracy: 0.8292 - val_loss: 0.3889\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8206 - loss: 0.4075 - val_accuracy: 0.8242 - val_loss: 0.3938\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.4021 - val_accuracy: 0.8290 - val_loss: 0.3945\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8292 - loss: 0.3814\n",
            "Test Loss: 0.3814\n",
            "Test Accuracy: 0.8294\n",
            "Confusion Matrix:\n",
            "[[6616 1322]\n",
            " [1525 7227]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.83      0.82      7938\n",
            "           1       0.85      0.83      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8294\n",
            "Precision: 0.8454\n",
            "Recall: 0.8258\n",
            "F1 Score: 0.8354\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build the DNN model\n",
        "model = Sequential()\n",
        "\n",
        "# Input and hidden layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tcrktRykjUH"
      },
      "source": [
        "improved dnn-lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVsh4NdfkjUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4871942f-8677-4250-c335-2eb7a415ea0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 14ms/step - accuracy: 0.5829 - loss: 0.6978 - val_accuracy: 0.6536 - val_loss: 0.6222\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.6431 - loss: 0.6354 - val_accuracy: 0.6556 - val_loss: 0.6170\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.6776 - loss: 0.5993 - val_accuracy: 0.7680 - val_loss: 0.5001\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.7525 - loss: 0.5192 - val_accuracy: 0.7871 - val_loss: 0.4607\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - accuracy: 0.7763 - loss: 0.4882 - val_accuracy: 0.7899 - val_loss: 0.4524\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.7866 - loss: 0.4744 - val_accuracy: 0.7903 - val_loss: 0.4440\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 15ms/step - accuracy: 0.7914 - loss: 0.4708 - val_accuracy: 0.8003 - val_loss: 0.4351\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.7931 - loss: 0.4609 - val_accuracy: 0.7994 - val_loss: 0.4367\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7943 - loss: 0.4581 - val_accuracy: 0.8015 - val_loss: 0.4277\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.7991 - loss: 0.4537 - val_accuracy: 0.8020 - val_loss: 0.4301\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.8011 - loss: 0.4492 - val_accuracy: 0.8089 - val_loss: 0.4192\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8006 - loss: 0.4470 - val_accuracy: 0.8098 - val_loss: 0.4178\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8047 - loss: 0.4440 - val_accuracy: 0.8102 - val_loss: 0.4109\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8021 - loss: 0.4390 - val_accuracy: 0.8104 - val_loss: 0.4159\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8075 - loss: 0.4355 - val_accuracy: 0.8120 - val_loss: 0.4077\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8062 - loss: 0.4373 - val_accuracy: 0.8139 - val_loss: 0.4109\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8095 - loss: 0.4311 - val_accuracy: 0.8149 - val_loss: 0.4037\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8101 - loss: 0.4290 - val_accuracy: 0.8042 - val_loss: 0.4236\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8121 - loss: 0.4285 - val_accuracy: 0.8066 - val_loss: 0.4142\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8086 - loss: 0.4269 - val_accuracy: 0.8170 - val_loss: 0.4010\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8103 - loss: 0.4290 - val_accuracy: 0.8102 - val_loss: 0.4096\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8127 - loss: 0.4243 - val_accuracy: 0.8155 - val_loss: 0.4018\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.4218 - val_accuracy: 0.8119 - val_loss: 0.4098\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.8118 - loss: 0.4224 - val_accuracy: 0.8188 - val_loss: 0.3925\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8157 - loss: 0.4167 - val_accuracy: 0.8173 - val_loss: 0.3925\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8168 - loss: 0.4146 - val_accuracy: 0.8203 - val_loss: 0.3908\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.8134 - loss: 0.4160 - val_accuracy: 0.8182 - val_loss: 0.3922\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 14ms/step - accuracy: 0.8200 - loss: 0.4103 - val_accuracy: 0.8202 - val_loss: 0.3942\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8171 - loss: 0.4133 - val_accuracy: 0.8240 - val_loss: 0.3889\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.8153 - loss: 0.4147 - val_accuracy: 0.8188 - val_loss: 0.3941\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 14ms/step - accuracy: 0.8195 - loss: 0.4077 - val_accuracy: 0.8234 - val_loss: 0.3885\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.8185 - loss: 0.4116 - val_accuracy: 0.8177 - val_loss: 0.4024\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8210 - loss: 0.4054 - val_accuracy: 0.8198 - val_loss: 0.3889\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8218 - loss: 0.4002 - val_accuracy: 0.8238 - val_loss: 0.3802\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - accuracy: 0.8231 - loss: 0.4036 - val_accuracy: 0.8236 - val_loss: 0.3868\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8216 - loss: 0.4014 - val_accuracy: 0.8233 - val_loss: 0.3879\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8189 - loss: 0.4075 - val_accuracy: 0.8252 - val_loss: 0.3836\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 17ms/step - accuracy: 0.8245 - loss: 0.3995 - val_accuracy: 0.8219 - val_loss: 0.3877\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 16ms/step - accuracy: 0.8219 - loss: 0.4025 - val_accuracy: 0.8244 - val_loss: 0.3797\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - accuracy: 0.8226 - loss: 0.3975 - val_accuracy: 0.8277 - val_loss: 0.3799\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.8238 - loss: 0.3998 - val_accuracy: 0.8288 - val_loss: 0.3781\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.8273 - loss: 0.3934 - val_accuracy: 0.8291 - val_loss: 0.3782\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8256 - loss: 0.3946 - val_accuracy: 0.8219 - val_loss: 0.3840\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8222 - loss: 0.3977 - val_accuracy: 0.8259 - val_loss: 0.3800\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8272 - loss: 0.3950 - val_accuracy: 0.8253 - val_loss: 0.3780\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8272 - loss: 0.3916 - val_accuracy: 0.8266 - val_loss: 0.3776\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8274 - loss: 0.3907 - val_accuracy: 0.8270 - val_loss: 0.3750\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 16ms/step - accuracy: 0.8292 - loss: 0.3881 - val_accuracy: 0.8268 - val_loss: 0.3799\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8250 - loss: 0.3964 - val_accuracy: 0.8304 - val_loss: 0.3744\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - accuracy: 0.8262 - loss: 0.3915 - val_accuracy: 0.8323 - val_loss: 0.3688\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.3747\n",
            "Test Loss: 0.3747\n",
            "Test Accuracy: 0.8318\n",
            "Confusion Matrix:\n",
            "[[6551 1387]\n",
            " [1421 7331]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.83      0.82      7938\n",
            "           1       0.84      0.84      0.84      8752\n",
            "\n",
            "    accuracy                           0.83     16690\n",
            "   macro avg       0.83      0.83      0.83     16690\n",
            "weighted avg       0.83      0.83      0.83     16690\n",
            "\n",
            "Accuracy: 0.8318\n",
            "Precision: 0.8409\n",
            "Recall: 0.8376\n",
            "F1 Score: 0.8393\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# LSTM layers\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBrm2OQwkjUH"
      },
      "source": [
        "improved dnn-gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IswlN_jDkjUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52b7dce-9731-4c8d-b605-c2cc786f828d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.5422 - loss: 0.7733 - val_accuracy: 0.6281 - val_loss: 0.6287\n",
            "Epoch 2/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 22ms/step - accuracy: 0.6494 - loss: 0.6262 - val_accuracy: 0.6563 - val_loss: 0.6167\n",
            "Epoch 3/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.7141 - loss: 0.5566 - val_accuracy: 0.7720 - val_loss: 0.4810\n",
            "Epoch 4/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.7553 - loss: 0.5099 - val_accuracy: 0.7805 - val_loss: 0.4705\n",
            "Epoch 5/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.7671 - loss: 0.4923 - val_accuracy: 0.7915 - val_loss: 0.4523\n",
            "Epoch 6/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 23ms/step - accuracy: 0.7753 - loss: 0.4798 - val_accuracy: 0.7937 - val_loss: 0.4467\n",
            "Epoch 7/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.7805 - loss: 0.4727 - val_accuracy: 0.7968 - val_loss: 0.4315\n",
            "Epoch 8/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.7799 - loss: 0.4678 - val_accuracy: 0.7931 - val_loss: 0.4353\n",
            "Epoch 9/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - accuracy: 0.7846 - loss: 0.4635 - val_accuracy: 0.8049 - val_loss: 0.4278\n",
            "Epoch 10/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.7896 - loss: 0.4556 - val_accuracy: 0.8072 - val_loss: 0.4234\n",
            "Epoch 11/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.7903 - loss: 0.4557 - val_accuracy: 0.8068 - val_loss: 0.4221\n",
            "Epoch 12/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.7922 - loss: 0.4501 - val_accuracy: 0.8089 - val_loss: 0.4159\n",
            "Epoch 13/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.7953 - loss: 0.4472 - val_accuracy: 0.8121 - val_loss: 0.4120\n",
            "Epoch 14/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 22ms/step - accuracy: 0.8009 - loss: 0.4414 - val_accuracy: 0.8066 - val_loss: 0.4206\n",
            "Epoch 15/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.7956 - loss: 0.4436 - val_accuracy: 0.8083 - val_loss: 0.4088\n",
            "Epoch 16/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8031 - loss: 0.4336 - val_accuracy: 0.8074 - val_loss: 0.4139\n",
            "Epoch 17/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.7986 - loss: 0.4380 - val_accuracy: 0.8155 - val_loss: 0.4041\n",
            "Epoch 18/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.7980 - loss: 0.4384 - val_accuracy: 0.8171 - val_loss: 0.4049\n",
            "Epoch 19/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.8027 - loss: 0.4344 - val_accuracy: 0.8156 - val_loss: 0.4015\n",
            "Epoch 20/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.8018 - loss: 0.4304 - val_accuracy: 0.8151 - val_loss: 0.4026\n",
            "Epoch 21/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8018 - loss: 0.4306 - val_accuracy: 0.8095 - val_loss: 0.4109\n",
            "Epoch 22/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.8013 - loss: 0.4326 - val_accuracy: 0.8200 - val_loss: 0.3962\n",
            "Epoch 23/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8079 - loss: 0.4206 - val_accuracy: 0.8170 - val_loss: 0.4032\n",
            "Epoch 24/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 22ms/step - accuracy: 0.8042 - loss: 0.4252 - val_accuracy: 0.8106 - val_loss: 0.4069\n",
            "Epoch 25/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.8065 - loss: 0.4218 - val_accuracy: 0.8149 - val_loss: 0.3969\n",
            "Epoch 26/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8074 - loss: 0.4199 - val_accuracy: 0.8146 - val_loss: 0.4018\n",
            "Epoch 27/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.8086 - loss: 0.4219 - val_accuracy: 0.8191 - val_loss: 0.3942\n",
            "Epoch 28/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8104 - loss: 0.4168 - val_accuracy: 0.8182 - val_loss: 0.3901\n",
            "Epoch 29/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.8082 - loss: 0.4188 - val_accuracy: 0.8205 - val_loss: 0.3933\n",
            "Epoch 30/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.8115 - loss: 0.4139 - val_accuracy: 0.8195 - val_loss: 0.3877\n",
            "Epoch 31/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - accuracy: 0.8125 - loss: 0.4182 - val_accuracy: 0.8229 - val_loss: 0.3905\n",
            "Epoch 32/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.8109 - loss: 0.4173 - val_accuracy: 0.8071 - val_loss: 0.4146\n",
            "Epoch 33/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - accuracy: 0.8140 - loss: 0.4118 - val_accuracy: 0.8249 - val_loss: 0.3856\n",
            "Epoch 34/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 23ms/step - accuracy: 0.8105 - loss: 0.4138 - val_accuracy: 0.8250 - val_loss: 0.3882\n",
            "Epoch 35/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.8123 - loss: 0.4118 - val_accuracy: 0.8228 - val_loss: 0.3859\n",
            "Epoch 36/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - accuracy: 0.8119 - loss: 0.4128 - val_accuracy: 0.8251 - val_loss: 0.3843\n",
            "Epoch 37/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 23ms/step - accuracy: 0.8132 - loss: 0.4110 - val_accuracy: 0.8196 - val_loss: 0.3869\n",
            "Epoch 38/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 22ms/step - accuracy: 0.8144 - loss: 0.4071 - val_accuracy: 0.8238 - val_loss: 0.3859\n",
            "Epoch 39/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 21ms/step - accuracy: 0.8156 - loss: 0.4150 - val_accuracy: 0.8146 - val_loss: 0.3958\n",
            "Epoch 40/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 23ms/step - accuracy: 0.8125 - loss: 0.4095 - val_accuracy: 0.8222 - val_loss: 0.3846\n",
            "Epoch 41/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 22ms/step - accuracy: 0.8127 - loss: 0.4103 - val_accuracy: 0.8253 - val_loss: 0.3803\n",
            "Epoch 42/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.8185 - loss: 0.4013 - val_accuracy: 0.8226 - val_loss: 0.3894\n",
            "Epoch 43/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - accuracy: 0.8113 - loss: 0.4103 - val_accuracy: 0.8231 - val_loss: 0.3846\n",
            "Epoch 44/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.8144 - loss: 0.4077 - val_accuracy: 0.8271 - val_loss: 0.3823\n",
            "Epoch 45/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - accuracy: 0.8156 - loss: 0.4077 - val_accuracy: 0.8212 - val_loss: 0.3868\n",
            "Epoch 46/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 22ms/step - accuracy: 0.8145 - loss: 0.4085 - val_accuracy: 0.8265 - val_loss: 0.3810\n",
            "Epoch 47/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 20ms/step - accuracy: 0.8162 - loss: 0.4067 - val_accuracy: 0.8203 - val_loss: 0.3846\n",
            "Epoch 48/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - accuracy: 0.8146 - loss: 0.4048 - val_accuracy: 0.8236 - val_loss: 0.3795\n",
            "Epoch 49/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 22ms/step - accuracy: 0.8170 - loss: 0.4023 - val_accuracy: 0.8259 - val_loss: 0.3803\n",
            "Epoch 50/50\n",
            "\u001b[1m1669/1669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - accuracy: 0.8167 - loss: 0.4040 - val_accuracy: 0.8211 - val_loss: 0.3879\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
            "\u001b[1m522/522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8224 - loss: 0.3862\n",
            "Test Loss: 0.3847\n",
            "Test Accuracy: 0.8228\n",
            "Confusion Matrix:\n",
            "[[6576 1362]\n",
            " [1596 7156]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.82      7938\n",
            "           1       0.84      0.82      0.83      8752\n",
            "\n",
            "    accuracy                           0.82     16690\n",
            "   macro avg       0.82      0.82      0.82     16690\n",
            "weighted avg       0.82      0.82      0.82     16690\n",
            "\n",
            "Accuracy: 0.8228\n",
            "Precision: 0.8401\n",
            "Recall: 0.8176\n",
            "F1 Score: 0.8287\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf  # Import TensorFlow\n",
        "\n",
        "# Load your data\n",
        "data = df.copy()\n",
        "\n",
        "# Drop irrelevant columns\n",
        "X = data[features]\n",
        "y = data['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for GRU [samples, timesteps, features]\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# Build the DNN-GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_reshaped.shape[1], 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Reshape output from Dense layers to be suitable for GRU layers\n",
        "model.add(tf.keras.layers.Reshape((X_train_reshaped.shape[1], 32)))\n",
        "\n",
        "# GRU layers\n",
        "model.add(GRU(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2,\n",
        "                    callbacks=[\n",
        "                        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "                    ])\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(X_test_reshaped)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate and print performance metrics\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# You can also extract individual metrics if needed\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "# Get the RAM details\n",
        "ram_info = psutil.virtual_memory()\n",
        "\n",
        "# Convert bytes to GB\n",
        "total_ram = ram_info.total / (1024 ** 3)\n",
        "available_ram = ram_info.available / (1024 ** 3)\n",
        "\n",
        "print(f\"Total RAM: {total_ram:.2f} GB\")\n",
        "print(f\"Available RAM: {available_ram:.2f} GB\")\n"
      ],
      "metadata": {
        "id": "GrvTbYCRl9Ky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98932e30-ab31-4589-b954-b66526b84cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total RAM: 12.67 GB\n",
            "Available RAM: 8.87 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if GPU is available\n",
        "gpu_available = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "if gpu_available:\n",
        "    gpu_info = tf.config.experimental.get_device_details(gpu_available[0])\n",
        "    print(\"GPU is available.\")\n",
        "    print(f\"GPU Name: {gpu_info['device_name']}\")\n",
        "else:\n",
        "    print(\"No GPU found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLo6qfOMT-fz",
        "outputId": "be08c3b9-09cf-4b26-a97f-45dee7910654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDdA7i3AUH2k",
        "outputId": "75189629-83b3-48bc-a82c-0d50a763f49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed bhi\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed bhi\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "itZxxnoXUIll"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}